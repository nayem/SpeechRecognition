{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Compatibility imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from six.moves import xrange as range\n",
    "\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from python_speech_features import mfcc\n",
    "except ImportError:\n",
    "    print(\"Failed to import python_speech_features.\\n Try pip install python_speech_features.\")\n",
    "    raise ImportError\n",
    "\n",
    "from utils import sparse_tuple_from as sparse_tuple_from\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Input, LSTM, GRU, Dense\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space\n",
    "\n",
    "# Some configs\n",
    "num_features = 13\n",
    "num_units=50 # Number of units in the LSTM cell\n",
    "# Accounting the 0th indice +  space + blank label = 28 characters\n",
    "num_classes = ord('z') - ord('a') + 1 + 1 + 1\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 200\n",
    "num_hidden = 50\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "initial_learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "\n",
    "num_examples = 1\n",
    "num_batches_per_epoch = int(num_examples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIRECTORY = 'TIMIT_full/'\n",
    "WAV_CLASS = '*.wav'\n",
    "TXT_CLASS = '*.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRECTORY = 'timit_train_16k/'\n",
    "VAL_DIRECTORY = 'timit_val_16k/'\n",
    "TEST_DIRECTORY = 'timit_test_16k/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRECTORY = 'train_16k/'\n",
    "VAL_DIRECTORY = 'val_16k/'\n",
    "TEST_DIRECTORY = 'test_16k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(wav_path,txt_path):\n",
    "\n",
    "    x_s = []\n",
    "    y_s = []\n",
    "    text_s = []\n",
    "    print(wav_path, txt_path)\n",
    "    for e, (f1, f2) in enumerate( zip(sorted(glob.glob(wav_path)),sorted(glob.glob(txt_path))) ) :\n",
    "#         print('FileName:',f1, f2)\n",
    "        \n",
    "        ##### Read Audio features #####\n",
    "        ###############################\n",
    "        audio, fs = sf.read(f1)\n",
    "        inputs = mfcc(audio, samplerate=fs)\n",
    "        \n",
    "        # Tranform in 3D array\n",
    "        train_inputs = np.asarray(inputs[np.newaxis, :])\n",
    "        train_inputs = (train_inputs - np.mean(train_inputs))/np.std(train_inputs)\n",
    "#         print('train_inputs.shape:', train_inputs.shape)\n",
    "        \n",
    "        train_seq_len = [train_inputs.shape[1]]\n",
    "#         print('train_seq_len.len:', len(train_seq_len) )\n",
    "        \n",
    "        x_s.append(train_inputs)\n",
    "#         print('x_s.len', len(x_s))\n",
    "        \n",
    "        ##### Read Labels features #####\n",
    "        ###############################\n",
    "        with open(f2, 'r') as txt_f:\n",
    "            line = txt_f.readlines()[-1] #Only the last line is necessary\n",
    "\n",
    "            targets = preprocess_line(line)\n",
    "            text_s.append(targets)\n",
    "\n",
    "            # Adding blank label\n",
    "            targets = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in targets])\n",
    "\n",
    "            # Transform char into index\n",
    "            targets = np.asarray([SPACE_INDEX if x == SPACE_TOKEN else ord(x) - FIRST_INDEX\n",
    "                                  for x in targets])\n",
    "\n",
    "            # Creating sparse representation to feed the placeholder\n",
    "            train_targets = sparse_tuple_from([targets])\n",
    "#             print('train_targets.shape:', len(train_targets))\n",
    "            y_s.append(train_targets)\n",
    "              \n",
    "    \n",
    "    print('x_s.len', len(x_s),', [-1]x_s.len', x_s[-1].shape)\n",
    "#     x_s = pad_sequences(x_s, maxlen=500, dtype='float', padding='post', truncating='post')\n",
    "#     print('x_s.shape', (x_s.shape))\n",
    "        \n",
    "    \n",
    "    return x_s, y_s,text_s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(line):\n",
    "    \n",
    "    original = ' '.join(line.strip().lower().split(' ')[2:])\n",
    "    for c in set(original):\n",
    "        if c != ' ' and not c.isalpha():\n",
    "            original = original.replace(c,'')\n",
    "        \n",
    "    targets = original.replace(' ', '  ')\n",
    "    targets = targets.split(' ')\n",
    "\n",
    "    i = 0\n",
    "    while i<len(targets)-1:\n",
    "        if targets[i]==targets[i+1] and targets[i+1]=='':\n",
    "            del targets[i+1]\n",
    "        else:\n",
    "            i +=1\n",
    "            \n",
    "    return targets\n",
    "    \n",
    "    # Get only the words between [a-z] and replace period for none\n",
    "#     original = ' '.join(line.strip().lower().split(' ')[2:]).replace('.', '').replace('\\'','')\n",
    "#     targets = original.replace(' ', '  ')\n",
    "#     return targets.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMIT_full/train_16k/*.wav TIMIT_full/train_16k/*.txt\n",
      "x_s.len 4576 , [-1]x_s.len (1, 204, 13)\n",
      "4576 4576\n"
     ]
    }
   ],
   "source": [
    "x_, y_,text_ = load_dataset(ROOT_DIRECTORY+TRAIN_DIRECTORY+WAV_CLASS, ROOT_DIRECTORY+TRAIN_DIRECTORY+TXT_CLASS)  \n",
    "print(len(x_), len(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMIT_full/val_16k/*.wav TIMIT_full/val_16k/*.txt\n",
      "x_s.len 44 , [-1]x_s.len (1, 194, 13)\n",
      "44 44\n"
     ]
    }
   ],
   "source": [
    "val_x_, val_y_, val_text_ = load_dataset(ROOT_DIRECTORY+VAL_DIRECTORY+WAV_CLASS, ROOT_DIRECTORY+VAL_DIRECTORY+TXT_CLASS)  \n",
    "print(len(val_x_), len(val_y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMIT_full/test_16k/*.wav TIMIT_full/test_16k/*.txt\n",
      "x_s.len 1680 , [-1]x_s.len (1, 315, 13)\n",
      "1680 1680\n"
     ]
    }
   ],
   "source": [
    "test_x_, test_y_, test_text_ = load_dataset(ROOT_DIRECTORY+TEST_DIRECTORY+WAV_CLASS, ROOT_DIRECTORY+TEST_DIRECTORY+TXT_CLASS)  \n",
    "print(len(test_x_), len(test_y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, depth = 1500, 100, 1 # MNIST images are 28x28 and greyscale\n",
    "num_classes = 2 # there are 10 classes (1 per digit)\n",
    "\n",
    "kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "\n",
    "hidden_size = 512 # the FC layer will have 512 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9aa4c9c61241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# CNN layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mconv_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_depth_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_depth_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    470\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=3"
     ]
    }
   ],
   "source": [
    "# THE MAIN CODE! CRNN\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # e.g: log filter bank or MFCC features\n",
    "    # Has size [batch_size, max_stepsize, num_features], but the\n",
    "    # batch_size and max_stepsize can vary along each step\n",
    "    inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "\n",
    "    # Here we use sparse_placeholder that will generate a\n",
    "    # SparseTensor required by ctc_loss op.\n",
    "    targets = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "    # 1d array of size [batch_size]\n",
    "    seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    # CNN layer\n",
    "    conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inputs)\n",
    "    conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "    # Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "    conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "    pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "\n",
    "    # Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "    conv_5 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_5)\n",
    "\n",
    "    pool_3 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    \n",
    "    # Defining the cell\n",
    "    # Can be:\n",
    "    #   tf.nn.rnn_cell.RNNCell\n",
    "    #   tf.nn.rnn_cell.GRUCell \n",
    "    cells = []\n",
    "    for _ in range(num_layers):\n",
    "        cell = tf.contrib.rnn.LSTMCell(num_units)  # Or LSTMCell(num_units)\n",
    "        cells.append(cell)\n",
    "    stack = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "    # The second output is the last state and we will no use that\n",
    "    outputs, _ = tf.nn.dynamic_rnn(stack, drop_3, seq_len, dtype=tf.float32)\n",
    "\n",
    "    shape = tf.shape(inputs)\n",
    "    batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "    # Reshaping to apply the same weights over the timesteps\n",
    "    outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "\n",
    "    # Truncated normal with mean 0 and stdev=0.1\n",
    "    # Tip: Try another initialization\n",
    "    # see https://www.tensorflow.org/versions/r0.9/api_docs/python/contrib.layers.html#initializers\n",
    "    W = tf.Variable(tf.truncated_normal([num_hidden,\n",
    "                                         num_classes],\n",
    "                                        stddev=0.1))\n",
    "    # Zero initialization\n",
    "    # Tip: Is tf.zeros_initializer the same?\n",
    "    b = tf.Variable(tf.constant(0., shape=[num_classes]))\n",
    "\n",
    "    # Doing the affine projection\n",
    "    logits = tf.matmul(outputs, W) + b\n",
    "\n",
    "    # Reshaping back to the original shape\n",
    "    logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "\n",
    "    # Time major\n",
    "    logits = tf.transpose(logits, (1, 0, 2))\n",
    "\n",
    "    loss = tf.nn.ctc_loss(targets, logits, seq_len)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(initial_learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "\n",
    "    # Option 2: tf.nn.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "    # Inaccuracy: label error rate\n",
    "    ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                          targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MAIN CODE! BiLSTM\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # e.g: log filter bank or MFCC features\n",
    "    # Has size [batch_size, max_stepsize, num_features], but the\n",
    "    # batch_size and max_stepsize can vary along each step\n",
    "    inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "\n",
    "    # Here we use sparse_placeholder that will generate a\n",
    "    # SparseTensor required by ctc_loss op.\n",
    "    targets = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "    # 1d array of size [batch_size]\n",
    "    seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    # Defining the cell\n",
    "    # Can be:\n",
    "    #   tf.nn.rnn_cell.RNNCell\n",
    "    #   tf.nn.rnn_cell.GRUCell \n",
    "    cells = []\n",
    "    for _ in range(num_layers):\n",
    "        cell = tf.contrib.rnn.GRUCell(num_units)  # Or LSTMCell(num_units)\n",
    "        cells.append(cell)\n",
    "    stack = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    \n",
    "    cells_bw = []\n",
    "    for _ in range(num_layers):\n",
    "        cell_bw = tf.contrib.rnn.GRUCell(num_units)  # Or LSTMCell(num_units)\n",
    "        cells_bw.append(cell_bw)\n",
    "    stack_bw = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "    # The second output is the last state and we will no use that\n",
    "    outputs, _ = tf.nn.bidirectional_dynamic_rnn(stack,stack_bw, inputs, seq_len, dtype=tf.float32)\n",
    "\n",
    "    shape = tf.shape(inputs)\n",
    "    batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "    # Reshaping to apply the same weights over the timesteps\n",
    "    outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "\n",
    "    # Truncated normal with mean 0 and stdev=0.1\n",
    "    # Tip: Try another initialization\n",
    "    # see https://www.tensorflow.org/versions/r0.9/api_docs/python/contrib.layers.html#initializers\n",
    "    W = tf.Variable(tf.truncated_normal([num_hidden,\n",
    "                                         num_classes],\n",
    "                                        stddev=0.1))\n",
    "    # Zero initialization\n",
    "    # Tip: Is tf.zeros_initializer the same?\n",
    "    b = tf.Variable(tf.constant(0., shape=[num_classes]))\n",
    "\n",
    "    # Doing the affine projection\n",
    "    logits = tf.matmul(outputs, W) + b\n",
    "\n",
    "    # Reshaping back to the original shape\n",
    "    logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "\n",
    "    # Time major\n",
    "    logits = tf.transpose(logits, (1, 0, 2))\n",
    "\n",
    "    loss = tf.nn.ctc_loss(targets, logits, seq_len)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(initial_learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "\n",
    "    # Option 2: tf.nn.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "    # Inaccuracy: label error rate\n",
    "    ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                          targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0 2459 (1, 316, 13)\n",
      "batch: 100 4393 (1, 383, 13)\n",
      "batch: 200 1367 (1, 159, 13)\n",
      "10 inf 422.82654052972794 254.10722303390503\n",
      "Epoch 1/10, train_cost = inf, train_ler = 422.827, val_cost = inf, val_ler = 15.096, time = 256.191\n",
      "batch: 0 847 (1, 235, 13)\n",
      "batch: 100 1760 (1, 136, 13)\n",
      "batch: 200 1602 (1, 159, 13)\n",
      "10 inf 323.74467927217484 254.82341027259827\n",
      "Epoch 2/10, train_cost = inf, train_ler = 323.745, val_cost = inf, val_ler = 8.102, time = 256.877\n",
      "batch: 0 3585 (1, 322, 13)\n",
      "batch: 100 3500 (1, 364, 13)\n",
      "batch: 200 2869 (1, 262, 13)\n",
      "10 inf 281.2521094083786 261.80276584625244\n",
      "Epoch 3/10, train_cost = inf, train_ler = 281.252, val_cost = inf, val_ler = 9.907, time = 263.860\n",
      "batch: 0 521 (1, 220, 13)\n",
      "batch: 100 56 (1, 371, 13)\n",
      "batch: 200 3480 (1, 242, 13)\n",
      "10 inf 271.51636749505997 262.4949402809143\n",
      "Epoch 4/10, train_cost = inf, train_ler = 271.516, val_cost = inf, val_ler = 8.978, time = 264.502\n",
      "batch: 0 1802 (1, 473, 13)\n",
      "batch: 100 3639 (1, 338, 13)\n",
      "batch: 200 2296 (1, 232, 13)\n",
      "10 inf 280.45990282297134 263.12632274627686\n",
      "Epoch 5/10, train_cost = inf, train_ler = 280.460, val_cost = inf, val_ler = 8.829, time = 265.395\n",
      "batch: 0 2358 (1, 407, 13)\n",
      "batch: 100 3390 (1, 263, 13)\n",
      "batch: 200 22 (1, 316, 13)\n",
      "10 inf 295.1415793299675 265.6552610397339\n",
      "Epoch 6/10, train_cost = inf, train_ler = 295.142, val_cost = inf, val_ler = 7.478, time = 267.907\n",
      "batch: 0 1246 (1, 386, 13)\n",
      "batch: 100 2146 (1, 438, 13)\n",
      "batch: 200 196 (1, 320, 13)\n",
      "10 inf 289.6043167710304 262.1061489582062\n",
      "Epoch 7/10, train_cost = inf, train_ler = 289.604, val_cost = inf, val_ler = 7.560, time = 263.973\n",
      "batch: 0 2881 (1, 208, 13)\n",
      "batch: 100 936 (1, 123, 13)\n",
      "batch: 200 2364 (1, 332, 13)\n",
      "10 inf 289.72720462083817 260.90149116516113\n",
      "Epoch 8/10, train_cost = inf, train_ler = 289.727, val_cost = inf, val_ler = 7.989, time = 262.916\n",
      "batch: 0 3956 (1, 318, 13)\n",
      "batch: 100 3153 (1, 301, 13)\n",
      "batch: 200 2671 (1, 454, 13)\n",
      "10 inf 286.9830397963524 263.8738474845886\n",
      "Epoch 9/10, train_cost = inf, train_ler = 286.983, val_cost = inf, val_ler = 7.417, time = 265.832\n",
      "batch: 0 3681 (1, 290, 13)\n",
      "batch: 100 2086 (1, 196, 13)\n",
      "batch: 200 3604 (1, 361, 13)\n",
      "10 inf 306.60292130708694 254.6882176399231\n",
      "Epoch 10/10, train_cost = inf, train_ler = 306.603, val_cost = inf, val_ler = 7.310, time = 256.576\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: zyzyzy\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: yeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyey\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: yeyeyeyeyeyeyeyeyeyeyeyeyjyeyeyeyeyeyey\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: eyeyeyeyeyeyeyeyeyeyeyeyey\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: eyeyeyeyeyeyeyeyeyeyeyeyey\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: zyzyzyzyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyey\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: eyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeyeye\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: y\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: y\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: y\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: eyeyeyeyeyeyeyeyeyeyeyeyey\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: y\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: eyeyeyeyeyeyeyeyeyey\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: y\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: jyeyeyeyeyeyey\n",
      "Original: ['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
      "Decoded: y\n"
     ]
    }
   ],
   "source": [
    "# Configuration to control GPU use\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.33\n",
    "# sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "num_batches_per_epoch = int(len(x_)/batch_size)\n",
    "\n",
    "with tf.Session(graph=graph,config=config) as session:\n",
    "    # Initializate the weights and biases\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    train_epoch = range(num_epochs)\n",
    "    train_edist = []\n",
    "    val_edist = []\n",
    "    \n",
    "    for curr_epoch in range(num_epochs):\n",
    "        train_cost = train_ler = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for batch in range(num_batches_per_epoch//20):\n",
    "            b = int(np.random.randint(len(x_), size=1))\n",
    "            if not batch%100:\n",
    "                print('batch:', batch, b, x_[b].shape)\n",
    "                \n",
    "            feed = {inputs: x_[b],\n",
    "                    targets: y_[b],\n",
    "                    seq_len: [ x_[b].shape[1] ]}\n",
    "\n",
    "            batch_cost, _ = session.run([cost, optimizer], feed)\n",
    "            train_cost += batch_cost*batch_size\n",
    "            train_ler += session.run(ler, feed_dict=feed)*batch_size\n",
    "\n",
    "        train_cost /= num_examples\n",
    "        train_ler /= num_examples\n",
    "        \n",
    "        print(num_epochs, train_cost, train_ler,time.time() - start)\n",
    "        train_edist.append(train_ler)\n",
    "\n",
    "        val_cost, val_ler = 0, 0\n",
    "        for batch in range(len(val_x_)//5):\n",
    "            b = int(np.random.randint(len(val_x_), size=1) )\n",
    "            val_feed = {inputs: val_x_[b],\n",
    "                        targets: val_y_[b],\n",
    "                        seq_len: [val_x_[b].shape[1]]}\n",
    "\n",
    "            val_c, val_l = session.run([cost, ler], feed_dict=val_feed)\n",
    "            val_cost += val_c\n",
    "            val_ler += val_l \n",
    "\n",
    "        log = \"Epoch {}/{}, train_cost = {:.3f}, train_ler = {:.3f}, val_cost = {:.3f}, val_ler = {:.3f}, time = {:.3f}\"\n",
    "        print(log.format(curr_epoch+1, num_epochs, train_cost, train_ler,\n",
    "                         val_cost, val_ler, time.time() - start))\n",
    "        val_edist.append(val_ler)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for batch in range(len(test_x_)//100):\n",
    "        b = int(batch)\n",
    "        test_feed = {inputs: test_x_[b],\n",
    "                        targets: test_y_[b],\n",
    "                        seq_len: [test_x_[b].shape[1]]}\n",
    "            \n",
    "        # Decoding\n",
    "        d = session.run(decoded[0], feed_dict=test_feed)\n",
    "        str_decoded = ''.join([chr(x) for x in np.asarray(d[1]) + FIRST_INDEX])\n",
    "        # Replacing blank label to none\n",
    "        str_decoded = str_decoded.replace(chr(ord('z') + 1), '')\n",
    "        # Replacing space label to space\n",
    "        str_decoded = str_decoded.replace(chr(ord('a') - 1), ' ')\n",
    "\n",
    "        print('Original:', test_text_[b])\n",
    "        print('Decoded:' , str_decoded)\n",
    "        \n",
    "        %matplotlib notebook\n",
    "        plt.figure()\n",
    "        plt.plot(train_epoch, train_edist, 'r-')\n",
    "        plt.plot(train_epoch, val_edist, 'b-')\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(right=0.8) \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
