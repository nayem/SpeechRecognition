{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn.python.ops import core_rnn_cell_impl\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.contrib.rnn import RNNCell\n",
    "import time\n",
    "\n",
    "_BIAS_VARIABLE_NAME = \"biases\"\n",
    "_WEIGHTS_VARIABLE_NAME = \"weights\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(core_rnn_cell_impl.RNNCell):\n",
    "  \"\"\"Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078).\n",
    "  Args:\n",
    "    num_units: int, The number of units in the GRU cell.\n",
    "    activation: Nonlinearity to use.  Default: `tanh`.\n",
    "    reuse: (optional) Python boolean describing whether to reuse variables\n",
    "     in an existing scope.  If not `True`, and the existing scope already has\n",
    "     the given variables, an error is raised.\n",
    "    kernel_initializer: (optional) The initializer to use for the weight and\n",
    "    projection matrices.\n",
    "    bias_initializer: (optional) The initializer to use for the bias.\n",
    "    name: String, the name of the layer. Layers with the same name will\n",
    "      share weights, but to avoid mistakes we require reuse=True in such\n",
    "      cases.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               num_units,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               kernel_initializer=None,\n",
    "               bias_initializer=None,\n",
    "               name=None):\n",
    "    super(GRUCell, self).__init__(_reuse=reuse, name=name)\n",
    "\n",
    "    # Inputs must be 2-dimensional.\n",
    "    self.input_spec = base_layer.InputSpec(ndim=2)\n",
    "\n",
    "    self._num_units = num_units\n",
    "    self._activation = activation or math_ops.tanh\n",
    "    self._kernel_initializer = kernel_initializer\n",
    "    self._bias_initializer = bias_initializer\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  def build(self, inputs_shape):\n",
    "    if inputs_shape[1].value is None:\n",
    "      raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\"\n",
    "                       % inputs_shape)\n",
    "\n",
    "    input_depth = inputs_shape[1].value\n",
    "    self._gate_kernel = self.add_variable(\n",
    "        \"gates/%s\" % _WEIGHTS_VARIABLE_NAME,\n",
    "        shape=[input_depth + self._num_units, 2 * self._num_units],\n",
    "        initializer=self._kernel_initializer)\n",
    "    self._gate_bias = self.add_variable(\n",
    "        \"gates/%s\" % _BIAS_VARIABLE_NAME,\n",
    "        shape=[2 * self._num_units],\n",
    "        initializer=(\n",
    "            self._bias_initializer\n",
    "            if self._bias_initializer is not None\n",
    "            else init_ops.constant_initializer(1.0, dtype=self.dtype)))\n",
    "    self._candidate_kernel = self.add_variable(\n",
    "        \"candidate/%s\" % _WEIGHTS_VARIABLE_NAME,\n",
    "        shape=[input_depth + self._num_units, self._num_units],\n",
    "        initializer=self._kernel_initializer)\n",
    "    self._candidate_bias = self.add_variable(\n",
    "        \"candidate/%s\" % _BIAS_VARIABLE_NAME,\n",
    "        shape=[self._num_units],\n",
    "        initializer=(\n",
    "            self._bias_initializer\n",
    "            if self._bias_initializer is not None\n",
    "            else init_ops.zeros_initializer(dtype=self.dtype)))\n",
    "\n",
    "    self.built = True\n",
    "\n",
    "  def call(self, inputs, state):\n",
    "    \"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"\n",
    "\n",
    "    gate_inputs = math_ops.matmul(\n",
    "        array_ops.concat([inputs, state], 1), self._gate_kernel)\n",
    "    gate_inputs = nn_ops.bias_add(gate_inputs, self._gate_bias)\n",
    "\n",
    "    value = math_ops.sigmoid(gate_inputs)\n",
    "    r, u = array_ops.split(value=value, num_or_size_splits=2, axis=1)\n",
    "\n",
    "    r_state = r * state\n",
    "\n",
    "    candidate = math_ops.matmul(\n",
    "        array_ops.concat([inputs, r_state], 1), self._candidate_kernel)\n",
    "    candidate = nn_ops.bias_add(candidate, self._candidate_bias)\n",
    "\n",
    "    c = self._activation(candidate)\n",
    "    new_h = u * state + (1 - u) * c\n",
    "    return new_h, new_h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    \n",
    "batch_sz = 8\n",
    "n_timesteps = 12\n",
    "n_hidden = 512\n",
    "n_inputs = 513 #f\n",
    "n_outputs = n_inputs\n",
    "\n",
    "def build_gru_single_layer():\n",
    "    reset_graph()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, n_timesteps, n_inputs])\n",
    "    y = tf.placeholder(tf.float32, [None, n_timesteps, n_outputs])\n",
    "    init_state = tf.placeholder(tf.float32, [None, n_hidden])\n",
    "\n",
    "    # Unpack columns\n",
    "    rnn_inputs = tf.unstack(x, axis=1) # <b arrays of shape (t,f)>. Converted like this for iteration\n",
    "    rnn_target_outputs = tf.unstack(y, axis=1) # <b arrays of shape (t,o)>\n",
    "\n",
    "\n",
    "    gru_cell = GRUCell(n_hidden)\n",
    "    hidden_l1_outputs, hidden_l1_final_state = tf.contrib.rnn.static_rnn(gru_cell, rnn_inputs, \n",
    "                                                                         initial_state=init_state)\n",
    "    \n",
    "\n",
    "    with tf.variable_scope('output_layer'):\n",
    "        W_hy = tf.get_variable('W_hy', [n_hidden, n_outputs])\n",
    "        b_y = tf.get_variable('b_y', [n_outputs], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    pre_activation_outputs = [tf.matmul(hidden_l1_output, W_hy) + b_y for hidden_l1_output in hidden_l1_outputs]\n",
    "    post_activation_outputs = [tf.nn.sigmoid(pre_activation_output) for pre_activation_output in pre_activation_outputs]\n",
    "    post_activation_outputs = tf.stack(post_activation_outputs, axis=1) # <n, t, o>\n",
    "\n",
    "    squared_losses = tf.pow(tf.subtract(y, post_activation_outputs), 2) # <n,t,o>\n",
    "    sum_of_squared_losses = tf.reduce_mean(squared_losses)\n",
    "    optimizer = tf.train.AdagradOptimizer(0.1).minimize(sum_of_squared_losses)\n",
    "\n",
    "    return dict(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        init_state = init_state,\n",
    "        predictions = post_activation_outputs,\n",
    "        total_loss = sum_of_squared_losses,\n",
    "        optimizer = optimizer\n",
    "    )\n",
    "\n",
    "def test_weight_compressed_gru():\n",
    "    # Build Computational Graph\n",
    "\n",
    "    t = time.time()\n",
    "    g = build_gru_single_layer()\n",
    "    print(\"It took\", time.time() - t, \"seconds to build the graph.\")\n",
    "    for item in tf.trainable_variables():\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes no parameters",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d8ae64bc81b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-1f630665da05>\u001b[0m in \u001b[0;36mtest_gru\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_gru_single_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"It took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds to build the graph.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-3155ee3abe28>\u001b[0m in \u001b[0;36mbuild_gru_single_layer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mgru_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     hidden_l1_outputs, hidden_l1_final_state = tf.contrib.rnn.static_rnn(gru_cell, rnn_inputs, \n\u001b[1;32m     27\u001b[0m                                                                          initial_state=init_state)\n",
      "\u001b[0;32m<ipython-input-18-df358a28d873>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_units, activation, reuse, kernel_initializer, bias_initializer, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m                \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                name=None):\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRUCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Inputs must be 2-dimensional.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes no parameters"
     ]
    }
   ],
   "source": [
    "test_gru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
