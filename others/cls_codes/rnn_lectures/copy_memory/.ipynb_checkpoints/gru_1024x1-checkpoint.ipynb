{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from CopyMemoryDataset import CopyMemoryProbs\n",
    "import IPython.display as ipd\n",
    "import glob\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100) (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "n_train_samples = 10000\n",
    "n_test_samples = 1000\n",
    "n_train_seq = 100\n",
    "batch_sz = 10\n",
    "n_hidden = 128\n",
    "n_inputs = 1 #f\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "cm_dataset = CopyMemoryProbs(n_train_samples, n_train_seq, n_classes).generate_data()\n",
    "cm_dataset_test = CopyMemoryProbs(n_test_samples, n_train_seq, n_classes).generate_data()\n",
    "\n",
    "x_train = np.squeeze(cm_dataset[0], axis=2)\n",
    "y_train = np.squeeze(cm_dataset[1], axis=2)\n",
    "\n",
    "x_test = np.squeeze(cm_dataset_test[0], axis=2)\n",
    "y_test = np.squeeze(cm_dataset_test[1], axis=2) \n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_truncated_gaussian_weights(shape, name):\n",
    "    return tf.Variable(tf.truncated_normal(shape, mean=0., stddev=1.), name=name)\n",
    "\n",
    "def define_uniform_weights(shape, name):\n",
    "    return tf.Variable(tf.random_uniform(shape, -1, 1), name=name)\n",
    "\n",
    "def define_xavier_weights(shape, name):\n",
    "    w_init = np.sqrt(6./(shape[0]+shape[1]))\n",
    "    return tf.Variable(tf.random_uniform(shape, -w_init, w_init), name=name)\n",
    "\n",
    "def define_constant_weights(shape, name):\n",
    "    return tf.Variable(tf.constant(0.01), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder('int32', [batch_sz, n_train_seq], name='x') # Each of them is a scalar\n",
    "y = tf.placeholder('int64', [batch_sz, n_train_seq], name='y')\n",
    "\n",
    "x_oh = tf.one_hot(x, depth=n_classes, dtype='float32')\n",
    "\n",
    "# I/P -> Hidden\n",
    "gru_cell = tf.contrib.rnn.GRUCell(n_hidden)\n",
    "h_out, _ = tf.nn.dynamic_rnn(gru_cell, x_oh, dtype='float32')\n",
    "\n",
    "# Hidden -> O/P\n",
    "W_output = define_xavier_weights([n_hidden, n_classes], 'W_output')\n",
    "b_output = define_constant_weights([n_classes], 'b_output')\n",
    "\n",
    "def output_step(state):\n",
    "    return tf.matmul(state, W_output) + b_output\n",
    "\n",
    "y_pred_oh = tf.map_fn(fn = output_step, \n",
    "                   elems = h_out,\n",
    "                   name = 'output_step')\n",
    "\n",
    "y_pred = tf.argmax(y_pred_oh, 2)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pred_oh, labels=y))\n",
    "correct_pred = tf.equal(y_pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, 'float32'))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.89, beta2=0.94).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..... Training\n",
      "Epoch 0\n",
      "\tTraining Error: 0.8713966608047485,  Train Accuracy: 64.65550065040588\n",
      "Orig_y: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 5 8 3 2 3 4 6 1 2 8 5 1 7\n",
      " 6 8 5 1 2 2 4 8 3 7 3 7 1 2 4 4 3 1 2 6 1 8 7 8 8 4]\n",
      "Pred_y: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 6 1 1 1 1 1 6 6 6 6 6 6 6\n",
      " 6 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\tTest Error: 0.8334941864013672,  Test Accuracy: 64.97600078582764\n",
      "Epoch 1\n",
      "\tTraining Error: 0.8339499831199646,  Train Accuracy: 65.04110097885132\n",
      "Epoch 2\n",
      "\tTraining Error: 0.8218659162521362,  Train Accuracy: 65.93199968338013\n",
      "Epoch 3\n",
      "\tTraining Error: 0.8011791706085205,  Train Accuracy: 67.3054039478302\n",
      "Epoch 4\n",
      "\tTraining Error: 0.7895611524581909,  Train Accuracy: 67.79959797859192\n",
      "Epoch 5\n",
      "\tTraining Error: 0.7793830633163452,  Train Accuracy: 68.59820485115051\n",
      "Epoch 6\n",
      "\tTraining Error: 0.7622398734092712,  Train Accuracy: 69.31489706039429\n",
      "Epoch 7\n",
      "\tTraining Error: 0.7473620176315308,  Train Accuracy: 69.9112057685852\n",
      "Epoch 8\n",
      "\tTraining Error: 0.7361927628517151,  Train Accuracy: 70.3434944152832\n",
      "Epoch 9\n",
      "\tTraining Error: 0.7247101068496704,  Train Accuracy: 70.83380222320557\n",
      "Epoch 10\n",
      "\tTraining Error: 0.7147903442382812,  Train Accuracy: 71.33609652519226\n",
      "\tTest Error: 0.7089705467224121,  Test Accuracy: 71.50099873542786\n",
      "Epoch 11\n",
      "\tTraining Error: 0.7033255696296692,  Train Accuracy: 71.7928946018219\n",
      "Epoch 12\n",
      "\tTraining Error: 0.6925727725028992,  Train Accuracy: 72.17569351196289\n",
      "Epoch 13\n",
      "\tTraining Error: 0.6861580610275269,  Train Accuracy: 72.41469621658325\n",
      "Epoch 14\n",
      "\tTraining Error: 0.6790382266044617,  Train Accuracy: 72.67249822616577\n",
      "Epoch 15\n",
      "\tTraining Error: 0.6713128089904785,  Train Accuracy: 72.93750047683716\n",
      "Epoch 16\n",
      "\tTraining Error: 0.6660716533660889,  Train Accuracy: 73.14110398292542\n",
      "Epoch 17\n",
      "\tTraining Error: 0.6597786545753479,  Train Accuracy: 73.34310412406921\n",
      "Epoch 18\n",
      "\tTraining Error: 0.6543934345245361,  Train Accuracy: 73.55470061302185\n",
      "Epoch 19\n",
      "\tTraining Error: 0.6490311622619629,  Train Accuracy: 73.72750043869019\n",
      "Epoch 20\n",
      "\tTraining Error: 0.6443890929222107,  Train Accuracy: 73.92839193344116\n",
      "\tTest Error: 0.6363343000411987,  Test Accuracy: 74.07800555229187\n",
      "Epoch 21\n",
      "\tTraining Error: 0.6378142237663269,  Train Accuracy: 74.1424024105072\n",
      "Epoch 22\n",
      "\tTraining Error: 0.6327753663063049,  Train Accuracy: 74.34219717979431\n",
      "Epoch 23\n",
      "\tTraining Error: 0.629883885383606,  Train Accuracy: 74.47929978370667\n",
      "Epoch 24\n",
      "\tTraining Error: 0.6249719262123108,  Train Accuracy: 74.61730241775513\n",
      "Epoch 25\n",
      "\tTraining Error: 0.6199573874473572,  Train Accuracy: 74.81350302696228\n",
      "Epoch 26\n",
      "\tTraining Error: 0.6160992980003357,  Train Accuracy: 74.95690584182739\n",
      "Epoch 27\n",
      "\tTraining Error: 0.6110106110572815,  Train Accuracy: 75.13459324836731\n",
      "Epoch 28\n",
      "\tTraining Error: 0.6067038178443909,  Train Accuracy: 75.29140710830688\n",
      "Epoch 29\n",
      "\tTraining Error: 0.6015583276748657,  Train Accuracy: 75.4601001739502\n",
      "Epoch 30\n",
      "\tTraining Error: 0.5968973636627197,  Train Accuracy: 75.63359141349792\n",
      "\tTest Error: 0.5988880395889282,  Test Accuracy: 75.52899122238159\n",
      "Epoch 31\n",
      "\tTraining Error: 0.5928198099136353,  Train Accuracy: 75.76209902763367\n",
      "Epoch 32\n",
      "\tTraining Error: 0.5900797843933105,  Train Accuracy: 75.88909864425659\n",
      "Epoch 33\n",
      "\tTraining Error: 0.5858861207962036,  Train Accuracy: 76.04889869689941\n",
      "Epoch 34\n",
      "\tTraining Error: 0.5835605263710022,  Train Accuracy: 76.1286973953247\n",
      "Epoch 35\n",
      "\tTraining Error: 0.5779933929443359,  Train Accuracy: 76.30659937858582\n",
      "Epoch 36\n",
      "\tTraining Error: 0.5738842487335205,  Train Accuracy: 76.44649744033813\n",
      "Epoch 37\n",
      "\tTraining Error: 0.5711066722869873,  Train Accuracy: 76.54939889907837\n"
     ]
    }
   ],
   "source": [
    "n_train_epochs = 1001\n",
    "test_step = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_epoch_loss = []\n",
    "    train_epoch_acc = []\n",
    "    test_epoch_loss = []\n",
    "    test_epoch_acc = []    \n",
    "    \n",
    "    print('..... Training')\n",
    "    for epoch_idx in range(n_train_epochs):\n",
    "        \n",
    "        minibatch_loss = []\n",
    "        minibatch_acc = []\n",
    "        n_minibatches = n_train_samples // batch_sz\n",
    "        \n",
    "        for batch_idx in range(n_minibatches):\n",
    "            start_idx = batch_idx * batch_sz\n",
    "            end_idx = start_idx + batch_sz\n",
    "            batch_x = x_train[start_idx:end_idx] # <b,t,f>\n",
    "            batch_y = y_train[start_idx:end_idx] # <b,t,o>\n",
    "\n",
    "            _, loss, acc, y_pred_val = sess.run(\n",
    "                [optimizer, cost, accuracy, y_pred],\n",
    "                feed_dict={\n",
    "                    x:batch_x,\n",
    "                    y:batch_y\n",
    "                })\n",
    "            minibatch_loss.append(loss)\n",
    "            minibatch_acc.append(acc)\n",
    "            \n",
    "        train_epoch_loss.append(np.mean(minibatch_loss))\n",
    "        train_epoch_acc.append(np.mean(minibatch_acc)*100)\n",
    "        print (\"Epoch {}\\n\\tTraining Error: {},  Train Accuracy: {}\".format(epoch_idx, train_epoch_loss[-1], train_epoch_acc[-1]))\n",
    "\n",
    "            \n",
    "        if epoch_idx%100==0:\n",
    "#             print('Orig_x:', batch_x[0].astype(np.int32))\n",
    "            print('Orig_y:', batch_y[0].astype(np.int32))\n",
    "            print('Pred_y:', y_pred_val[0])\n",
    "        \n",
    "        \n",
    "        if epoch_idx % test_step == 0:\n",
    "            minibatch_loss = []\n",
    "            minibatch_acc = []\n",
    "            n_minibatches = n_test_samples // batch_sz   \n",
    "            \n",
    "            for batch_idx in range(n_minibatches):\n",
    "                start_idx = batch_idx * batch_sz\n",
    "                end_idx = start_idx + batch_sz\n",
    "                batch_x = x_test[start_idx:end_idx] # <b,t,f>\n",
    "                batch_y = y_test[start_idx:end_idx] # <b,t,o>\n",
    "\n",
    "                loss, acc, y_pred_val = sess.run(\n",
    "                    [cost, accuracy, y_pred],\n",
    "                    feed_dict={\n",
    "                        x:batch_x,\n",
    "                        y:batch_y\n",
    "                    })\n",
    "                minibatch_loss.append(loss)\n",
    "                minibatch_acc.append(acc)\n",
    "                \n",
    "            test_epoch_loss.append(np.mean(minibatch_loss))\n",
    "            test_epoch_acc.append(np.mean(minibatch_acc)*100)\n",
    "                    \n",
    "\n",
    "            print (\"\\tTest Error: {},  Test Accuracy: {}\".format(test_epoch_loss[-1], test_epoch_acc[-1]))\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_epoch_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_epoch_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
