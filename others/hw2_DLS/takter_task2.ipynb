{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hw-2: Task 2\n",
    "### Taslima Akter\n",
    "### ID: takter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file names for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/e533/timit-homework/tr/trx0100.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### File names for Training Data\n",
    "\n",
    "import glob\n",
    "import librosa\n",
    "fname_trn=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/tr/trn*.wav'):\n",
    "    (fname_trn.append(filename))\n",
    "fname_trn.sort()\n",
    "# fname_trn\n",
    "\n",
    "fname_trs=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/tr/trs*.wav'):\n",
    "    (fname_trs.append(filename))\n",
    "fname_trs.sort()\n",
    "# fname_trs\n",
    "\n",
    "fname_trx=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/tr/trx*.wav'):\n",
    "    (fname_trx.append(filename))\n",
    "fname_trx.sort()\n",
    "fname_trx[100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file names for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### File names for validation Data\n",
    "\n",
    "fname_val_n=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/v/vn*.wav'):\n",
    "    (fname_val_n.append(filename))\n",
    "fname_val_n.sort()\n",
    "# print(fname_val_n)\n",
    "\n",
    "fname_val_s=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/v/vs*.wav'):\n",
    "    (fname_val_s.append(filename))\n",
    "fname_val_s.sort()\n",
    "# fname_trs\n",
    "\n",
    "fname_val_x=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/v/vx*.wav'):\n",
    "    (fname_val_x.append(filename))\n",
    "fname_val_x.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file names for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### File names for Test Data\n",
    "\n",
    "fname_test=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/te/tex*.wav'):\n",
    "    (fname_test.append(filename))\n",
    "fname_test.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data into txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function For writing file\n",
    "import librosa\n",
    "def write_file(file_name, fname_list):\n",
    "    ### Writing training data S\n",
    "\n",
    "    with open(file_name, 'wb') as fs:\n",
    "        for i in range(len(fname_list)):\n",
    "            sn, sr=librosa.load(fname_list[i], sr=None)\n",
    "            Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "            mag_Sn=np.abs(Sn)\n",
    "    #         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "            np.savetxt(fs, mag_Sn, fmt='%.5f')\n",
    "            fs.write(b'\\n')\n",
    "    fs.close()            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing complex data X into file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function For writing just X into file\n",
    "import librosa\n",
    "def write_file_X(file_name, fname_list):\n",
    "    ### Writing training data S\n",
    "\n",
    "    with open(file_name, 'wb') as fs:\n",
    "        for i in range(len(fname_list)):\n",
    "            sn, sr=librosa.load(fname_list[i], sr=None)\n",
    "            Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "#             mag_Sn=np.abs(Sn)\n",
    "    #         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "            np.savetxt(fs, Sn, fmt='%.5f')\n",
    "            fs.write(b'\\n')\n",
    "    fs.close()            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing training data S\n",
    "Train_complx_X=[]\n",
    "\n",
    "def read_complex_data(fname_trx):\n",
    "    Train_complx_X=[]\n",
    "    for i in range(len(fname_trx)):\n",
    "        print(i),\n",
    "\n",
    "        sn, sr=librosa.load(fname_trx[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        Train_complx_X.append(np.array(Sn))\n",
    "    return Train_complx_X\n",
    "\n",
    "\n",
    "#             mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n"
     ]
    }
   ],
   "source": [
    "Train_complx_X=read_complex_data(fname_trx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3853499 +0.0000000e+00j,  0.060454  +0.0000000e+00j,\n",
       "         0.01165429+0.0000000e+00j, ...,  0.01285191+0.0000000e+00j,\n",
       "        -0.21756761+0.0000000e+00j,  0.24008064+0.0000000e+00j],\n",
       "       [ 0.09418306-8.3754618e-18j, -0.23302463+1.5076146e-01j,\n",
       "        -0.08883861-2.4753909e-01j, ...,  0.1361649 +2.1456896e-01j,\n",
       "         0.18064187-2.7819940e-01j, -0.4199345 -7.4127577e-02j],\n",
       "       [ 0.05248116+2.3452779e-17j,  0.6149999 -1.4774410e-01j,\n",
       "         0.04419272+5.4086918e-01j, ..., -0.3379148 -4.0866500e-01j,\n",
       "         0.41280326+2.7587944e-01j,  0.25685748+1.3153780e-01j],\n",
       "       ...,\n",
       "       [ 0.1367664 -2.6360976e-18j, -0.05970686-8.4518110e-03j,\n",
       "         0.00300826+9.1337882e-02j, ..., -0.10093805+2.0822957e-01j,\n",
       "         0.04817577+1.6439554e-01j, -0.12954259+2.0553760e-01j],\n",
       "       [ 0.0008341 +1.3145951e-17j,  0.04312928-2.8533509e-02j,\n",
       "         0.01229421-4.8449092e-02j, ...,  0.04757174-1.0008689e-01j,\n",
       "         0.01047064-5.0540548e-03j,  0.24539188-1.7348814e-01j],\n",
       "       [-0.07608886+0.0000000e+00j, -0.08655041+0.0000000e+00j,\n",
       "        -0.01379778+0.0000000e+00j, ..., -0.02555746+0.0000000e+00j,\n",
       "        -0.08739388+0.0000000e+00j, -0.34622538+0.0000000e+00j]],\n",
       "      dtype=complex64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_complx_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n"
     ]
    }
   ],
   "source": [
    "val_complx_X=read_complex_data(fname_val_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n"
     ]
    }
   ],
   "source": [
    "val_complx_S=read_complex_data(fname_val_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "test_complx_S=read_complex_data(fname_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling functions to write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"train_s.txt\", fname_trs)\n",
    "write_file(\"train_n.txt\", fname_trn)\n",
    "write_file(\"train_x.txt\", fname_trx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write validation files\n",
    "\n",
    "write_file(\"validation_s.txt\", fname_val_s)\n",
    "write_file(\"validation_n.txt\", fname_val_n)\n",
    "write_file(\"validation_x.txt\", fname_val_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file_X(\"train_x_tr.txt\", fname_trx)\n",
    "write_file_X(\"validation_x_tr.txt\", fname_trx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"test_data.txt\", fname_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing training data N\n",
    "import librosa\n",
    "\n",
    "count=0\n",
    "total_train_s=[]\n",
    "with open('train_n.txt', 'wb') as fn:\n",
    "    for i in range(len(fname_trn)):\n",
    "        sn, sr=librosa.load(fname_trn[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "        np.savetxt(fn, mag_Sn, fmt='%.5f')\n",
    "        fn.write(b'\\n')\n",
    "fn.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing training data S\n",
    "\n",
    "with open('train_s.txt', 'wb') as fs:\n",
    "    for i in range(len(fname_trs)):\n",
    "        sn, sr=librosa.load(fname_trs[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "        np.savetxt(fs, mag_Sn, fmt='%.5f')\n",
    "        fs.write(b'\\n')\n",
    "fs.close()            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing training file X\n",
    "\n",
    "with open('train_x.txt', 'wb') as fs:\n",
    "    for i in range(len(fname_trx)):\n",
    "        sn, sr=librosa.load(fname_trx[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "        np.savetxt(fs, mag_Sn, fmt='%.5f')\n",
    "        fs.write(b'\\n')\n",
    "fs.close()            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for Reading file\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name) as f:\n",
    "        lines=f.readlines()\n",
    "        print(len(lines))\n",
    "        sentence_full=[]\n",
    "        count = 0\n",
    "        sentence=[]\n",
    "        for line in lines:\n",
    "\n",
    "            if count < 513:\n",
    "                if count ==0:\n",
    "                    sentence=np.array(np.fromstring(line, dtype=float, sep=' '), ndmin=2)\n",
    "                    count+=1\n",
    "                else:\n",
    "                    myarray = np.array(np.fromstring(line, dtype=float, sep=' '), ndmin=2)\n",
    "                    sentence=np.concatenate((sentence, myarray), axis=0)\n",
    "                    count+=1\n",
    "            else:\n",
    "                sentence_full.append(sentence) \n",
    "                count=0\n",
    "                sentence=[]\n",
    "        return sentence_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616800\n",
      "616800\n",
      "616800\n"
     ]
    }
   ],
   "source": [
    "data_train_n = read_file(\"train_n.txt\")\n",
    "data_train_s = read_file(\"train_s.txt\")\n",
    "data_train_x = read_file(\"train_x.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616800\n",
      "616800\n",
      "616800\n"
     ]
    }
   ],
   "source": [
    "data_val_n = read_file(\"validation_n.txt\")\n",
    "data_val_s = read_file(\"validation_s.txt\")\n",
    "data_val_x = read_file(\"validation_x.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read complex X from training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616800\n",
      "616800\n"
     ]
    }
   ],
   "source": [
    "data_train_xtr = read_file(\"train_x_tr.txt\")\n",
    "data_val_xtr = read_file(\"validation_x_tr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_val_xtr)\n",
    "data_val_xtr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205600\n"
     ]
    }
   ],
   "source": [
    "data_test = read_file(\"test_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating M for training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating M:\n",
    "data_train_M=[]\n",
    "data_val_M=[]\n",
    "for i in range(len(data_train_s)):\n",
    "    data_train_M.append(1*(data_train_s[i]>data_train_n[i]))\n",
    "    data_val_M.append(1*(data_val_s[i]>data_val_n[i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 65)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_M[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batchXSCmplx(X_, S_, X_cmplx, S_cmplx):\n",
    "    \n",
    "    batch_x = None\n",
    "    batch_s = None\n",
    "    batch_x_cmplx = None\n",
    "    batch_s_cmplx = None\n",
    "    \n",
    "    for e,(x, s, x_cmplx, s_cmplx) in enumerate(zip(X_, S_, X_cmplx, S_cmplx)): \n",
    "        batch_x = np.array(x.T) if batch_x is None else np.concatenate( (batch_x,x.T), axis=0)\n",
    "        batch_s = np.array(s.T) if batch_s is None else np.concatenate( (batch_s,s.T), axis=0)\n",
    "        batch_x_cmplx = np.array(x_cmplx.T) if batch_x_cmplx is None else np.concatenate( (batch_x_cmplx,x_cmplx.T), axis=0)\n",
    "        batch_s_cmplx = np.array(s_cmplx.T) if batch_s_cmplx is None else np.concatenate( (batch_s_cmplx,s_cmplx.T), axis=0)\n",
    " \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp_x, batch_x = batch_x, None\n",
    "            temp_s, batch_s = batch_s, None\n",
    "            temp_x_cmplx, batch_x_cmplx = batch_x_cmplx, None\n",
    "            temp_s_cmplx, batch_s_cmplx = batch_s_cmplx, None\n",
    "            \n",
    "            temp_x = temp_x.reshape((-1,Max_RNN,513))\n",
    "            temp_s = temp_s.reshape((-1,Max_RNN,513))\n",
    "            temp_x_cmplx = temp_x_cmplx.reshape((-1,Max_RNN,513))\n",
    "#             temp_s_cmplx = temp_s_cmplx.reshape((-1,Max_RNN,513))\n",
    "\n",
    "            yield temp_x, temp_s, temp_x_cmplx, temp_s_cmplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X_,Y_):\n",
    "    \n",
    "    batch_x, batch_y = None, None\n",
    "    \n",
    "    for e,(x,y) in enumerate(zip(X_,Y_)):\n",
    "#         print(e)\n",
    "        \n",
    "        batch_x = np.array(x.T) if batch_x is None else np.concatenate( (batch_x,x.T), axis=0)\n",
    "        batch_y = np.array(y.T) if batch_y is None else np.concatenate( (batch_y,y.T), axis=0)\n",
    "        \n",
    "#         print('batch_x',batch_x.shape)\n",
    "#         print('batch_y',batch_y.shape)\n",
    "        \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp_x, batch_x = batch_x, None\n",
    "            temp_y, batch_y = batch_y, None\n",
    "            \n",
    "            temp_x = temp_x.reshape((-1,Max_RNN,513))\n",
    "            temp_y = temp_y.reshape((-1,Max_RNN,513))\n",
    "\n",
    "#             print('temp_x',temp_x.shape)\n",
    "#             print('temp_y',temp_y.shape)\n",
    "        \n",
    "            yield temp_x,temp_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 5, 10)             15570     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 10)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 5, 10)             480       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5, 513)            5643      \n",
      "=================================================================\n",
      "Total params: 21,693\n",
      "Trainable params: 21,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.6931 - acc: 0.5061 - val_loss: 0.6927 - val_acc: 0.5190\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 562us/step - loss: 0.6924 - acc: 0.5265 - val_loss: 0.6921 - val_acc: 0.5245\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 626us/step - loss: 0.6906 - acc: 0.5534 - val_loss: 0.6904 - val_acc: 0.5389\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 665us/step - loss: 0.6899 - acc: 0.5548 - val_loss: 0.6906 - val_acc: 0.5227\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 549us/step - loss: 0.6892 - acc: 0.5455 - val_loss: 0.6886 - val_acc: 0.5432\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 668us/step - loss: 0.6856 - acc: 0.5896 - val_loss: 0.6891 - val_acc: 0.5316\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 558us/step - loss: 0.6867 - acc: 0.5620 - val_loss: 0.6841 - val_acc: 0.5860\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 524us/step - loss: 0.6862 - acc: 0.5658 - val_loss: 0.6869 - val_acc: 0.5414\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 623us/step - loss: 0.6845 - acc: 0.5828 - val_loss: 0.6858 - val_acc: 0.5572\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 637us/step - loss: 0.6865 - acc: 0.5587 - val_loss: 0.6941 - val_acc: 0.4871\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 525us/step - loss: 0.6929 - acc: 0.5053 - val_loss: 0.6954 - val_acc: 0.4815\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 680us/step - loss: 0.6784 - acc: 0.6061 - val_loss: 0.6876 - val_acc: 0.5290\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 670us/step - loss: 0.6814 - acc: 0.5860 - val_loss: 0.6821 - val_acc: 0.5660\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 589us/step - loss: 0.6753 - acc: 0.6233 - val_loss: 0.6815 - val_acc: 0.5598\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 585us/step - loss: 0.6885 - acc: 0.5424 - val_loss: 0.6970 - val_acc: 0.4831\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 608us/step - loss: 0.6743 - acc: 0.6030 - val_loss: 0.6755 - val_acc: 0.5750\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 666us/step - loss: 0.6858 - acc: 0.5465 - val_loss: 0.7081 - val_acc: 0.4208\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 494us/step - loss: 0.6879 - acc: 0.5264 - val_loss: 0.6827 - val_acc: 0.5537\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 658us/step - loss: 0.6781 - acc: 0.5779 - val_loss: 0.6818 - val_acc: 0.5360\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 608us/step - loss: 0.6762 - acc: 0.5767 - val_loss: 0.6829 - val_acc: 0.5390\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 692us/step - loss: 0.6803 - acc: 0.5750 - val_loss: 0.6766 - val_acc: 0.5738\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 577us/step - loss: 0.6855 - acc: 0.5577 - val_loss: 0.6867 - val_acc: 0.5276\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 506us/step - loss: 0.6776 - acc: 0.5978 - val_loss: 0.6563 - val_acc: 0.6606\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 583us/step - loss: 0.6657 - acc: 0.6381 - val_loss: 0.6716 - val_acc: 0.5900\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 574us/step - loss: 0.6740 - acc: 0.5991 - val_loss: 0.6645 - val_acc: 0.6040\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 536us/step - loss: 0.6729 - acc: 0.6141 - val_loss: 0.6713 - val_acc: 0.5838\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 700us/step - loss: 0.6753 - acc: 0.5755 - val_loss: 0.6845 - val_acc: 0.5331\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 541us/step - loss: 0.6693 - acc: 0.6204 - val_loss: 0.6714 - val_acc: 0.5969\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 692us/step - loss: 0.6708 - acc: 0.6080 - val_loss: 0.6718 - val_acc: 0.5827\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 537us/step - loss: 0.6586 - acc: 0.6244 - val_loss: 0.6603 - val_acc: 0.6108\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 578us/step - loss: 0.6564 - acc: 0.6393 - val_loss: 0.6665 - val_acc: 0.5920\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 587us/step - loss: 0.6717 - acc: 0.5818 - val_loss: 0.6723 - val_acc: 0.5740\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 766us/step - loss: 0.6698 - acc: 0.5977 - val_loss: 0.6623 - val_acc: 0.6102\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 647us/step - loss: 0.6644 - acc: 0.5836 - val_loss: 0.6691 - val_acc: 0.5703\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 537us/step - loss: 0.6916 - acc: 0.5091 - val_loss: 0.6857 - val_acc: 0.5137\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 505us/step - loss: 0.6520 - acc: 0.6357 - val_loss: 0.6559 - val_acc: 0.5973\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 750us/step - loss: 0.6587 - acc: 0.5961 - val_loss: 0.6506 - val_acc: 0.6179\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.6576 - acc: 0.5973 - val_loss: 0.6587 - val_acc: 0.5807\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 660us/step - loss: 0.6691 - acc: 0.5609 - val_loss: 0.6581 - val_acc: 0.5745\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 668us/step - loss: 0.6437 - acc: 0.6800 - val_loss: 0.6296 - val_acc: 0.6834\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 665us/step - loss: 0.6755 - acc: 0.5626 - val_loss: 0.6956 - val_acc: 0.4989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 618us/step - loss: 0.6780 - acc: 0.5568 - val_loss: 0.6727 - val_acc: 0.5555\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 573us/step - loss: 0.6564 - acc: 0.6346 - val_loss: 0.6681 - val_acc: 0.5638\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 553us/step - loss: 0.6554 - acc: 0.6167 - val_loss: 0.6622 - val_acc: 0.5848\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 644us/step - loss: 0.6869 - acc: 0.5014 - val_loss: 0.6725 - val_acc: 0.5514\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 550us/step - loss: 0.6616 - acc: 0.5784 - val_loss: 0.6545 - val_acc: 0.6066\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 641us/step - loss: 0.6636 - acc: 0.5889 - val_loss: 0.6654 - val_acc: 0.5803\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 536us/step - loss: 0.6536 - acc: 0.6317 - val_loss: 0.6551 - val_acc: 0.6153\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 545us/step - loss: 0.6601 - acc: 0.6060 - val_loss: 0.6593 - val_acc: 0.5793\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 643us/step - loss: 0.6593 - acc: 0.5953 - val_loss: 0.6529 - val_acc: 0.6192\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 540us/step - loss: 0.6974 - acc: 0.4968 - val_loss: 0.6972 - val_acc: 0.4955\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 675us/step - loss: 0.6798 - acc: 0.5239 - val_loss: 0.6782 - val_acc: 0.5316\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 488us/step - loss: 0.6724 - acc: 0.5777 - val_loss: 0.6817 - val_acc: 0.5427\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 548us/step - loss: 0.6754 - acc: 0.5757 - val_loss: 0.6755 - val_acc: 0.5804\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 658us/step - loss: 0.6739 - acc: 0.5831 - val_loss: 0.6751 - val_acc: 0.5993\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 676us/step - loss: 0.6719 - acc: 0.6133 - val_loss: 0.6718 - val_acc: 0.5977\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 593us/step - loss: 0.6700 - acc: 0.6251 - val_loss: 0.6761 - val_acc: 0.5945\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 568us/step - loss: 0.6726 - acc: 0.6046 - val_loss: 0.6606 - val_acc: 0.6292\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 611us/step - loss: 0.6628 - acc: 0.6228 - val_loss: 0.6677 - val_acc: 0.5995\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 761us/step - loss: 0.6598 - acc: 0.6307 - val_loss: 0.6633 - val_acc: 0.5915\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 614us/step - loss: 0.6661 - acc: 0.6187 - val_loss: 0.6753 - val_acc: 0.5581\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 615us/step - loss: 0.6333 - acc: 0.6956 - val_loss: 0.6446 - val_acc: 0.6333\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 574us/step - loss: 0.6702 - acc: 0.5903 - val_loss: 0.6765 - val_acc: 0.5679\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 599us/step - loss: 0.6477 - acc: 0.6424 - val_loss: 0.6497 - val_acc: 0.6232\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 723us/step - loss: 0.6667 - acc: 0.5878 - val_loss: 0.6418 - val_acc: 0.6326\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 495us/step - loss: 0.6475 - acc: 0.6117 - val_loss: 0.6565 - val_acc: 0.6012\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 592us/step - loss: 0.6720 - acc: 0.5805 - val_loss: 0.6650 - val_acc: 0.5869\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 520us/step - loss: 0.6594 - acc: 0.5980 - val_loss: 0.6434 - val_acc: 0.6233\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 563us/step - loss: 0.6672 - acc: 0.5942 - val_loss: 0.6684 - val_acc: 0.5964\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 548us/step - loss: 0.6274 - acc: 0.6860 - val_loss: 0.6276 - val_acc: 0.6951\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 542us/step - loss: 0.6477 - acc: 0.6468 - val_loss: 0.6317 - val_acc: 0.6812\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 684us/step - loss: 0.6379 - acc: 0.6721 - val_loss: 0.6481 - val_acc: 0.6476\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 661us/step - loss: 0.6423 - acc: 0.6757 - val_loss: 0.6354 - val_acc: 0.6602\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 653us/step - loss: 0.6263 - acc: 0.6973 - val_loss: 0.6295 - val_acc: 0.6925\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 559us/step - loss: 0.6122 - acc: 0.7076 - val_loss: 0.6294 - val_acc: 0.6563\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 615us/step - loss: 0.6798 - acc: 0.5656 - val_loss: 0.6488 - val_acc: 0.6196\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 531us/step - loss: 0.6470 - acc: 0.6231 - val_loss: 0.6334 - val_acc: 0.6570\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 643us/step - loss: 0.6234 - acc: 0.6716 - val_loss: 0.6408 - val_acc: 0.6608\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 663us/step - loss: 0.6149 - acc: 0.6608 - val_loss: 0.6299 - val_acc: 0.6629\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 555us/step - loss: 0.6354 - acc: 0.6344 - val_loss: 0.6551 - val_acc: 0.6133\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 631us/step - loss: 0.6916 - acc: 0.5667 - val_loss: 0.6956 - val_acc: 0.5525\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 838us/step - loss: 0.6727 - acc: 0.5727 - val_loss: 0.6477 - val_acc: 0.6084\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 499us/step - loss: 0.6671 - acc: 0.5891 - val_loss: 0.6484 - val_acc: 0.6409\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 750us/step - loss: 0.6629 - acc: 0.6295 - val_loss: 0.6651 - val_acc: 0.5792\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 628us/step - loss: 0.6626 - acc: 0.6134 - val_loss: 0.6625 - val_acc: 0.5902\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 579us/step - loss: 0.6692 - acc: 0.5837 - val_loss: 0.6627 - val_acc: 0.5955\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 762us/step - loss: 0.6780 - acc: 0.5666 - val_loss: 0.6585 - val_acc: 0.5988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 592us/step - loss: 0.6902 - acc: 0.5400 - val_loss: 0.6604 - val_acc: 0.6101\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 669us/step - loss: 0.6510 - acc: 0.6290 - val_loss: 0.6529 - val_acc: 0.6234\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 577us/step - loss: 0.6651 - acc: 0.5727 - val_loss: 0.6542 - val_acc: 0.6240\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 640us/step - loss: 0.6822 - acc: 0.5617 - val_loss: 0.6774 - val_acc: 0.5806\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 656us/step - loss: 0.6466 - acc: 0.6504 - val_loss: 0.6524 - val_acc: 0.6153\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 558us/step - loss: 0.6510 - acc: 0.6351 - val_loss: 0.6547 - val_acc: 0.6106\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 630us/step - loss: 0.6445 - acc: 0.6652 - val_loss: 0.6299 - val_acc: 0.7102\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 549us/step - loss: 0.6552 - acc: 0.6362 - val_loss: 0.6506 - val_acc: 0.6277\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 628us/step - loss: 0.6436 - acc: 0.6459 - val_loss: 0.6307 - val_acc: 0.6795\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 610us/step - loss: 0.6374 - acc: 0.6560 - val_loss: 0.6208 - val_acc: 0.6920\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 680us/step - loss: 0.6331 - acc: 0.6802 - val_loss: 0.6306 - val_acc: 0.6666\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 642us/step - loss: 0.6362 - acc: 0.6557 - val_loss: 0.6220 - val_acc: 0.7026\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 630us/step - loss: 0.6233 - acc: 0.6885 - val_loss: 0.5989 - val_acc: 0.7287\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 492us/step - loss: 0.6411 - acc: 0.6289 - val_loss: 0.6182 - val_acc: 0.6740\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 707us/step - loss: 0.6436 - acc: 0.6280 - val_loss: 0.6551 - val_acc: 0.6065\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 517us/step - loss: 0.6435 - acc: 0.6276 - val_loss: 0.6261 - val_acc: 0.6597\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 522us/step - loss: 0.6330 - acc: 0.6523 - val_loss: 0.6285 - val_acc: 0.6562\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 494us/step - loss: 0.6199 - acc: 0.6811 - val_loss: 0.6183 - val_acc: 0.6779\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 622us/step - loss: 0.6097 - acc: 0.6913 - val_loss: 0.6102 - val_acc: 0.6940\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 491us/step - loss: 0.6298 - acc: 0.6440 - val_loss: 0.6254 - val_acc: 0.6585\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 594us/step - loss: 0.6678 - acc: 0.6047 - val_loss: 0.6570 - val_acc: 0.6257\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 517us/step - loss: 0.6176 - acc: 0.6771 - val_loss: 0.6101 - val_acc: 0.6960\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 581us/step - loss: 0.6233 - acc: 0.6589 - val_loss: 0.5859 - val_acc: 0.7215\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 593us/step - loss: 0.6312 - acc: 0.6304 - val_loss: 0.6020 - val_acc: 0.6983\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 603us/step - loss: 0.6554 - acc: 0.6110 - val_loss: 0.6346 - val_acc: 0.6590\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 576us/step - loss: 0.6352 - acc: 0.6431 - val_loss: 0.6078 - val_acc: 0.6910\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 607us/step - loss: 0.6031 - acc: 0.6955 - val_loss: 0.5885 - val_acc: 0.6981\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.5957 - acc: 0.7107 - val_loss: 0.6103 - val_acc: 0.6798\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 566us/step - loss: 0.5920 - acc: 0.7038 - val_loss: 0.5815 - val_acc: 0.7245\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 473us/step - loss: 0.6254 - acc: 0.6613 - val_loss: 0.6046 - val_acc: 0.6904\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 611us/step - loss: 0.6452 - acc: 0.6441 - val_loss: 0.6254 - val_acc: 0.6701\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 584us/step - loss: 0.6059 - acc: 0.6820 - val_loss: 0.6024 - val_acc: 0.6688\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 606us/step - loss: 0.6345 - acc: 0.6384 - val_loss: 0.6073 - val_acc: 0.6775\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.5670 - acc: 0.7265 - val_loss: 0.5969 - val_acc: 0.6798\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 629us/step - loss: 0.6183 - acc: 0.6668 - val_loss: 0.5998 - val_acc: 0.6997\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 702us/step - loss: 0.5980 - acc: 0.6888 - val_loss: 0.6152 - val_acc: 0.6660\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 737us/step - loss: 0.6045 - acc: 0.6774 - val_loss: 0.6203 - val_acc: 0.6603\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 505us/step - loss: 0.6018 - acc: 0.6851 - val_loss: 0.6239 - val_acc: 0.6465\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 650us/step - loss: 0.5762 - acc: 0.7138 - val_loss: 0.6151 - val_acc: 0.6619\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 543us/step - loss: 0.6142 - acc: 0.6562 - val_loss: 0.5988 - val_acc: 0.6828\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 514us/step - loss: 0.6328 - acc: 0.6337 - val_loss: 0.6171 - val_acc: 0.6683\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 562us/step - loss: 0.6134 - acc: 0.6488 - val_loss: 0.6054 - val_acc: 0.6705\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 562us/step - loss: 0.6330 - acc: 0.6468 - val_loss: 0.6253 - val_acc: 0.6792\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 527us/step - loss: 0.6680 - acc: 0.5950 - val_loss: 0.6221 - val_acc: 0.6663\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 666us/step - loss: 0.6325 - acc: 0.6455 - val_loss: 0.6265 - val_acc: 0.6606\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 573us/step - loss: 0.6209 - acc: 0.6714 - val_loss: 0.5926 - val_acc: 0.6929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 573us/step - loss: 0.6194 - acc: 0.6541 - val_loss: 0.6171 - val_acc: 0.6577\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 636us/step - loss: 0.6703 - acc: 0.5984 - val_loss: 0.6349 - val_acc: 0.6457\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 625us/step - loss: 0.5974 - acc: 0.7016 - val_loss: 0.5755 - val_acc: 0.7238\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 614us/step - loss: 0.6445 - acc: 0.6251 - val_loss: 0.6603 - val_acc: 0.6374\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 510us/step - loss: 0.6133 - acc: 0.6768 - val_loss: 0.6060 - val_acc: 0.6920\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 645us/step - loss: 0.6259 - acc: 0.6564 - val_loss: 0.5869 - val_acc: 0.7257\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 607us/step - loss: 0.6048 - acc: 0.6843 - val_loss: 0.6160 - val_acc: 0.6743\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 629us/step - loss: 0.6047 - acc: 0.6762 - val_loss: 0.6075 - val_acc: 0.6888\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 550us/step - loss: 0.6604 - acc: 0.5959 - val_loss: 0.6450 - val_acc: 0.6179\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 528us/step - loss: 0.6467 - acc: 0.6064 - val_loss: 0.5748 - val_acc: 0.7185\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 537us/step - loss: 0.6231 - acc: 0.6550 - val_loss: 0.5837 - val_acc: 0.7279\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 550us/step - loss: 0.6268 - acc: 0.6316 - val_loss: 0.5741 - val_acc: 0.7346\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 493us/step - loss: 0.6239 - acc: 0.6456 - val_loss: 0.5712 - val_acc: 0.7387\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 696us/step - loss: 0.6007 - acc: 0.6883 - val_loss: 0.5938 - val_acc: 0.6993\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 497us/step - loss: 0.6360 - acc: 0.6351 - val_loss: 0.5999 - val_acc: 0.6942\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 639us/step - loss: 0.6098 - acc: 0.6737 - val_loss: 0.5935 - val_acc: 0.6967\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 513us/step - loss: 0.5858 - acc: 0.6919 - val_loss: 0.5900 - val_acc: 0.6968\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 549us/step - loss: 0.5979 - acc: 0.6588 - val_loss: 0.5893 - val_acc: 0.7069\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 541us/step - loss: 0.6205 - acc: 0.6380 - val_loss: 0.6093 - val_acc: 0.6602\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 620us/step - loss: 0.5744 - acc: 0.7053 - val_loss: 0.5490 - val_acc: 0.7678\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 623us/step - loss: 0.5979 - acc: 0.6877 - val_loss: 0.6046 - val_acc: 0.6768\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 559us/step - loss: 0.6185 - acc: 0.6664 - val_loss: 0.5938 - val_acc: 0.7003\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 516us/step - loss: 0.5850 - acc: 0.6861 - val_loss: 0.5659 - val_acc: 0.7402\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 803us/step - loss: 0.6052 - acc: 0.6571 - val_loss: 0.5752 - val_acc: 0.6997\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 688us/step - loss: 0.5766 - acc: 0.7279 - val_loss: 0.5717 - val_acc: 0.7224\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 639us/step - loss: 0.6227 - acc: 0.6473 - val_loss: 0.5973 - val_acc: 0.6752\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 612us/step - loss: 0.5631 - acc: 0.7275 - val_loss: 0.5407 - val_acc: 0.7486\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 666us/step - loss: 0.6334 - acc: 0.6661 - val_loss: 0.6755 - val_acc: 0.5964\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 620us/step - loss: 0.6448 - acc: 0.6307 - val_loss: 0.6252 - val_acc: 0.6512\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 610us/step - loss: 0.6113 - acc: 0.6579 - val_loss: 0.6122 - val_acc: 0.6686\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 503us/step - loss: 0.6451 - acc: 0.6273 - val_loss: 0.6361 - val_acc: 0.6393\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 689us/step - loss: 0.6319 - acc: 0.6481 - val_loss: 0.6130 - val_acc: 0.6664\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 517us/step - loss: 0.6300 - acc: 0.6355 - val_loss: 0.6117 - val_acc: 0.6738\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 663us/step - loss: 0.6397 - acc: 0.6247 - val_loss: 0.6433 - val_acc: 0.6218\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 516us/step - loss: 0.6272 - acc: 0.6434 - val_loss: 0.6066 - val_acc: 0.6737\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 549us/step - loss: 0.6231 - acc: 0.6599 - val_loss: 0.6095 - val_acc: 0.6729\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 608us/step - loss: 0.6205 - acc: 0.6433 - val_loss: 0.6214 - val_acc: 0.6694\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 516us/step - loss: 0.6453 - acc: 0.6437 - val_loss: 0.6245 - val_acc: 0.6730\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 621us/step - loss: 0.6063 - acc: 0.6865 - val_loss: 0.6085 - val_acc: 0.6923\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 572us/step - loss: 0.6228 - acc: 0.6639 - val_loss: 0.6180 - val_acc: 0.6793\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 500us/step - loss: 0.6476 - acc: 0.6162 - val_loss: 0.6214 - val_acc: 0.6630\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 621us/step - loss: 0.6266 - acc: 0.6495 - val_loss: 0.6183 - val_acc: 0.6816\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 690us/step - loss: 0.5947 - acc: 0.7055 - val_loss: 0.6072 - val_acc: 0.6845\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 618us/step - loss: 0.6093 - acc: 0.6802 - val_loss: 0.6242 - val_acc: 0.6683\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 581us/step - loss: 0.6317 - acc: 0.6447 - val_loss: 0.5913 - val_acc: 0.7182\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 567us/step - loss: 0.6172 - acc: 0.6727 - val_loss: 0.6235 - val_acc: 0.6711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 718us/step - loss: 0.6133 - acc: 0.6660 - val_loss: 0.6231 - val_acc: 0.6619\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 622us/step - loss: 0.6137 - acc: 0.6830 - val_loss: 0.6218 - val_acc: 0.6834\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 587us/step - loss: 0.5640 - acc: 0.7454 - val_loss: 0.5843 - val_acc: 0.7172\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 596us/step - loss: 0.6386 - acc: 0.6455 - val_loss: 0.6200 - val_acc: 0.6673\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 611us/step - loss: 0.5877 - acc: 0.7006 - val_loss: 0.5722 - val_acc: 0.7167\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 627us/step - loss: 0.6093 - acc: 0.7004 - val_loss: 0.5870 - val_acc: 0.7087\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 524us/step - loss: 0.5876 - acc: 0.6868 - val_loss: 0.6000 - val_acc: 0.6992\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 579us/step - loss: 0.6351 - acc: 0.6431 - val_loss: 0.6110 - val_acc: 0.6798\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 524us/step - loss: 0.6204 - acc: 0.6689 - val_loss: 0.5834 - val_acc: 0.7175\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 561us/step - loss: 0.6216 - acc: 0.6743 - val_loss: 0.6297 - val_acc: 0.6779\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 542us/step - loss: 0.5666 - acc: 0.7284 - val_loss: 0.5694 - val_acc: 0.7207\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 567us/step - loss: 0.6152 - acc: 0.6543 - val_loss: 0.5733 - val_acc: 0.7287\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 603us/step - loss: 0.5946 - acc: 0.7053 - val_loss: 0.6032 - val_acc: 0.6858\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 576us/step - loss: 0.5893 - acc: 0.6976 - val_loss: 0.5873 - val_acc: 0.6819\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 686us/step - loss: 0.5706 - acc: 0.7256 - val_loss: 0.5844 - val_acc: 0.7142\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 566us/step - loss: 0.5533 - acc: 0.7311 - val_loss: 0.5776 - val_acc: 0.7041\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 597us/step - loss: 0.6487 - acc: 0.6246 - val_loss: 0.6028 - val_acc: 0.6819\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 547us/step - loss: 0.6082 - acc: 0.6876 - val_loss: 0.5862 - val_acc: 0.7009\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 664us/step - loss: 0.5919 - acc: 0.6735 - val_loss: 0.5955 - val_acc: 0.7019\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 618us/step - loss: 0.5844 - acc: 0.6787 - val_loss: 0.5911 - val_acc: 0.7080\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 553us/step - loss: 0.5956 - acc: 0.6981 - val_loss: 0.6206 - val_acc: 0.6737\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 684us/step - loss: 0.6459 - acc: 0.6337 - val_loss: 0.6403 - val_acc: 0.6526\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 780us/step - loss: 0.5962 - acc: 0.6907 - val_loss: 0.5904 - val_acc: 0.7075\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 520us/step - loss: 0.6041 - acc: 0.6812 - val_loss: 0.5923 - val_acc: 0.6950\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.6044 - acc: 0.6920 - val_loss: 0.6220 - val_acc: 0.6651\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 583us/step - loss: 0.6355 - acc: 0.6359 - val_loss: 0.6246 - val_acc: 0.6313\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 556us/step - loss: 0.6184 - acc: 0.6526 - val_loss: 0.6148 - val_acc: 0.6499\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 674us/step - loss: 0.6347 - acc: 0.6362 - val_loss: 0.5871 - val_acc: 0.6812\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 625us/step - loss: 0.6498 - acc: 0.6260 - val_loss: 0.6077 - val_acc: 0.6764\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 677us/step - loss: 0.5850 - acc: 0.6943 - val_loss: 0.5931 - val_acc: 0.7020\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 533us/step - loss: 0.5991 - acc: 0.6774 - val_loss: 0.5803 - val_acc: 0.7216\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.6755 - acc: 0.6290 - val_loss: 0.6788 - val_acc: 0.6381\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 626us/step - loss: 0.6041 - acc: 0.6998 - val_loss: 0.6083 - val_acc: 0.6858\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 600us/step - loss: 0.6051 - acc: 0.6849 - val_loss: 0.6054 - val_acc: 0.6842\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 621us/step - loss: 0.5892 - acc: 0.7034 - val_loss: 0.5534 - val_acc: 0.7475\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 508us/step - loss: 0.5906 - acc: 0.7085 - val_loss: 0.5880 - val_acc: 0.6936\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 589us/step - loss: 0.6089 - acc: 0.6675 - val_loss: 0.5829 - val_acc: 0.7007\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 529us/step - loss: 0.5974 - acc: 0.6829 - val_loss: 0.5727 - val_acc: 0.7151\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 637us/step - loss: 0.5912 - acc: 0.7012 - val_loss: 0.5884 - val_acc: 0.6988\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 565us/step - loss: 0.6009 - acc: 0.7002 - val_loss: 0.5728 - val_acc: 0.7329\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 637us/step - loss: 0.5713 - acc: 0.7184 - val_loss: 0.5560 - val_acc: 0.7248\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 496us/step - loss: 0.6157 - acc: 0.6502 - val_loss: 0.5732 - val_acc: 0.7088\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 710us/step - loss: 0.6063 - acc: 0.6626 - val_loss: 0.6447 - val_acc: 0.6276\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 524us/step - loss: 0.6262 - acc: 0.6487 - val_loss: 0.6050 - val_acc: 0.6573\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 503us/step - loss: 0.6130 - acc: 0.6657 - val_loss: 0.6117 - val_acc: 0.6622\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 491us/step - loss: 0.5967 - acc: 0.6874 - val_loss: 0.5910 - val_acc: 0.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 603us/step - loss: 0.5814 - acc: 0.7100 - val_loss: 0.5737 - val_acc: 0.7233\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 518us/step - loss: 0.6088 - acc: 0.6702 - val_loss: 0.6014 - val_acc: 0.6940\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 590us/step - loss: 0.6369 - acc: 0.6468 - val_loss: 0.6283 - val_acc: 0.6616\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 482us/step - loss: 0.5951 - acc: 0.6927 - val_loss: 0.5809 - val_acc: 0.7170\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 574us/step - loss: 0.6080 - acc: 0.6692 - val_loss: 0.5529 - val_acc: 0.7344\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 591us/step - loss: 0.6211 - acc: 0.6449 - val_loss: 0.5801 - val_acc: 0.7021\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 594us/step - loss: 0.6411 - acc: 0.6242 - val_loss: 0.6108 - val_acc: 0.6762\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 555us/step - loss: 0.5955 - acc: 0.6855 - val_loss: 0.5656 - val_acc: 0.7292\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 582us/step - loss: 0.5655 - acc: 0.7091 - val_loss: 0.5564 - val_acc: 0.7160\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.5722 - acc: 0.7155 - val_loss: 0.5840 - val_acc: 0.6985\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 580us/step - loss: 0.5594 - acc: 0.7122 - val_loss: 0.5515 - val_acc: 0.7290\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 470us/step - loss: 0.5969 - acc: 0.6922 - val_loss: 0.5718 - val_acc: 0.7039\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 635us/step - loss: 0.6104 - acc: 0.6716 - val_loss: 0.5981 - val_acc: 0.6932\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 594us/step - loss: 0.5933 - acc: 0.6768 - val_loss: 0.5794 - val_acc: 0.6887\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 543us/step - loss: 0.6172 - acc: 0.6583 - val_loss: 0.5769 - val_acc: 0.7148\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 632us/step - loss: 0.5420 - acc: 0.7340 - val_loss: 0.5710 - val_acc: 0.7096\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 515us/step - loss: 0.5923 - acc: 0.6924 - val_loss: 0.5743 - val_acc: 0.7191\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 593us/step - loss: 0.5640 - acc: 0.7160 - val_loss: 0.5805 - val_acc: 0.6975\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 603us/step - loss: 0.5642 - acc: 0.7164 - val_loss: 0.5738 - val_acc: 0.7153\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 528us/step - loss: 0.5645 - acc: 0.7168 - val_loss: 0.5859 - val_acc: 0.6904\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 684us/step - loss: 0.5462 - acc: 0.7387 - val_loss: 0.5846 - val_acc: 0.6843\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 522us/step - loss: 0.5995 - acc: 0.6713 - val_loss: 0.5802 - val_acc: 0.6942\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 587us/step - loss: 0.6065 - acc: 0.6623 - val_loss: 0.5788 - val_acc: 0.7038\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 579us/step - loss: 0.5933 - acc: 0.6773 - val_loss: 0.5718 - val_acc: 0.7111\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 593us/step - loss: 0.5975 - acc: 0.6826 - val_loss: 0.5866 - val_acc: 0.7131\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 527us/step - loss: 0.6551 - acc: 0.6240 - val_loss: 0.6039 - val_acc: 0.6897\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 692us/step - loss: 0.6086 - acc: 0.6832 - val_loss: 0.6004 - val_acc: 0.6932\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 626us/step - loss: 0.6083 - acc: 0.6781 - val_loss: 0.5625 - val_acc: 0.7187\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 761us/step - loss: 0.5912 - acc: 0.6892 - val_loss: 0.5862 - val_acc: 0.6951\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 557us/step - loss: 0.6713 - acc: 0.6118 - val_loss: 0.6243 - val_acc: 0.6548\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 590us/step - loss: 0.5805 - acc: 0.7025 - val_loss: 0.5396 - val_acc: 0.7544\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 599us/step - loss: 0.6125 - acc: 0.6717 - val_loss: 0.6178 - val_acc: 0.6940\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 538us/step - loss: 0.5860 - acc: 0.7104 - val_loss: 0.5834 - val_acc: 0.7144\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 667us/step - loss: 0.6020 - acc: 0.6952 - val_loss: 0.5587 - val_acc: 0.7497\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 601us/step - loss: 0.5805 - acc: 0.7020 - val_loss: 0.5949 - val_acc: 0.6993\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 728us/step - loss: 0.5774 - acc: 0.7091 - val_loss: 0.5860 - val_acc: 0.7022\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 649us/step - loss: 0.6400 - acc: 0.6191 - val_loss: 0.6267 - val_acc: 0.6474\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 540us/step - loss: 0.6481 - acc: 0.6180 - val_loss: 0.5617 - val_acc: 0.7277\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 565us/step - loss: 0.6032 - acc: 0.6758 - val_loss: 0.5558 - val_acc: 0.7458\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 555us/step - loss: 0.6129 - acc: 0.6450 - val_loss: 0.5511 - val_acc: 0.7417\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 487us/step - loss: 0.6066 - acc: 0.6730 - val_loss: 0.5406 - val_acc: 0.7572\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 657us/step - loss: 0.5848 - acc: 0.6927 - val_loss: 0.5743 - val_acc: 0.7126\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 514us/step - loss: 0.6239 - acc: 0.6565 - val_loss: 0.5753 - val_acc: 0.7140\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 653us/step - loss: 0.5913 - acc: 0.6904 - val_loss: 0.5720 - val_acc: 0.7120\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 513us/step - loss: 0.5712 - acc: 0.7043 - val_loss: 0.5677 - val_acc: 0.7140\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 608us/step - loss: 0.5889 - acc: 0.6740 - val_loss: 0.5751 - val_acc: 0.7262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 625us/step - loss: 0.5973 - acc: 0.6668 - val_loss: 0.5976 - val_acc: 0.6705\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 638us/step - loss: 0.5537 - acc: 0.7208 - val_loss: 0.5194 - val_acc: 0.7852\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 601us/step - loss: 0.5739 - acc: 0.7054 - val_loss: 0.5859 - val_acc: 0.6911\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 499us/step - loss: 0.6080 - acc: 0.6734 - val_loss: 0.5785 - val_acc: 0.7092\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 488us/step - loss: 0.5659 - acc: 0.7113 - val_loss: 0.5436 - val_acc: 0.7451\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 827us/step - loss: 0.5974 - acc: 0.6701 - val_loss: 0.5574 - val_acc: 0.7132\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 715us/step - loss: 0.5500 - acc: 0.7371 - val_loss: 0.5470 - val_acc: 0.7379\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 656us/step - loss: 0.6199 - acc: 0.6495 - val_loss: 0.5783 - val_acc: 0.6987\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 635us/step - loss: 0.5441 - acc: 0.7462 - val_loss: 0.5226 - val_acc: 0.7658\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 674us/step - loss: 0.6057 - acc: 0.7030 - val_loss: 0.6438 - val_acc: 0.6397\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 659us/step - loss: 0.6344 - acc: 0.6453 - val_loss: 0.6081 - val_acc: 0.6765\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 612us/step - loss: 0.5894 - acc: 0.6886 - val_loss: 0.5938 - val_acc: 0.6947\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 463us/step - loss: 0.6313 - acc: 0.6443 - val_loss: 0.6127 - val_acc: 0.6678\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 669us/step - loss: 0.6084 - acc: 0.6793 - val_loss: 0.5821 - val_acc: 0.7067\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 546us/step - loss: 0.6086 - acc: 0.6729 - val_loss: 0.5925 - val_acc: 0.6959\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 648us/step - loss: 0.6319 - acc: 0.6396 - val_loss: 0.6258 - val_acc: 0.6429\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 521us/step - loss: 0.6257 - acc: 0.6438 - val_loss: 0.5969 - val_acc: 0.6845\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 512us/step - loss: 0.6004 - acc: 0.6848 - val_loss: 0.5857 - val_acc: 0.7011\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 660us/step - loss: 0.6051 - acc: 0.6702 - val_loss: 0.6031 - val_acc: 0.6854\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 530us/step - loss: 0.6140 - acc: 0.6732 - val_loss: 0.5978 - val_acc: 0.6977\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 608us/step - loss: 0.5810 - acc: 0.7112 - val_loss: 0.5902 - val_acc: 0.7142\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 501us/step - loss: 0.6116 - acc: 0.6743 - val_loss: 0.5910 - val_acc: 0.7034\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 527us/step - loss: 0.6239 - acc: 0.6564 - val_loss: 0.5950 - val_acc: 0.6956\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 661us/step - loss: 0.6111 - acc: 0.6683 - val_loss: 0.5964 - val_acc: 0.7014\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 658us/step - loss: 0.5764 - acc: 0.7197 - val_loss: 0.5897 - val_acc: 0.6981\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 635us/step - loss: 0.5967 - acc: 0.6906 - val_loss: 0.6084 - val_acc: 0.6717\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 537us/step - loss: 0.6177 - acc: 0.6628 - val_loss: 0.5693 - val_acc: 0.7317\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 581us/step - loss: 0.6018 - acc: 0.6864 - val_loss: 0.6057 - val_acc: 0.6863\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 754us/step - loss: 0.6018 - acc: 0.6788 - val_loss: 0.6044 - val_acc: 0.6855\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 668us/step - loss: 0.6056 - acc: 0.6713 - val_loss: 0.5959 - val_acc: 0.6974\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 624us/step - loss: 0.5454 - acc: 0.7363 - val_loss: 0.5556 - val_acc: 0.7401\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 667us/step - loss: 0.6151 - acc: 0.6638 - val_loss: 0.5812 - val_acc: 0.7084\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 618us/step - loss: 0.5670 - acc: 0.7104 - val_loss: 0.5472 - val_acc: 0.7327\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 667us/step - loss: 0.5882 - acc: 0.7029 - val_loss: 0.5654 - val_acc: 0.7201\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 536us/step - loss: 0.5698 - acc: 0.7019 - val_loss: 0.5862 - val_acc: 0.6964\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 596us/step - loss: 0.6233 - acc: 0.6591 - val_loss: 0.6008 - val_acc: 0.6808\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 562us/step - loss: 0.6089 - acc: 0.6784 - val_loss: 0.5715 - val_acc: 0.7237\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 563us/step - loss: 0.6063 - acc: 0.6929 - val_loss: 0.6124 - val_acc: 0.6963\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 532us/step - loss: 0.5432 - acc: 0.7451 - val_loss: 0.5479 - val_acc: 0.7330\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 555us/step - loss: 0.5931 - acc: 0.6759 - val_loss: 0.5505 - val_acc: 0.7460\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 656us/step - loss: 0.5774 - acc: 0.7164 - val_loss: 0.5851 - val_acc: 0.7119\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 609us/step - loss: 0.5727 - acc: 0.7062 - val_loss: 0.5764 - val_acc: 0.6973\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 648us/step - loss: 0.5505 - acc: 0.7392 - val_loss: 0.5651 - val_acc: 0.7297\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 516us/step - loss: 0.5376 - acc: 0.7381 - val_loss: 0.5581 - val_acc: 0.7227\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 632us/step - loss: 0.6363 - acc: 0.6495 - val_loss: 0.5835 - val_acc: 0.7098\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 519us/step - loss: 0.5986 - acc: 0.7019 - val_loss: 0.5666 - val_acc: 0.7187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 599us/step - loss: 0.5835 - acc: 0.6767 - val_loss: 0.5855 - val_acc: 0.7033\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 674us/step - loss: 0.5777 - acc: 0.6896 - val_loss: 0.5768 - val_acc: 0.7233\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 502us/step - loss: 0.5860 - acc: 0.6986 - val_loss: 0.6152 - val_acc: 0.6833\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 657us/step - loss: 0.6239 - acc: 0.6553 - val_loss: 0.6209 - val_acc: 0.6747\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 809us/step - loss: 0.5626 - acc: 0.7263 - val_loss: 0.5704 - val_acc: 0.7176\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 543us/step - loss: 0.5934 - acc: 0.6884 - val_loss: 0.5894 - val_acc: 0.6919\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 728us/step - loss: 0.6016 - acc: 0.6861 - val_loss: 0.6065 - val_acc: 0.6807\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 641us/step - loss: 0.5975 - acc: 0.6916 - val_loss: 0.5949 - val_acc: 0.6799\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 540us/step - loss: 0.5912 - acc: 0.6895 - val_loss: 0.5910 - val_acc: 0.6851\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 657us/step - loss: 0.6144 - acc: 0.6643 - val_loss: 0.5586 - val_acc: 0.7154\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 637us/step - loss: 0.6358 - acc: 0.6501 - val_loss: 0.5893 - val_acc: 0.6888\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 685us/step - loss: 0.5701 - acc: 0.7078 - val_loss: 0.5792 - val_acc: 0.7132\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 543us/step - loss: 0.5862 - acc: 0.6753 - val_loss: 0.5660 - val_acc: 0.7225\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.6265 - acc: 0.6873 - val_loss: 0.6319 - val_acc: 0.6848\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 643us/step - loss: 0.5851 - acc: 0.7166 - val_loss: 0.5930 - val_acc: 0.7057\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 539us/step - loss: 0.5803 - acc: 0.7033 - val_loss: 0.5888 - val_acc: 0.6963\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 587us/step - loss: 0.5655 - acc: 0.7228 - val_loss: 0.5299 - val_acc: 0.7567\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 534us/step - loss: 0.5710 - acc: 0.7205 - val_loss: 0.5693 - val_acc: 0.7112\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 567us/step - loss: 0.5909 - acc: 0.6892 - val_loss: 0.5605 - val_acc: 0.7238\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 565us/step - loss: 0.5814 - acc: 0.7035 - val_loss: 0.5577 - val_acc: 0.7267\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 634us/step - loss: 0.5805 - acc: 0.7170 - val_loss: 0.5775 - val_acc: 0.7090\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 570us/step - loss: 0.5919 - acc: 0.6985 - val_loss: 0.5532 - val_acc: 0.7431\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 644us/step - loss: 0.5576 - acc: 0.7287 - val_loss: 0.5412 - val_acc: 0.7298\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 522us/step - loss: 0.6234 - acc: 0.6523 - val_loss: 0.5681 - val_acc: 0.7141\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 662us/step - loss: 0.5997 - acc: 0.6878 - val_loss: 0.6453 - val_acc: 0.6362\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 493us/step - loss: 0.6229 - acc: 0.6610 - val_loss: 0.5992 - val_acc: 0.6692\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 562us/step - loss: 0.6020 - acc: 0.6804 - val_loss: 0.5998 - val_acc: 0.6751\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 598us/step - loss: 0.5879 - acc: 0.6959 - val_loss: 0.5793 - val_acc: 0.7091\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 645us/step - loss: 0.5739 - acc: 0.7205 - val_loss: 0.5657 - val_acc: 0.7274\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 542us/step - loss: 0.6068 - acc: 0.6782 - val_loss: 0.5989 - val_acc: 0.6917\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 611us/step - loss: 0.6314 - acc: 0.6486 - val_loss: 0.6301 - val_acc: 0.6571\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 496us/step - loss: 0.5884 - acc: 0.6947 - val_loss: 0.5701 - val_acc: 0.7296\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 582us/step - loss: 0.5970 - acc: 0.6914 - val_loss: 0.5423 - val_acc: 0.7489\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 562us/step - loss: 0.6138 - acc: 0.6511 - val_loss: 0.5677 - val_acc: 0.7126\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 577us/step - loss: 0.6337 - acc: 0.6411 - val_loss: 0.6043 - val_acc: 0.6873\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 603us/step - loss: 0.5797 - acc: 0.7006 - val_loss: 0.5512 - val_acc: 0.7361\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 612us/step - loss: 0.5481 - acc: 0.7289 - val_loss: 0.5372 - val_acc: 0.7348\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.5584 - acc: 0.7243 - val_loss: 0.5724 - val_acc: 0.7118\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 636us/step - loss: 0.5368 - acc: 0.7336 - val_loss: 0.5334 - val_acc: 0.7453\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 538us/step - loss: 0.5811 - acc: 0.7032 - val_loss: 0.5529 - val_acc: 0.7228\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 653us/step - loss: 0.5884 - acc: 0.7020 - val_loss: 0.5801 - val_acc: 0.7115\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 583us/step - loss: 0.5859 - acc: 0.6851 - val_loss: 0.5687 - val_acc: 0.6974\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 520us/step - loss: 0.6021 - acc: 0.6738 - val_loss: 0.5637 - val_acc: 0.7232\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 699us/step - loss: 0.5238 - acc: 0.7496 - val_loss: 0.5614 - val_acc: 0.7165\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 574us/step - loss: 0.5785 - acc: 0.7050 - val_loss: 0.5598 - val_acc: 0.7281\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 635us/step - loss: 0.5531 - acc: 0.7309 - val_loss: 0.5659 - val_acc: 0.7111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 647us/step - loss: 0.5516 - acc: 0.7301 - val_loss: 0.5573 - val_acc: 0.7283\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 554us/step - loss: 0.5542 - acc: 0.7282 - val_loss: 0.5724 - val_acc: 0.7046\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 665us/step - loss: 0.5385 - acc: 0.7459 - val_loss: 0.5767 - val_acc: 0.6931\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 561us/step - loss: 0.5942 - acc: 0.6745 - val_loss: 0.5702 - val_acc: 0.7002\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 524us/step - loss: 0.5957 - acc: 0.6770 - val_loss: 0.5677 - val_acc: 0.7120\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 587us/step - loss: 0.5844 - acc: 0.6803 - val_loss: 0.5585 - val_acc: 0.7259\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 651us/step - loss: 0.5847 - acc: 0.6918 - val_loss: 0.5783 - val_acc: 0.7167\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 515us/step - loss: 0.6447 - acc: 0.6370 - val_loss: 0.5932 - val_acc: 0.7027\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 656us/step - loss: 0.6031 - acc: 0.6951 - val_loss: 0.5913 - val_acc: 0.7051\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 621us/step - loss: 0.6029 - acc: 0.6846 - val_loss: 0.5516 - val_acc: 0.7260\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 608us/step - loss: 0.5791 - acc: 0.7007 - val_loss: 0.5707 - val_acc: 0.7157\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 561us/step - loss: 0.6720 - acc: 0.6161 - val_loss: 0.6163 - val_acc: 0.6681\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 622us/step - loss: 0.5664 - acc: 0.7188 - val_loss: 0.5287 - val_acc: 0.7594\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 554us/step - loss: 0.6014 - acc: 0.6844 - val_loss: 0.6016 - val_acc: 0.7074\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 509us/step - loss: 0.5730 - acc: 0.7259 - val_loss: 0.5739 - val_acc: 0.7231\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 654us/step - loss: 0.5942 - acc: 0.7015 - val_loss: 0.5472 - val_acc: 0.7524\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 606us/step - loss: 0.5698 - acc: 0.7118 - val_loss: 0.5840 - val_acc: 0.7068\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 634us/step - loss: 0.5629 - acc: 0.7217 - val_loss: 0.5737 - val_acc: 0.7120\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 582us/step - loss: 0.6218 - acc: 0.6520 - val_loss: 0.6145 - val_acc: 0.6586\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 518us/step - loss: 0.6348 - acc: 0.6454 - val_loss: 0.5511 - val_acc: 0.7347\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 576us/step - loss: 0.5910 - acc: 0.6879 - val_loss: 0.5437 - val_acc: 0.7510\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 578us/step - loss: 0.6039 - acc: 0.6546 - val_loss: 0.5375 - val_acc: 0.7489\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 475us/step - loss: 0.5957 - acc: 0.6884 - val_loss: 0.5233 - val_acc: 0.7713\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 684us/step - loss: 0.5786 - acc: 0.7010 - val_loss: 0.5608 - val_acc: 0.7230\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 520us/step - loss: 0.6176 - acc: 0.6644 - val_loss: 0.5617 - val_acc: 0.7266\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 630us/step - loss: 0.5797 - acc: 0.7043 - val_loss: 0.5606 - val_acc: 0.7180\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 501us/step - loss: 0.5607 - acc: 0.7183 - val_loss: 0.5597 - val_acc: 0.7210\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 569us/step - loss: 0.5868 - acc: 0.6866 - val_loss: 0.5670 - val_acc: 0.7245\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 582us/step - loss: 0.5902 - acc: 0.6761 - val_loss: 0.5941 - val_acc: 0.6755\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 645us/step - loss: 0.5453 - acc: 0.7267 - val_loss: 0.5078 - val_acc: 0.7915\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 615us/step - loss: 0.5625 - acc: 0.7118 - val_loss: 0.5730 - val_acc: 0.7034\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 508us/step - loss: 0.6036 - acc: 0.6751 - val_loss: 0.5654 - val_acc: 0.7202\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 502us/step - loss: 0.5584 - acc: 0.7134 - val_loss: 0.5294 - val_acc: 0.7587\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 726us/step - loss: 0.5857 - acc: 0.6827 - val_loss: 0.5439 - val_acc: 0.7295\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 686us/step - loss: 0.5469 - acc: 0.7358 - val_loss: 0.5334 - val_acc: 0.7469\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 652us/step - loss: 0.6141 - acc: 0.6579 - val_loss: 0.5660 - val_acc: 0.7141\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 653us/step - loss: 0.5305 - acc: 0.7583 - val_loss: 0.5051 - val_acc: 0.7817\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 649us/step - loss: 0.6048 - acc: 0.7088 - val_loss: 0.6432 - val_acc: 0.6533\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 652us/step - loss: 0.6382 - acc: 0.6529 - val_loss: 0.6088 - val_acc: 0.6780\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 599us/step - loss: 0.5932 - acc: 0.6883 - val_loss: 0.5886 - val_acc: 0.7014\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 474us/step - loss: 0.6139 - acc: 0.6749 - val_loss: 0.5965 - val_acc: 0.6945\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 710us/step - loss: 0.5913 - acc: 0.7070 - val_loss: 0.5629 - val_acc: 0.7373\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 504us/step - loss: 0.5843 - acc: 0.6944 - val_loss: 0.5752 - val_acc: 0.7099\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 710us/step - loss: 0.6139 - acc: 0.6644 - val_loss: 0.6123 - val_acc: 0.6574\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 529us/step - loss: 0.6265 - acc: 0.6382 - val_loss: 0.5950 - val_acc: 0.6789\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 570us/step - loss: 0.5929 - acc: 0.6868 - val_loss: 0.5735 - val_acc: 0.7113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 627us/step - loss: 0.5830 - acc: 0.7098 - val_loss: 0.5884 - val_acc: 0.6904\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 473us/step - loss: 0.5922 - acc: 0.6948 - val_loss: 0.5822 - val_acc: 0.7127\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 605us/step - loss: 0.5647 - acc: 0.7313 - val_loss: 0.5753 - val_acc: 0.7277\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 545us/step - loss: 0.6032 - acc: 0.6855 - val_loss: 0.5800 - val_acc: 0.7130\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 500us/step - loss: 0.6162 - acc: 0.6668 - val_loss: 0.5832 - val_acc: 0.7019\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 738us/step - loss: 0.5994 - acc: 0.6841 - val_loss: 0.5806 - val_acc: 0.7138\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 701us/step - loss: 0.5666 - acc: 0.7282 - val_loss: 0.5831 - val_acc: 0.7048\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 607us/step - loss: 0.5862 - acc: 0.7022 - val_loss: 0.5955 - val_acc: 0.6899\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 540us/step - loss: 0.6028 - acc: 0.6822 - val_loss: 0.5551 - val_acc: 0.7448\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 667us/step - loss: 0.5938 - acc: 0.6988 - val_loss: 0.5943 - val_acc: 0.7087\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 691us/step - loss: 0.5868 - acc: 0.7050 - val_loss: 0.5964 - val_acc: 0.6926\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 588us/step - loss: 0.5811 - acc: 0.7032 - val_loss: 0.5842 - val_acc: 0.7063\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 601us/step - loss: 0.5291 - acc: 0.7583 - val_loss: 0.5381 - val_acc: 0.7546\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 647us/step - loss: 0.6073 - acc: 0.6802 - val_loss: 0.5716 - val_acc: 0.7170\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 582us/step - loss: 0.5517 - acc: 0.7310 - val_loss: 0.5298 - val_acc: 0.7524\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 687us/step - loss: 0.5853 - acc: 0.7101 - val_loss: 0.5567 - val_acc: 0.7268\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 478us/step - loss: 0.5641 - acc: 0.7018 - val_loss: 0.5728 - val_acc: 0.7105\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 599us/step - loss: 0.6129 - acc: 0.6624 - val_loss: 0.5876 - val_acc: 0.6908\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 570us/step - loss: 0.5979 - acc: 0.6885 - val_loss: 0.5652 - val_acc: 0.7277\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 599us/step - loss: 0.5935 - acc: 0.7078 - val_loss: 0.6005 - val_acc: 0.7057\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 489us/step - loss: 0.5272 - acc: 0.7623 - val_loss: 0.5373 - val_acc: 0.7432\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 502us/step - loss: 0.5743 - acc: 0.7060 - val_loss: 0.5389 - val_acc: 0.7547\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 643us/step - loss: 0.5721 - acc: 0.7268 - val_loss: 0.5666 - val_acc: 0.7315\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 570us/step - loss: 0.5584 - acc: 0.7251 - val_loss: 0.5668 - val_acc: 0.7126\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 659us/step - loss: 0.5436 - acc: 0.7456 - val_loss: 0.5500 - val_acc: 0.7396\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 499us/step - loss: 0.5304 - acc: 0.7478 - val_loss: 0.5479 - val_acc: 0.7326\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 601us/step - loss: 0.6239 - acc: 0.6602 - val_loss: 0.5698 - val_acc: 0.7192\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 542us/step - loss: 0.5858 - acc: 0.7055 - val_loss: 0.5522 - val_acc: 0.7335\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 574us/step - loss: 0.5754 - acc: 0.6954 - val_loss: 0.5758 - val_acc: 0.7112\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 604us/step - loss: 0.5645 - acc: 0.7038 - val_loss: 0.5621 - val_acc: 0.7326\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 508us/step - loss: 0.5756 - acc: 0.7048 - val_loss: 0.5995 - val_acc: 0.6906\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 592us/step - loss: 0.6064 - acc: 0.6722 - val_loss: 0.6070 - val_acc: 0.6881\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 723us/step - loss: 0.5500 - acc: 0.7270 - val_loss: 0.5567 - val_acc: 0.7309\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 494us/step - loss: 0.5777 - acc: 0.7062 - val_loss: 0.5764 - val_acc: 0.7021\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 725us/step - loss: 0.5850 - acc: 0.7062 - val_loss: 0.5994 - val_acc: 0.6881\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.5858 - acc: 0.7014 - val_loss: 0.5846 - val_acc: 0.6932\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 570us/step - loss: 0.5750 - acc: 0.7036 - val_loss: 0.5787 - val_acc: 0.6984\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 707us/step - loss: 0.6009 - acc: 0.6770 - val_loss: 0.5460 - val_acc: 0.7286\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 599us/step - loss: 0.6328 - acc: 0.6520 - val_loss: 0.5793 - val_acc: 0.6982\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 709us/step - loss: 0.5551 - acc: 0.7217 - val_loss: 0.5706 - val_acc: 0.7179\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 531us/step - loss: 0.5722 - acc: 0.7011 - val_loss: 0.5583 - val_acc: 0.7326\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.6057 - acc: 0.7058 - val_loss: 0.6135 - val_acc: 0.6945\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 688us/step - loss: 0.5806 - acc: 0.7157 - val_loss: 0.5839 - val_acc: 0.7117\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 552us/step - loss: 0.5715 - acc: 0.7069 - val_loss: 0.5764 - val_acc: 0.7063\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 586us/step - loss: 0.5531 - acc: 0.7262 - val_loss: 0.5180 - val_acc: 0.7631\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 522us/step - loss: 0.5597 - acc: 0.7311 - val_loss: 0.5563 - val_acc: 0.7277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 629us/step - loss: 0.5872 - acc: 0.6949 - val_loss: 0.5469 - val_acc: 0.7326\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 625us/step - loss: 0.5729 - acc: 0.7102 - val_loss: 0.5486 - val_acc: 0.7358\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 664us/step - loss: 0.5703 - acc: 0.7261 - val_loss: 0.5735 - val_acc: 0.7158\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 565us/step - loss: 0.5888 - acc: 0.6976 - val_loss: 0.5412 - val_acc: 0.7434\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 664us/step - loss: 0.5437 - acc: 0.7390 - val_loss: 0.5316 - val_acc: 0.7398\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 522us/step - loss: 0.6010 - acc: 0.6781 - val_loss: 0.5500 - val_acc: 0.7305\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 742us/step - loss: 0.5903 - acc: 0.6915 - val_loss: 0.6349 - val_acc: 0.6464\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 529us/step - loss: 0.6116 - acc: 0.6685 - val_loss: 0.5896 - val_acc: 0.6813\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 544us/step - loss: 0.5907 - acc: 0.6892 - val_loss: 0.5870 - val_acc: 0.6917\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 525us/step - loss: 0.5784 - acc: 0.7052 - val_loss: 0.5703 - val_acc: 0.7145\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 644us/step - loss: 0.5601 - acc: 0.7229 - val_loss: 0.5539 - val_acc: 0.7320\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 529us/step - loss: 0.6016 - acc: 0.6859 - val_loss: 0.5883 - val_acc: 0.6979\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 642us/step - loss: 0.6169 - acc: 0.6638 - val_loss: 0.6174 - val_acc: 0.6640\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 508us/step - loss: 0.5814 - acc: 0.7024 - val_loss: 0.5540 - val_acc: 0.7351\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 625us/step - loss: 0.5912 - acc: 0.6937 - val_loss: 0.5344 - val_acc: 0.7549\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 662us/step - loss: 0.5981 - acc: 0.6678 - val_loss: 0.5606 - val_acc: 0.7167\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 649us/step - loss: 0.6302 - acc: 0.6488 - val_loss: 0.5903 - val_acc: 0.6968\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 614us/step - loss: 0.5602 - acc: 0.7237 - val_loss: 0.5408 - val_acc: 0.7475\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 645us/step - loss: 0.5423 - acc: 0.7355 - val_loss: 0.5295 - val_acc: 0.7452\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.5540 - acc: 0.7299 - val_loss: 0.5585 - val_acc: 0.7236\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 607us/step - loss: 0.5348 - acc: 0.7421 - val_loss: 0.5270 - val_acc: 0.7491\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 506us/step - loss: 0.5734 - acc: 0.7146 - val_loss: 0.5418 - val_acc: 0.7348\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 656us/step - loss: 0.5792 - acc: 0.7088 - val_loss: 0.5656 - val_acc: 0.7292\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 596us/step - loss: 0.5842 - acc: 0.6840 - val_loss: 0.5593 - val_acc: 0.7066\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 543us/step - loss: 0.5898 - acc: 0.6940 - val_loss: 0.5531 - val_acc: 0.7320\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 674us/step - loss: 0.5277 - acc: 0.7495 - val_loss: 0.5552 - val_acc: 0.7201\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 556us/step - loss: 0.5659 - acc: 0.7170 - val_loss: 0.5439 - val_acc: 0.7372\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 594us/step - loss: 0.5398 - acc: 0.7420 - val_loss: 0.5486 - val_acc: 0.7327\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 638us/step - loss: 0.5370 - acc: 0.7430 - val_loss: 0.5468 - val_acc: 0.7395\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 497us/step - loss: 0.5424 - acc: 0.7441 - val_loss: 0.5593 - val_acc: 0.7225\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 668us/step - loss: 0.5330 - acc: 0.7498 - val_loss: 0.5732 - val_acc: 0.6978\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 538us/step - loss: 0.5864 - acc: 0.6837 - val_loss: 0.5557 - val_acc: 0.7179\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 517us/step - loss: 0.5819 - acc: 0.6911 - val_loss: 0.5559 - val_acc: 0.7204\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 582us/step - loss: 0.5679 - acc: 0.6898 - val_loss: 0.5433 - val_acc: 0.7396\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 590us/step - loss: 0.5748 - acc: 0.7048 - val_loss: 0.5637 - val_acc: 0.7196\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 512us/step - loss: 0.6343 - acc: 0.6497 - val_loss: 0.5858 - val_acc: 0.7087\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 615us/step - loss: 0.5870 - acc: 0.7102 - val_loss: 0.5811 - val_acc: 0.7084\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 555us/step - loss: 0.5879 - acc: 0.6883 - val_loss: 0.5378 - val_acc: 0.7359\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 577us/step - loss: 0.5642 - acc: 0.7173 - val_loss: 0.5614 - val_acc: 0.7175\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 587us/step - loss: 0.6574 - acc: 0.6215 - val_loss: 0.6026 - val_acc: 0.6774\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 603us/step - loss: 0.5521 - acc: 0.7266 - val_loss: 0.5159 - val_acc: 0.7630\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 538us/step - loss: 0.5904 - acc: 0.7000 - val_loss: 0.5955 - val_acc: 0.7005\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 491us/step - loss: 0.5599 - acc: 0.7282 - val_loss: 0.5615 - val_acc: 0.7337\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 658us/step - loss: 0.5790 - acc: 0.7227 - val_loss: 0.5366 - val_acc: 0.7563\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 512us/step - loss: 0.5547 - acc: 0.7308 - val_loss: 0.5716 - val_acc: 0.7149\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 624us/step - loss: 0.5556 - acc: 0.7246 - val_loss: 0.5606 - val_acc: 0.7239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 543us/step - loss: 0.6090 - acc: 0.6602 - val_loss: 0.6056 - val_acc: 0.6683\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 533us/step - loss: 0.6103 - acc: 0.6674 - val_loss: 0.5356 - val_acc: 0.7450\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 544us/step - loss: 0.5778 - acc: 0.6988 - val_loss: 0.5345 - val_acc: 0.7508\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 522us/step - loss: 0.5883 - acc: 0.6710 - val_loss: 0.5259 - val_acc: 0.7549\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 462us/step - loss: 0.5743 - acc: 0.7171 - val_loss: 0.5112 - val_acc: 0.7778\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 653us/step - loss: 0.5589 - acc: 0.7162 - val_loss: 0.5504 - val_acc: 0.7291\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 497us/step - loss: 0.6024 - acc: 0.6767 - val_loss: 0.5475 - val_acc: 0.7368\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 612us/step - loss: 0.5596 - acc: 0.7192 - val_loss: 0.5409 - val_acc: 0.7290\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 512us/step - loss: 0.5517 - acc: 0.7275 - val_loss: 0.5508 - val_acc: 0.7295\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 621us/step - loss: 0.5924 - acc: 0.6836 - val_loss: 0.5589 - val_acc: 0.7242\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 554us/step - loss: 0.5769 - acc: 0.6944 - val_loss: 0.5763 - val_acc: 0.6995\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 653us/step - loss: 0.5301 - acc: 0.7453 - val_loss: 0.4960 - val_acc: 0.7923\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 611us/step - loss: 0.5399 - acc: 0.7316 - val_loss: 0.5562 - val_acc: 0.7091\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 561us/step - loss: 0.5949 - acc: 0.6841 - val_loss: 0.5589 - val_acc: 0.7203\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 489us/step - loss: 0.5409 - acc: 0.7323 - val_loss: 0.5141 - val_acc: 0.7732\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 796us/step - loss: 0.5744 - acc: 0.7070 - val_loss: 0.5373 - val_acc: 0.7294\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 670us/step - loss: 0.5282 - acc: 0.7457 - val_loss: 0.5145 - val_acc: 0.7566\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 663us/step - loss: 0.5870 - acc: 0.6838 - val_loss: 0.5477 - val_acc: 0.7280\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 604us/step - loss: 0.5113 - acc: 0.7685 - val_loss: 0.4938 - val_acc: 0.7954\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 642us/step - loss: 0.5840 - acc: 0.7217 - val_loss: 0.6124 - val_acc: 0.6856\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 653us/step - loss: 0.6198 - acc: 0.6714 - val_loss: 0.5928 - val_acc: 0.6859\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 578us/step - loss: 0.5828 - acc: 0.7056 - val_loss: 0.5768 - val_acc: 0.7053\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 497us/step - loss: 0.6117 - acc: 0.6826 - val_loss: 0.5964 - val_acc: 0.6917\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 648us/step - loss: 0.5881 - acc: 0.7112 - val_loss: 0.5481 - val_acc: 0.7485\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 516us/step - loss: 0.5749 - acc: 0.7144 - val_loss: 0.5616 - val_acc: 0.7236\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 650us/step - loss: 0.5929 - acc: 0.6849 - val_loss: 0.5870 - val_acc: 0.6930\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 511us/step - loss: 0.5963 - acc: 0.6787 - val_loss: 0.5648 - val_acc: 0.7083\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 533us/step - loss: 0.5696 - acc: 0.7107 - val_loss: 0.5554 - val_acc: 0.7257\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 632us/step - loss: 0.5700 - acc: 0.7207 - val_loss: 0.5727 - val_acc: 0.7090\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 480us/step - loss: 0.5834 - acc: 0.7064 - val_loss: 0.5732 - val_acc: 0.7201\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 583us/step - loss: 0.5554 - acc: 0.7292 - val_loss: 0.5592 - val_acc: 0.7269\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 495us/step - loss: 0.5884 - acc: 0.7021 - val_loss: 0.5560 - val_acc: 0.7318\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 508us/step - loss: 0.5969 - acc: 0.6914 - val_loss: 0.5636 - val_acc: 0.7135\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 620us/step - loss: 0.5894 - acc: 0.6917 - val_loss: 0.5521 - val_acc: 0.7241\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 647us/step - loss: 0.5532 - acc: 0.7304 - val_loss: 0.5678 - val_acc: 0.7120\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 635us/step - loss: 0.5693 - acc: 0.7197 - val_loss: 0.5714 - val_acc: 0.6997\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 549us/step - loss: 0.5878 - acc: 0.6970 - val_loss: 0.5353 - val_acc: 0.7579\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 563us/step - loss: 0.5735 - acc: 0.7095 - val_loss: 0.5733 - val_acc: 0.7150\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 707us/step - loss: 0.5770 - acc: 0.7092 - val_loss: 0.5720 - val_acc: 0.6994\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 585us/step - loss: 0.5696 - acc: 0.7058 - val_loss: 0.5593 - val_acc: 0.7251\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 579us/step - loss: 0.5078 - acc: 0.7696 - val_loss: 0.5116 - val_acc: 0.7677\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 612us/step - loss: 0.5997 - acc: 0.6796 - val_loss: 0.5474 - val_acc: 0.7274\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 551us/step - loss: 0.5338 - acc: 0.7428 - val_loss: 0.5149 - val_acc: 0.7686\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 615us/step - loss: 0.5642 - acc: 0.7190 - val_loss: 0.5400 - val_acc: 0.7382\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 477us/step - loss: 0.5495 - acc: 0.7204 - val_loss: 0.5469 - val_acc: 0.7206\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 555us/step - loss: 0.6030 - acc: 0.6647 - val_loss: 0.5862 - val_acc: 0.6878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 520us/step - loss: 0.5860 - acc: 0.6919 - val_loss: 0.5538 - val_acc: 0.7290\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 528us/step - loss: 0.5685 - acc: 0.7190 - val_loss: 0.5755 - val_acc: 0.7182\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 492us/step - loss: 0.5155 - acc: 0.7674 - val_loss: 0.5205 - val_acc: 0.7511\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 498us/step - loss: 0.5641 - acc: 0.7177 - val_loss: 0.5218 - val_acc: 0.7621\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 613us/step - loss: 0.5568 - acc: 0.7360 - val_loss: 0.5424 - val_acc: 0.7366\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 576us/step - loss: 0.5522 - acc: 0.7274 - val_loss: 0.5570 - val_acc: 0.7198\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 664us/step - loss: 0.5230 - acc: 0.7611 - val_loss: 0.5322 - val_acc: 0.7507\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 504us/step - loss: 0.5165 - acc: 0.7512 - val_loss: 0.5344 - val_acc: 0.7369\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 581us/step - loss: 0.6067 - acc: 0.6671 - val_loss: 0.5523 - val_acc: 0.7223\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 495us/step - loss: 0.5717 - acc: 0.7121 - val_loss: 0.5361 - val_acc: 0.7460\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 590us/step - loss: 0.5617 - acc: 0.7103 - val_loss: 0.5547 - val_acc: 0.7145\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 626us/step - loss: 0.5478 - acc: 0.7149 - val_loss: 0.5426 - val_acc: 0.7418\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 494us/step - loss: 0.5623 - acc: 0.7175 - val_loss: 0.5802 - val_acc: 0.6984\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 624us/step - loss: 0.6001 - acc: 0.6788 - val_loss: 0.5863 - val_acc: 0.6912\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 744us/step - loss: 0.5355 - acc: 0.7338 - val_loss: 0.5433 - val_acc: 0.7331\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 511us/step - loss: 0.5631 - acc: 0.7170 - val_loss: 0.5642 - val_acc: 0.7092\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 635us/step - loss: 0.5781 - acc: 0.7069 - val_loss: 0.5896 - val_acc: 0.6943\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 604us/step - loss: 0.5748 - acc: 0.7089 - val_loss: 0.5703 - val_acc: 0.7045\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 543us/step - loss: 0.5707 - acc: 0.7009 - val_loss: 0.5628 - val_acc: 0.7086\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 605us/step - loss: 0.5843 - acc: 0.6855 - val_loss: 0.5373 - val_acc: 0.7301\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 587us/step - loss: 0.6156 - acc: 0.6684 - val_loss: 0.5564 - val_acc: 0.7165\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 626us/step - loss: 0.5479 - acc: 0.7295 - val_loss: 0.5541 - val_acc: 0.7278\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 488us/step - loss: 0.5557 - acc: 0.7175 - val_loss: 0.5359 - val_acc: 0.7442\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.5987 - acc: 0.7099 - val_loss: 0.5968 - val_acc: 0.6980\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 609us/step - loss: 0.5697 - acc: 0.7223 - val_loss: 0.5644 - val_acc: 0.7164\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 503us/step - loss: 0.5553 - acc: 0.7185 - val_loss: 0.5582 - val_acc: 0.7201\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 574us/step - loss: 0.5368 - acc: 0.7331 - val_loss: 0.4999 - val_acc: 0.7701\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 508us/step - loss: 0.5400 - acc: 0.7435 - val_loss: 0.5370 - val_acc: 0.7470\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 562us/step - loss: 0.5777 - acc: 0.7005 - val_loss: 0.5284 - val_acc: 0.7442\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 570us/step - loss: 0.5575 - acc: 0.7227 - val_loss: 0.5333 - val_acc: 0.7445\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 615us/step - loss: 0.5508 - acc: 0.7370 - val_loss: 0.5537 - val_acc: 0.7288\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 524us/step - loss: 0.5614 - acc: 0.7173 - val_loss: 0.5131 - val_acc: 0.7538\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 651us/step - loss: 0.5258 - acc: 0.7478 - val_loss: 0.5111 - val_acc: 0.7542\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 474us/step - loss: 0.5823 - acc: 0.6986 - val_loss: 0.5401 - val_acc: 0.7407\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 671us/step - loss: 0.5702 - acc: 0.7068 - val_loss: 0.6202 - val_acc: 0.6509\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 487us/step - loss: 0.6117 - acc: 0.6666 - val_loss: 0.5860 - val_acc: 0.6839\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 527us/step - loss: 0.5840 - acc: 0.6885 - val_loss: 0.5740 - val_acc: 0.7015\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 493us/step - loss: 0.5666 - acc: 0.7099 - val_loss: 0.5560 - val_acc: 0.7157\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 608us/step - loss: 0.5431 - acc: 0.7266 - val_loss: 0.5368 - val_acc: 0.7339\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 481us/step - loss: 0.5957 - acc: 0.6853 - val_loss: 0.5741 - val_acc: 0.6995\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 570us/step - loss: 0.6197 - acc: 0.6604 - val_loss: 0.6012 - val_acc: 0.6728\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 465us/step - loss: 0.5605 - acc: 0.7097 - val_loss: 0.5293 - val_acc: 0.7455\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 551us/step - loss: 0.5772 - acc: 0.7001 - val_loss: 0.5158 - val_acc: 0.7637\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 577us/step - loss: 0.5828 - acc: 0.6836 - val_loss: 0.5473 - val_acc: 0.7379\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 625us/step - loss: 0.6025 - acc: 0.6743 - val_loss: 0.5690 - val_acc: 0.7138\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 557us/step - loss: 0.5483 - acc: 0.7261 - val_loss: 0.5227 - val_acc: 0.7595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 642us/step - loss: 0.5381 - acc: 0.7338 - val_loss: 0.5183 - val_acc: 0.7545\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.5436 - acc: 0.7335 - val_loss: 0.5423 - val_acc: 0.7338\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 565us/step - loss: 0.5233 - acc: 0.7516 - val_loss: 0.5158 - val_acc: 0.7515\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 491us/step - loss: 0.5593 - acc: 0.7299 - val_loss: 0.5268 - val_acc: 0.7470\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 659us/step - loss: 0.5545 - acc: 0.7282 - val_loss: 0.5556 - val_acc: 0.7391\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 577us/step - loss: 0.5662 - acc: 0.7032 - val_loss: 0.5384 - val_acc: 0.7257\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 506us/step - loss: 0.5726 - acc: 0.7096 - val_loss: 0.5415 - val_acc: 0.7347\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.5050 - acc: 0.7622 - val_loss: 0.5357 - val_acc: 0.7266\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 515us/step - loss: 0.5509 - acc: 0.7348 - val_loss: 0.5228 - val_acc: 0.7500\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.5246 - acc: 0.7524 - val_loss: 0.5290 - val_acc: 0.7421\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 618us/step - loss: 0.5321 - acc: 0.7442 - val_loss: 0.5377 - val_acc: 0.7422\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 505us/step - loss: 0.5229 - acc: 0.7520 - val_loss: 0.5453 - val_acc: 0.7335\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 613us/step - loss: 0.5114 - acc: 0.7636 - val_loss: 0.5639 - val_acc: 0.6987\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 511us/step - loss: 0.5782 - acc: 0.6940 - val_loss: 0.5389 - val_acc: 0.7287\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 496us/step - loss: 0.5669 - acc: 0.6992 - val_loss: 0.5403 - val_acc: 0.7294\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 548us/step - loss: 0.5450 - acc: 0.7150 - val_loss: 0.5227 - val_acc: 0.7461\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 559us/step - loss: 0.5582 - acc: 0.7182 - val_loss: 0.5430 - val_acc: 0.7245\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 503us/step - loss: 0.6300 - acc: 0.6501 - val_loss: 0.5798 - val_acc: 0.7098\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 632us/step - loss: 0.5817 - acc: 0.6978 - val_loss: 0.5687 - val_acc: 0.7087\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 544us/step - loss: 0.5708 - acc: 0.7030 - val_loss: 0.5214 - val_acc: 0.7451\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 594us/step - loss: 0.5570 - acc: 0.7151 - val_loss: 0.5477 - val_acc: 0.7244\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 514us/step - loss: 0.6623 - acc: 0.6242 - val_loss: 0.5879 - val_acc: 0.6894\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 546us/step - loss: 0.5434 - acc: 0.7250 - val_loss: 0.5018 - val_acc: 0.7643\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 554us/step - loss: 0.5853 - acc: 0.7102 - val_loss: 0.5760 - val_acc: 0.7201\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 494us/step - loss: 0.5444 - acc: 0.7352 - val_loss: 0.5487 - val_acc: 0.7408\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 599us/step - loss: 0.5676 - acc: 0.7251 - val_loss: 0.5195 - val_acc: 0.7610\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 533us/step - loss: 0.5460 - acc: 0.7321 - val_loss: 0.5577 - val_acc: 0.7195\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 606us/step - loss: 0.5487 - acc: 0.7299 - val_loss: 0.5468 - val_acc: 0.7290\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 577us/step - loss: 0.5913 - acc: 0.6838 - val_loss: 0.5934 - val_acc: 0.6824\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 530us/step - loss: 0.5884 - acc: 0.6827 - val_loss: 0.5141 - val_acc: 0.7587\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 544us/step - loss: 0.5659 - acc: 0.7054 - val_loss: 0.5219 - val_acc: 0.7536\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 527us/step - loss: 0.5791 - acc: 0.6815 - val_loss: 0.5132 - val_acc: 0.7595\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 466us/step - loss: 0.5714 - acc: 0.7073 - val_loss: 0.4949 - val_acc: 0.7768\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 624us/step - loss: 0.5430 - acc: 0.7263 - val_loss: 0.5353 - val_acc: 0.7350\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 486us/step - loss: 0.5916 - acc: 0.6840 - val_loss: 0.5313 - val_acc: 0.7432\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 618us/step - loss: 0.5407 - acc: 0.7265 - val_loss: 0.5227 - val_acc: 0.7449\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 487us/step - loss: 0.5381 - acc: 0.7280 - val_loss: 0.5362 - val_acc: 0.7333\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 566us/step - loss: 0.5807 - acc: 0.6914 - val_loss: 0.5389 - val_acc: 0.7300\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 529us/step - loss: 0.5558 - acc: 0.7103 - val_loss: 0.5532 - val_acc: 0.7178\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 625us/step - loss: 0.5096 - acc: 0.7617 - val_loss: 0.4783 - val_acc: 0.7947\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 612us/step - loss: 0.5244 - acc: 0.7409 - val_loss: 0.5309 - val_acc: 0.7295\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 467us/step - loss: 0.5805 - acc: 0.6947 - val_loss: 0.5369 - val_acc: 0.7358\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 485us/step - loss: 0.5256 - acc: 0.7389 - val_loss: 0.4970 - val_acc: 0.7807\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 701us/step - loss: 0.5482 - acc: 0.7219 - val_loss: 0.5165 - val_acc: 0.7496\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 641us/step - loss: 0.5128 - acc: 0.7510 - val_loss: 0.4957 - val_acc: 0.7663\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 689us/step - loss: 0.5590 - acc: 0.7106 - val_loss: 0.5225 - val_acc: 0.7378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 572us/step - loss: 0.4935 - acc: 0.7718 - val_loss: 0.4792 - val_acc: 0.7956\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 634us/step - loss: 0.5817 - acc: 0.7281 - val_loss: 0.6010 - val_acc: 0.6966\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 639us/step - loss: 0.6245 - acc: 0.6730 - val_loss: 0.5967 - val_acc: 0.6883\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 548us/step - loss: 0.5853 - acc: 0.7016 - val_loss: 0.5733 - val_acc: 0.7037\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 476us/step - loss: 0.6011 - acc: 0.6974 - val_loss: 0.5909 - val_acc: 0.6965\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 629us/step - loss: 0.5804 - acc: 0.7156 - val_loss: 0.5331 - val_acc: 0.7567\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 543us/step - loss: 0.5597 - acc: 0.7215 - val_loss: 0.5456 - val_acc: 0.7334\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 701us/step - loss: 0.5787 - acc: 0.7010 - val_loss: 0.5751 - val_acc: 0.7020\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 554us/step - loss: 0.5900 - acc: 0.6825 - val_loss: 0.5500 - val_acc: 0.7163\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 571us/step - loss: 0.5551 - acc: 0.7207 - val_loss: 0.5429 - val_acc: 0.7306\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 775us/step - loss: 0.5510 - acc: 0.7357 - val_loss: 0.5619 - val_acc: 0.7136\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 518us/step - loss: 0.5643 - acc: 0.7156 - val_loss: 0.5551 - val_acc: 0.7308\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 613us/step - loss: 0.5465 - acc: 0.7315 - val_loss: 0.5460 - val_acc: 0.7323\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 537us/step - loss: 0.5790 - acc: 0.7034 - val_loss: 0.5422 - val_acc: 0.7354\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.5860 - acc: 0.7008 - val_loss: 0.5506 - val_acc: 0.7199\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 614us/step - loss: 0.5807 - acc: 0.7000 - val_loss: 0.5333 - val_acc: 0.7353\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 628us/step - loss: 0.5423 - acc: 0.7351 - val_loss: 0.5550 - val_acc: 0.7197\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 565us/step - loss: 0.5618 - acc: 0.7262 - val_loss: 0.5528 - val_acc: 0.7190\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 535us/step - loss: 0.5877 - acc: 0.6910 - val_loss: 0.5234 - val_acc: 0.7539\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 558us/step - loss: 0.5643 - acc: 0.7219 - val_loss: 0.5568 - val_acc: 0.7225\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 686us/step - loss: 0.5652 - acc: 0.7067 - val_loss: 0.5544 - val_acc: 0.7142\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 574us/step - loss: 0.5684 - acc: 0.7015 - val_loss: 0.5465 - val_acc: 0.7327\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 585us/step - loss: 0.5009 - acc: 0.7686 - val_loss: 0.4913 - val_acc: 0.7754\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 618us/step - loss: 0.5909 - acc: 0.6947 - val_loss: 0.5357 - val_acc: 0.7341\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 618us/step - loss: 0.5262 - acc: 0.7429 - val_loss: 0.5099 - val_acc: 0.7637\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 613us/step - loss: 0.5488 - acc: 0.7291 - val_loss: 0.5334 - val_acc: 0.7426\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 512us/step - loss: 0.5481 - acc: 0.7240 - val_loss: 0.5372 - val_acc: 0.7325\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 556us/step - loss: 0.5995 - acc: 0.6682 - val_loss: 0.5809 - val_acc: 0.6915\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 572us/step - loss: 0.5711 - acc: 0.7015 - val_loss: 0.5470 - val_acc: 0.7281\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 533us/step - loss: 0.5586 - acc: 0.7251 - val_loss: 0.5659 - val_acc: 0.7267\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 492us/step - loss: 0.5066 - acc: 0.7673 - val_loss: 0.5120 - val_acc: 0.7542\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 489us/step - loss: 0.5520 - acc: 0.7246 - val_loss: 0.5137 - val_acc: 0.7641\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 651us/step - loss: 0.5477 - acc: 0.7386 - val_loss: 0.5248 - val_acc: 0.7490\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 581us/step - loss: 0.5411 - acc: 0.7402 - val_loss: 0.5503 - val_acc: 0.7237\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 617us/step - loss: 0.5089 - acc: 0.7719 - val_loss: 0.5185 - val_acc: 0.7585\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 510us/step - loss: 0.5098 - acc: 0.7591 - val_loss: 0.5277 - val_acc: 0.7373\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 648us/step - loss: 0.5899 - acc: 0.6855 - val_loss: 0.5384 - val_acc: 0.7293\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 552us/step - loss: 0.5576 - acc: 0.7166 - val_loss: 0.5228 - val_acc: 0.7528\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 647us/step - loss: 0.5531 - acc: 0.7132 - val_loss: 0.5449 - val_acc: 0.7201\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 641us/step - loss: 0.5336 - acc: 0.7254 - val_loss: 0.5285 - val_acc: 0.7460\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 566us/step - loss: 0.5515 - acc: 0.7310 - val_loss: 0.5633 - val_acc: 0.7104\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 651us/step - loss: 0.5903 - acc: 0.6929 - val_loss: 0.5752 - val_acc: 0.7007\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 860us/step - loss: 0.5345 - acc: 0.7350 - val_loss: 0.5328 - val_acc: 0.7394\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 544us/step - loss: 0.5607 - acc: 0.7160 - val_loss: 0.5546 - val_acc: 0.7133\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 676us/step - loss: 0.5722 - acc: 0.7083 - val_loss: 0.5825 - val_acc: 0.6978\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 606us/step - loss: 0.5705 - acc: 0.7038 - val_loss: 0.5562 - val_acc: 0.7116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 538us/step - loss: 0.5562 - acc: 0.7086 - val_loss: 0.5498 - val_acc: 0.7173\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 662us/step - loss: 0.5636 - acc: 0.7070 - val_loss: 0.5231 - val_acc: 0.7365\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 598us/step - loss: 0.6023 - acc: 0.6806 - val_loss: 0.5442 - val_acc: 0.7278\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 629us/step - loss: 0.5477 - acc: 0.7241 - val_loss: 0.5510 - val_acc: 0.7260\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 527us/step - loss: 0.5439 - acc: 0.7209 - val_loss: 0.5253 - val_acc: 0.7514\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.5849 - acc: 0.7163 - val_loss: 0.5826 - val_acc: 0.7089\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 596us/step - loss: 0.5600 - acc: 0.7234 - val_loss: 0.5497 - val_acc: 0.7304\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 496us/step - loss: 0.5442 - acc: 0.7272 - val_loss: 0.5448 - val_acc: 0.7277\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 560us/step - loss: 0.5216 - acc: 0.7438 - val_loss: 0.4853 - val_acc: 0.7776\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 504us/step - loss: 0.5311 - acc: 0.7487 - val_loss: 0.5259 - val_acc: 0.7522\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 557us/step - loss: 0.5679 - acc: 0.7084 - val_loss: 0.5154 - val_acc: 0.7515\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 524us/step - loss: 0.5501 - acc: 0.7267 - val_loss: 0.5249 - val_acc: 0.7487\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 578us/step - loss: 0.5406 - acc: 0.7445 - val_loss: 0.5454 - val_acc: 0.7400\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 511us/step - loss: 0.5534 - acc: 0.7235 - val_loss: 0.5040 - val_acc: 0.7645\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 592us/step - loss: 0.5118 - acc: 0.7572 - val_loss: 0.5001 - val_acc: 0.7601\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 461us/step - loss: 0.5719 - acc: 0.7032 - val_loss: 0.5394 - val_acc: 0.7358\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 657us/step - loss: 0.5767 - acc: 0.7000 - val_loss: 0.6234 - val_acc: 0.6570\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 520us/step - loss: 0.6092 - acc: 0.6709 - val_loss: 0.5910 - val_acc: 0.6797\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 496us/step - loss: 0.5733 - acc: 0.7001 - val_loss: 0.5734 - val_acc: 0.7026\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 477us/step - loss: 0.5643 - acc: 0.7118 - val_loss: 0.5472 - val_acc: 0.7215\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 605us/step - loss: 0.5322 - acc: 0.7322 - val_loss: 0.5269 - val_acc: 0.7347\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 471us/step - loss: 0.5914 - acc: 0.6877 - val_loss: 0.5576 - val_acc: 0.7154\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 574us/step - loss: 0.5920 - acc: 0.6891 - val_loss: 0.5774 - val_acc: 0.6971\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 490us/step - loss: 0.5517 - acc: 0.7175 - val_loss: 0.5196 - val_acc: 0.7546\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 599us/step - loss: 0.5610 - acc: 0.7173 - val_loss: 0.5051 - val_acc: 0.7661\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 592us/step - loss: 0.5783 - acc: 0.6913 - val_loss: 0.5418 - val_acc: 0.7366\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 559us/step - loss: 0.5957 - acc: 0.6796 - val_loss: 0.5551 - val_acc: 0.7261\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 523us/step - loss: 0.5312 - acc: 0.7406 - val_loss: 0.5132 - val_acc: 0.7630\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 587us/step - loss: 0.5266 - acc: 0.7464 - val_loss: 0.5113 - val_acc: 0.7570\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.5448 - acc: 0.7341 - val_loss: 0.5363 - val_acc: 0.7375\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 565us/step - loss: 0.5128 - acc: 0.7493 - val_loss: 0.5105 - val_acc: 0.7545\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 483us/step - loss: 0.5511 - acc: 0.7281 - val_loss: 0.5241 - val_acc: 0.7506\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 568us/step - loss: 0.5597 - acc: 0.7209 - val_loss: 0.5515 - val_acc: 0.7438\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 557us/step - loss: 0.5545 - acc: 0.7073 - val_loss: 0.5285 - val_acc: 0.7341\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 506us/step - loss: 0.5675 - acc: 0.7132 - val_loss: 0.5398 - val_acc: 0.7339\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 627us/step - loss: 0.4940 - acc: 0.7687 - val_loss: 0.5279 - val_acc: 0.7330\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 508us/step - loss: 0.5375 - acc: 0.7425 - val_loss: 0.5140 - val_acc: 0.7568\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 557us/step - loss: 0.5154 - acc: 0.7526 - val_loss: 0.5161 - val_acc: 0.7495\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 600us/step - loss: 0.5238 - acc: 0.7518 - val_loss: 0.5296 - val_acc: 0.7475\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 488us/step - loss: 0.5171 - acc: 0.7586 - val_loss: 0.5355 - val_acc: 0.7379\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 609us/step - loss: 0.5064 - acc: 0.7608 - val_loss: 0.5584 - val_acc: 0.7038\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 519us/step - loss: 0.5742 - acc: 0.7014 - val_loss: 0.5259 - val_acc: 0.7360\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 489us/step - loss: 0.5591 - acc: 0.7047 - val_loss: 0.5304 - val_acc: 0.7358\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 560us/step - loss: 0.5432 - acc: 0.7128 - val_loss: 0.5145 - val_acc: 0.7481\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 535us/step - loss: 0.5439 - acc: 0.7211 - val_loss: 0.5334 - val_acc: 0.7308\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 528us/step - loss: 0.6327 - acc: 0.6517 - val_loss: 0.5799 - val_acc: 0.7115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 606us/step - loss: 0.5758 - acc: 0.7058 - val_loss: 0.5700 - val_acc: 0.7033\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 562us/step - loss: 0.5633 - acc: 0.7070 - val_loss: 0.5134 - val_acc: 0.7507\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 583us/step - loss: 0.5446 - acc: 0.7293 - val_loss: 0.5437 - val_acc: 0.7220\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 526us/step - loss: 0.6528 - acc: 0.6272 - val_loss: 0.5886 - val_acc: 0.6897\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 596us/step - loss: 0.5244 - acc: 0.7405 - val_loss: 0.4919 - val_acc: 0.7725\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 561us/step - loss: 0.5825 - acc: 0.7135 - val_loss: 0.5793 - val_acc: 0.7109\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 523us/step - loss: 0.5388 - acc: 0.7409 - val_loss: 0.5440 - val_acc: 0.7450\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 604us/step - loss: 0.5579 - acc: 0.7288 - val_loss: 0.5136 - val_acc: 0.7633\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 564us/step - loss: 0.5415 - acc: 0.7346 - val_loss: 0.5512 - val_acc: 0.7259\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 654us/step - loss: 0.5361 - acc: 0.7364 - val_loss: 0.5437 - val_acc: 0.7278\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 554us/step - loss: 0.5860 - acc: 0.6868 - val_loss: 0.5873 - val_acc: 0.6869\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 507us/step - loss: 0.5854 - acc: 0.6904 - val_loss: 0.5054 - val_acc: 0.7602\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 550us/step - loss: 0.5595 - acc: 0.7104 - val_loss: 0.5144 - val_acc: 0.7572\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 519us/step - loss: 0.5741 - acc: 0.6864 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 504us/step - loss: 0.5534 - acc: 0.7175 - val_loss: 0.4917 - val_acc: 0.7775\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 689us/step - loss: 0.5346 - acc: 0.7352 - val_loss: 0.5267 - val_acc: 0.7383\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 498us/step - loss: 0.5857 - acc: 0.6888 - val_loss: 0.5240 - val_acc: 0.7467\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 633us/step - loss: 0.5346 - acc: 0.7273 - val_loss: 0.5127 - val_acc: 0.7520\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 472us/step - loss: 0.5319 - acc: 0.7286 - val_loss: 0.5321 - val_acc: 0.7335\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 574us/step - loss: 0.5636 - acc: 0.7067 - val_loss: 0.5311 - val_acc: 0.7364\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 546us/step - loss: 0.5504 - acc: 0.7106 - val_loss: 0.5485 - val_acc: 0.7158\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 639us/step - loss: 0.4999 - acc: 0.7696 - val_loss: 0.4728 - val_acc: 0.7935\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 599us/step - loss: 0.5189 - acc: 0.7458 - val_loss: 0.5265 - val_acc: 0.7346\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 564us/step - loss: 0.5707 - acc: 0.6988 - val_loss: 0.5282 - val_acc: 0.7378\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 489us/step - loss: 0.5099 - acc: 0.7494 - val_loss: 0.4861 - val_acc: 0.7895\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 764us/step - loss: 0.5384 - acc: 0.7277 - val_loss: 0.5101 - val_acc: 0.7526\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 654us/step - loss: 0.5066 - acc: 0.7515 - val_loss: 0.4853 - val_acc: 0.7712\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 621us/step - loss: 0.5525 - acc: 0.7127 - val_loss: 0.5167 - val_acc: 0.7398\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 598us/step - loss: 0.4819 - acc: 0.7804 - val_loss: 0.4689 - val_acc: 0.7962\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 614us/step - loss: 0.5700 - acc: 0.7339 - val_loss: 0.5915 - val_acc: 0.7026\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 626us/step - loss: 0.6161 - acc: 0.6752 - val_loss: 0.5892 - val_acc: 0.6989\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 594us/step - loss: 0.5760 - acc: 0.7029 - val_loss: 0.5678 - val_acc: 0.7111\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 487us/step - loss: 0.5870 - acc: 0.7124 - val_loss: 0.5848 - val_acc: 0.7056\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 631us/step - loss: 0.5690 - acc: 0.7241 - val_loss: 0.5259 - val_acc: 0.7596\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 516us/step - loss: 0.5534 - acc: 0.7270 - val_loss: 0.5395 - val_acc: 0.7364\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 608us/step - loss: 0.5730 - acc: 0.7052 - val_loss: 0.5616 - val_acc: 0.7136\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 538us/step - loss: 0.5793 - acc: 0.6959 - val_loss: 0.5403 - val_acc: 0.7236\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 503us/step - loss: 0.5483 - acc: 0.7317 - val_loss: 0.5369 - val_acc: 0.7356\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 595us/step - loss: 0.5489 - acc: 0.7336 - val_loss: 0.5531 - val_acc: 0.7211\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 464us/step - loss: 0.5560 - acc: 0.7221 - val_loss: 0.5444 - val_acc: 0.7365\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 589us/step - loss: 0.5407 - acc: 0.7333 - val_loss: 0.5349 - val_acc: 0.7381\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 496us/step - loss: 0.5638 - acc: 0.7151 - val_loss: 0.5326 - val_acc: 0.7428\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 489us/step - loss: 0.5816 - acc: 0.6981 - val_loss: 0.5459 - val_acc: 0.7247\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 599us/step - loss: 0.5733 - acc: 0.7089 - val_loss: 0.5223 - val_acc: 0.7472\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 621us/step - loss: 0.5452 - acc: 0.7301 - val_loss: 0.5505 - val_acc: 0.7246\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 584us/step - loss: 0.5623 - acc: 0.7257 - val_loss: 0.5468 - val_acc: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 519us/step - loss: 0.5735 - acc: 0.7019 - val_loss: 0.5114 - val_acc: 0.7619\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 550us/step - loss: 0.5581 - acc: 0.7244 - val_loss: 0.5468 - val_acc: 0.7330\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 688us/step - loss: 0.5621 - acc: 0.7222 - val_loss: 0.5471 - val_acc: 0.7189\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 570us/step - loss: 0.5472 - acc: 0.7248 - val_loss: 0.5390 - val_acc: 0.7407\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 579us/step - loss: 0.4913 - acc: 0.7731 - val_loss: 0.4814 - val_acc: 0.7814\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 637us/step - loss: 0.5806 - acc: 0.6996 - val_loss: 0.5249 - val_acc: 0.7398\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 582us/step - loss: 0.5206 - acc: 0.7430 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 619us/step - loss: 0.5493 - acc: 0.7281 - val_loss: 0.5256 - val_acc: 0.7461\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 469us/step - loss: 0.5434 - acc: 0.7219 - val_loss: 0.5270 - val_acc: 0.7417\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 544us/step - loss: 0.5903 - acc: 0.6851 - val_loss: 0.5684 - val_acc: 0.7036\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 520us/step - loss: 0.5612 - acc: 0.7106 - val_loss: 0.5428 - val_acc: 0.7273\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 525us/step - loss: 0.5504 - acc: 0.7320 - val_loss: 0.5597 - val_acc: 0.7301\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 468us/step - loss: 0.4944 - acc: 0.7771 - val_loss: 0.5047 - val_acc: 0.7591\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 504us/step - loss: 0.5471 - acc: 0.7320 - val_loss: 0.5070 - val_acc: 0.7661\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 602us/step - loss: 0.5367 - acc: 0.7480 - val_loss: 0.5157 - val_acc: 0.7567\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 560us/step - loss: 0.5375 - acc: 0.7377 - val_loss: 0.5449 - val_acc: 0.7278\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 625us/step - loss: 0.5048 - acc: 0.7710 - val_loss: 0.5117 - val_acc: 0.7598\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 492us/step - loss: 0.5075 - acc: 0.7544 - val_loss: 0.5225 - val_acc: 0.7385\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 563us/step - loss: 0.5905 - acc: 0.6906 - val_loss: 0.5314 - val_acc: 0.7357\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 475us/step - loss: 0.5580 - acc: 0.7198 - val_loss: 0.5153 - val_acc: 0.7592\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 563us/step - loss: 0.5434 - acc: 0.7201 - val_loss: 0.5396 - val_acc: 0.7249\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 586us/step - loss: 0.5341 - acc: 0.7228 - val_loss: 0.5213 - val_acc: 0.7506\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 490us/step - loss: 0.5435 - acc: 0.7357 - val_loss: 0.5529 - val_acc: 0.7200\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 601us/step - loss: 0.5922 - acc: 0.6959 - val_loss: 0.5672 - val_acc: 0.7108\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 743us/step - loss: 0.5182 - acc: 0.7507 - val_loss: 0.5262 - val_acc: 0.7431\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 488us/step - loss: 0.5453 - acc: 0.7287 - val_loss: 0.5472 - val_acc: 0.7216\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 792us/step - loss: 0.5667 - acc: 0.7149 - val_loss: 0.5821 - val_acc: 0.6988\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 1ms/step - loss: 0.5686 - acc: 0.7105 - val_loss: 0.5476 - val_acc: 0.7173\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 596us/step - loss: 0.5419 - acc: 0.7214 - val_loss: 0.5399 - val_acc: 0.7246\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 637us/step - loss: 0.5479 - acc: 0.7178 - val_loss: 0.5129 - val_acc: 0.7454\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 598us/step - loss: 0.5962 - acc: 0.6818 - val_loss: 0.5376 - val_acc: 0.7342\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 634us/step - loss: 0.5394 - acc: 0.7351 - val_loss: 0.5414 - val_acc: 0.7337\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 491us/step - loss: 0.5416 - acc: 0.7272 - val_loss: 0.5247 - val_acc: 0.7480\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5651 - acc: 0.7237 - val_loss: 0.5590 - val_acc: 0.7226\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 576us/step - loss: 0.5591 - acc: 0.7190 - val_loss: 0.5477 - val_acc: 0.7321\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 513us/step - loss: 0.5387 - acc: 0.7343 - val_loss: 0.5399 - val_acc: 0.7279\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 592us/step - loss: 0.5141 - acc: 0.7475 - val_loss: 0.4792 - val_acc: 0.7792\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 513us/step - loss: 0.5165 - acc: 0.7585 - val_loss: 0.5216 - val_acc: 0.7542\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 557us/step - loss: 0.5577 - acc: 0.7166 - val_loss: 0.5098 - val_acc: 0.7542\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 539us/step - loss: 0.5492 - acc: 0.7264 - val_loss: 0.5206 - val_acc: 0.7504\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 598us/step - loss: 0.5352 - acc: 0.7473 - val_loss: 0.5393 - val_acc: 0.7425\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 509us/step - loss: 0.5531 - acc: 0.7191 - val_loss: 0.4986 - val_acc: 0.7676\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 599us/step - loss: 0.5065 - acc: 0.7562 - val_loss: 0.4944 - val_acc: 0.7616\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 466us/step - loss: 0.5695 - acc: 0.7063 - val_loss: 0.5359 - val_acc: 0.7369\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 672us/step - loss: 0.5684 - acc: 0.7099 - val_loss: 0.6185 - val_acc: 0.6616\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 475us/step - loss: 0.6035 - acc: 0.6766 - val_loss: 0.5882 - val_acc: 0.6844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 497us/step - loss: 0.5615 - acc: 0.7069 - val_loss: 0.5653 - val_acc: 0.7071\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 485us/step - loss: 0.5606 - acc: 0.7096 - val_loss: 0.5394 - val_acc: 0.7256\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 579us/step - loss: 0.5267 - acc: 0.7405 - val_loss: 0.5183 - val_acc: 0.7392\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 490us/step - loss: 0.5795 - acc: 0.7029 - val_loss: 0.5479 - val_acc: 0.7228\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 567us/step - loss: 0.5855 - acc: 0.6955 - val_loss: 0.5692 - val_acc: 0.7057\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 468us/step - loss: 0.5424 - acc: 0.7254 - val_loss: 0.5133 - val_acc: 0.7584\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 540us/step - loss: 0.5592 - acc: 0.7153 - val_loss: 0.4977 - val_acc: 0.7713\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 616us/step - loss: 0.5690 - acc: 0.6997 - val_loss: 0.5370 - val_acc: 0.7414\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 587us/step - loss: 0.5770 - acc: 0.7001 - val_loss: 0.5528 - val_acc: 0.7310\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 534us/step - loss: 0.5333 - acc: 0.7366 - val_loss: 0.5110 - val_acc: 0.7596\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 573us/step - loss: 0.5282 - acc: 0.7408 - val_loss: 0.5033 - val_acc: 0.7616\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.5410 - acc: 0.7342 - val_loss: 0.5313 - val_acc: 0.7420\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 557us/step - loss: 0.5066 - acc: 0.7569 - val_loss: 0.5056 - val_acc: 0.7574\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 506us/step - loss: 0.5523 - acc: 0.7257 - val_loss: 0.5182 - val_acc: 0.7546\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 584us/step - loss: 0.5440 - acc: 0.7364 - val_loss: 0.5448 - val_acc: 0.7478\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 564us/step - loss: 0.5477 - acc: 0.7139 - val_loss: 0.5190 - val_acc: 0.7412\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 502us/step - loss: 0.5608 - acc: 0.7197 - val_loss: 0.5350 - val_acc: 0.7379\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 631us/step - loss: 0.4950 - acc: 0.7657 - val_loss: 0.5232 - val_acc: 0.7391\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 534us/step - loss: 0.5335 - acc: 0.7464 - val_loss: 0.5091 - val_acc: 0.7579\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 566us/step - loss: 0.5002 - acc: 0.7658 - val_loss: 0.5090 - val_acc: 0.7522\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 602us/step - loss: 0.5237 - acc: 0.7486 - val_loss: 0.5277 - val_acc: 0.7454\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 485us/step - loss: 0.5136 - acc: 0.7569 - val_loss: 0.5317 - val_acc: 0.7407\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 626us/step - loss: 0.5034 - acc: 0.7642 - val_loss: 0.5563 - val_acc: 0.7078\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 505us/step - loss: 0.5697 - acc: 0.7055 - val_loss: 0.5221 - val_acc: 0.7425\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 476us/step - loss: 0.5504 - acc: 0.7128 - val_loss: 0.5281 - val_acc: 0.7372\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 561us/step - loss: 0.5296 - acc: 0.7230 - val_loss: 0.5140 - val_acc: 0.7458\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.5435 - acc: 0.7233 - val_loss: 0.5320 - val_acc: 0.7334\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 484us/step - loss: 0.6252 - acc: 0.6580 - val_loss: 0.5866 - val_acc: 0.7090\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 632us/step - loss: 0.5742 - acc: 0.7107 - val_loss: 0.5714 - val_acc: 0.7045\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 554us/step - loss: 0.5669 - acc: 0.7024 - val_loss: 0.5088 - val_acc: 0.7544\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 583us/step - loss: 0.5434 - acc: 0.7270 - val_loss: 0.5410 - val_acc: 0.7264\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 516us/step - loss: 0.6507 - acc: 0.6377 - val_loss: 0.5832 - val_acc: 0.6956\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 606us/step - loss: 0.5329 - acc: 0.7313 - val_loss: 0.4876 - val_acc: 0.7740\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 562us/step - loss: 0.5773 - acc: 0.7140 - val_loss: 0.5757 - val_acc: 0.7132\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 484us/step - loss: 0.5325 - acc: 0.7443 - val_loss: 0.5407 - val_acc: 0.7481\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 628us/step - loss: 0.5530 - acc: 0.7291 - val_loss: 0.5098 - val_acc: 0.7642\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 505us/step - loss: 0.5326 - acc: 0.7391 - val_loss: 0.5486 - val_acc: 0.7289\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 620us/step - loss: 0.5382 - acc: 0.7284 - val_loss: 0.5395 - val_acc: 0.7284\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 530us/step - loss: 0.5832 - acc: 0.6888 - val_loss: 0.5862 - val_acc: 0.6884\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 496us/step - loss: 0.5786 - acc: 0.6946 - val_loss: 0.5006 - val_acc: 0.7630\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 524us/step - loss: 0.5558 - acc: 0.7147 - val_loss: 0.5100 - val_acc: 0.7601\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 549us/step - loss: 0.5643 - acc: 0.6921 - val_loss: 0.5040 - val_acc: 0.7624\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 455us/step - loss: 0.5515 - acc: 0.7156 - val_loss: 0.4866 - val_acc: 0.7772\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 619us/step - loss: 0.5261 - acc: 0.7428 - val_loss: 0.5177 - val_acc: 0.7445\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 499us/step - loss: 0.5800 - acc: 0.6947 - val_loss: 0.5198 - val_acc: 0.7478\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 586us/step - loss: 0.5302 - acc: 0.7350 - val_loss: 0.5069 - val_acc: 0.7573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 488us/step - loss: 0.5304 - acc: 0.7318 - val_loss: 0.5273 - val_acc: 0.7357\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 601us/step - loss: 0.5658 - acc: 0.7139 - val_loss: 0.5215 - val_acc: 0.7420\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 519us/step - loss: 0.5467 - acc: 0.7178 - val_loss: 0.5417 - val_acc: 0.7227\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 657us/step - loss: 0.4963 - acc: 0.7682 - val_loss: 0.4688 - val_acc: 0.7952\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 606us/step - loss: 0.5159 - acc: 0.7507 - val_loss: 0.5197 - val_acc: 0.7403\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 478us/step - loss: 0.5600 - acc: 0.7136 - val_loss: 0.5227 - val_acc: 0.7413\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 454us/step - loss: 0.5101 - acc: 0.7516 - val_loss: 0.4817 - val_acc: 0.7923\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 773us/step - loss: 0.5358 - acc: 0.7308 - val_loss: 0.5073 - val_acc: 0.7541\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 620us/step - loss: 0.4977 - acc: 0.7619 - val_loss: 0.4776 - val_acc: 0.7784\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 609us/step - loss: 0.5486 - acc: 0.7188 - val_loss: 0.5132 - val_acc: 0.7454\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 550us/step - loss: 0.4755 - acc: 0.7852 - val_loss: 0.4634 - val_acc: 0.7962\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 606us/step - loss: 0.5632 - acc: 0.7364 - val_loss: 0.5800 - val_acc: 0.7099\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 611us/step - loss: 0.6001 - acc: 0.6845 - val_loss: 0.5808 - val_acc: 0.7070\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 559us/step - loss: 0.5715 - acc: 0.7068 - val_loss: 0.5552 - val_acc: 0.7282\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 469us/step - loss: 0.5819 - acc: 0.7104 - val_loss: 0.5735 - val_acc: 0.7116\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 620us/step - loss: 0.5642 - acc: 0.7328 - val_loss: 0.5197 - val_acc: 0.7633\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 502us/step - loss: 0.5415 - acc: 0.7390 - val_loss: 0.5280 - val_acc: 0.7462\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 597us/step - loss: 0.5619 - acc: 0.7129 - val_loss: 0.5575 - val_acc: 0.7126\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 486us/step - loss: 0.5768 - acc: 0.7024 - val_loss: 0.5388 - val_acc: 0.7247\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 515us/step - loss: 0.5381 - acc: 0.7363 - val_loss: 0.5321 - val_acc: 0.7401\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 580us/step - loss: 0.5479 - acc: 0.7292 - val_loss: 0.5486 - val_acc: 0.7266\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 464us/step - loss: 0.5518 - acc: 0.7261 - val_loss: 0.5409 - val_acc: 0.7393\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 567us/step - loss: 0.5408 - acc: 0.7287 - val_loss: 0.5352 - val_acc: 0.7381\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 490us/step - loss: 0.5697 - acc: 0.7076 - val_loss: 0.5269 - val_acc: 0.7464\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 539us/step - loss: 0.5772 - acc: 0.7049 - val_loss: 0.5431 - val_acc: 0.7268\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 631us/step - loss: 0.5674 - acc: 0.7080 - val_loss: 0.5165 - val_acc: 0.7534\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 667us/step - loss: 0.5301 - acc: 0.7414 - val_loss: 0.5425 - val_acc: 0.7322\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 614us/step - loss: 0.5593 - acc: 0.7264 - val_loss: 0.5425 - val_acc: 0.7324\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 536us/step - loss: 0.5762 - acc: 0.6992 - val_loss: 0.5070 - val_acc: 0.7634\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 554us/step - loss: 0.5564 - acc: 0.7221 - val_loss: 0.5413 - val_acc: 0.7359\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 702us/step - loss: 0.5598 - acc: 0.7238 - val_loss: 0.5399 - val_acc: 0.7277\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 593us/step - loss: 0.5501 - acc: 0.7218 - val_loss: 0.5323 - val_acc: 0.7441\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 596us/step - loss: 0.4892 - acc: 0.7740 - val_loss: 0.4734 - val_acc: 0.7861\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 603us/step - loss: 0.5728 - acc: 0.7066 - val_loss: 0.5161 - val_acc: 0.7454\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 582us/step - loss: 0.5145 - acc: 0.7474 - val_loss: 0.4979 - val_acc: 0.7644\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 605us/step - loss: 0.5344 - acc: 0.7389 - val_loss: 0.5193 - val_acc: 0.7484\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 467us/step - loss: 0.5380 - acc: 0.7291 - val_loss: 0.5192 - val_acc: 0.7459\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 533us/step - loss: 0.5828 - acc: 0.6876 - val_loss: 0.5593 - val_acc: 0.7134\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 524us/step - loss: 0.5550 - acc: 0.7156 - val_loss: 0.5349 - val_acc: 0.7337\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 518us/step - loss: 0.5470 - acc: 0.7343 - val_loss: 0.5508 - val_acc: 0.7374\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 502us/step - loss: 0.4964 - acc: 0.7710 - val_loss: 0.5027 - val_acc: 0.7579\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 491us/step - loss: 0.5389 - acc: 0.7328 - val_loss: 0.5022 - val_acc: 0.7691\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 587us/step - loss: 0.5339 - acc: 0.7488 - val_loss: 0.5096 - val_acc: 0.7609\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 575us/step - loss: 0.5335 - acc: 0.7393 - val_loss: 0.5407 - val_acc: 0.7299\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 655us/step - loss: 0.5003 - acc: 0.7739 - val_loss: 0.5065 - val_acc: 0.7629\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 516us/step - loss: 0.5003 - acc: 0.7611 - val_loss: 0.5168 - val_acc: 0.7426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 582us/step - loss: 0.5831 - acc: 0.6973 - val_loss: 0.5272 - val_acc: 0.7410\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 489us/step - loss: 0.5557 - acc: 0.7191 - val_loss: 0.5113 - val_acc: 0.7621\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 577us/step - loss: 0.5380 - acc: 0.7279 - val_loss: 0.5346 - val_acc: 0.7285\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 604us/step - loss: 0.5221 - acc: 0.7286 - val_loss: 0.5160 - val_acc: 0.7532\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 532us/step - loss: 0.5296 - acc: 0.7441 - val_loss: 0.5485 - val_acc: 0.7230\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 622us/step - loss: 0.5815 - acc: 0.6951 - val_loss: 0.5669 - val_acc: 0.7101\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 734us/step - loss: 0.5171 - acc: 0.7470 - val_loss: 0.5202 - val_acc: 0.7481\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 533us/step - loss: 0.5430 - acc: 0.7266 - val_loss: 0.5325 - val_acc: 0.7352\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 626us/step - loss: 0.5559 - acc: 0.7257 - val_loss: 0.5734 - val_acc: 0.7089\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 570us/step - loss: 0.5704 - acc: 0.7094 - val_loss: 0.5543 - val_acc: 0.7078\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 537us/step - loss: 0.5507 - acc: 0.7162 - val_loss: 0.5396 - val_acc: 0.7241\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 632us/step - loss: 0.5568 - acc: 0.7117 - val_loss: 0.5209 - val_acc: 0.7356\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 592us/step - loss: 0.6062 - acc: 0.6847 - val_loss: 0.5334 - val_acc: 0.7349\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 631us/step - loss: 0.5386 - acc: 0.7346 - val_loss: 0.5376 - val_acc: 0.7365\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 505us/step - loss: 0.5327 - acc: 0.7297 - val_loss: 0.5198 - val_acc: 0.7495\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.5756 - acc: 0.7218 - val_loss: 0.5708 - val_acc: 0.7183\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 582us/step - loss: 0.5569 - acc: 0.7290 - val_loss: 0.5395 - val_acc: 0.7379\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 501us/step - loss: 0.5354 - acc: 0.7348 - val_loss: 0.5339 - val_acc: 0.7363\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 554us/step - loss: 0.5136 - acc: 0.7483 - val_loss: 0.4776 - val_acc: 0.7797\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 488us/step - loss: 0.5120 - acc: 0.7639 - val_loss: 0.5182 - val_acc: 0.7548\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 555us/step - loss: 0.5596 - acc: 0.7123 - val_loss: 0.5056 - val_acc: 0.7550\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 515us/step - loss: 0.5402 - acc: 0.7330 - val_loss: 0.5152 - val_acc: 0.7527\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 605us/step - loss: 0.5257 - acc: 0.7553 - val_loss: 0.5314 - val_acc: 0.7483\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 510us/step - loss: 0.5460 - acc: 0.7252 - val_loss: 0.4911 - val_acc: 0.7713\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 596us/step - loss: 0.5015 - acc: 0.7619 - val_loss: 0.4902 - val_acc: 0.7636\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 449us/step - loss: 0.5588 - acc: 0.7163 - val_loss: 0.5308 - val_acc: 0.7390\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 661us/step - loss: 0.5695 - acc: 0.7005 - val_loss: 0.6140 - val_acc: 0.6648\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 474us/step - loss: 0.6011 - acc: 0.6774 - val_loss: 0.5844 - val_acc: 0.6874\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 492us/step - loss: 0.5599 - acc: 0.7147 - val_loss: 0.5570 - val_acc: 0.7133\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 478us/step - loss: 0.5490 - acc: 0.7203 - val_loss: 0.5323 - val_acc: 0.7318\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 575us/step - loss: 0.5221 - acc: 0.7405 - val_loss: 0.5122 - val_acc: 0.7448\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 462us/step - loss: 0.5716 - acc: 0.7080 - val_loss: 0.5389 - val_acc: 0.7285\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 556us/step - loss: 0.5735 - acc: 0.7064 - val_loss: 0.5625 - val_acc: 0.7102\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 456us/step - loss: 0.5379 - acc: 0.7256 - val_loss: 0.5091 - val_acc: 0.7626\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 552us/step - loss: 0.5503 - acc: 0.7191 - val_loss: 0.4918 - val_acc: 0.7775\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 549us/step - loss: 0.5625 - acc: 0.7055 - val_loss: 0.5245 - val_acc: 0.7489\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 572us/step - loss: 0.5736 - acc: 0.6998 - val_loss: 0.5443 - val_acc: 0.7291\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 545us/step - loss: 0.5224 - acc: 0.7397 - val_loss: 0.5075 - val_acc: 0.7616\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 592us/step - loss: 0.5282 - acc: 0.7405 - val_loss: 0.5026 - val_acc: 0.7606\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5363 - acc: 0.7355 - val_loss: 0.5254 - val_acc: 0.7431\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 562us/step - loss: 0.5060 - acc: 0.7491 - val_loss: 0.5019 - val_acc: 0.7603\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 462us/step - loss: 0.5457 - acc: 0.7356 - val_loss: 0.5144 - val_acc: 0.7566\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 629us/step - loss: 0.5436 - acc: 0.7351 - val_loss: 0.5378 - val_acc: 0.7536\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 587us/step - loss: 0.5467 - acc: 0.7163 - val_loss: 0.5104 - val_acc: 0.7489\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 506us/step - loss: 0.5577 - acc: 0.7198 - val_loss: 0.5334 - val_acc: 0.7375\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 631us/step - loss: 0.4893 - acc: 0.7692 - val_loss: 0.5195 - val_acc: 0.7451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 503us/step - loss: 0.5272 - acc: 0.7488 - val_loss: 0.5046 - val_acc: 0.7626\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 628us/step - loss: 0.5029 - acc: 0.7631 - val_loss: 0.5068 - val_acc: 0.7515\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 639us/step - loss: 0.5159 - acc: 0.7562 - val_loss: 0.5244 - val_acc: 0.7456\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 514us/step - loss: 0.5110 - acc: 0.7613 - val_loss: 0.5288 - val_acc: 0.7401\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 636us/step - loss: 0.5002 - acc: 0.7607 - val_loss: 0.5562 - val_acc: 0.7089\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 511us/step - loss: 0.5686 - acc: 0.7029 - val_loss: 0.5109 - val_acc: 0.7502\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 502us/step - loss: 0.5486 - acc: 0.7164 - val_loss: 0.5217 - val_acc: 0.7409\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 561us/step - loss: 0.5235 - acc: 0.7342 - val_loss: 0.5010 - val_acc: 0.7546\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 541us/step - loss: 0.5356 - acc: 0.7327 - val_loss: 0.5202 - val_acc: 0.7404\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 478us/step - loss: 0.6172 - acc: 0.6698 - val_loss: 0.5734 - val_acc: 0.7225\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 620us/step - loss: 0.5694 - acc: 0.7110 - val_loss: 0.5604 - val_acc: 0.7144\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 547us/step - loss: 0.5550 - acc: 0.7151 - val_loss: 0.5011 - val_acc: 0.7587\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 581us/step - loss: 0.5434 - acc: 0.7282 - val_loss: 0.5326 - val_acc: 0.7342\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 506us/step - loss: 0.6553 - acc: 0.6406 - val_loss: 0.5829 - val_acc: 0.6960\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 552us/step - loss: 0.5134 - acc: 0.7476 - val_loss: 0.4845 - val_acc: 0.7752\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 553us/step - loss: 0.5774 - acc: 0.7149 - val_loss: 0.5684 - val_acc: 0.7188\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 481us/step - loss: 0.5289 - acc: 0.7483 - val_loss: 0.5389 - val_acc: 0.7469\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 597us/step - loss: 0.5493 - acc: 0.7335 - val_loss: 0.5039 - val_acc: 0.7685\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 512us/step - loss: 0.5293 - acc: 0.7410 - val_loss: 0.5443 - val_acc: 0.7309\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 597us/step - loss: 0.5335 - acc: 0.7339 - val_loss: 0.5356 - val_acc: 0.7309\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 538us/step - loss: 0.5769 - acc: 0.6935 - val_loss: 0.5819 - val_acc: 0.6926\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 490us/step - loss: 0.5798 - acc: 0.6929 - val_loss: 0.4974 - val_acc: 0.7628\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 513us/step - loss: 0.5471 - acc: 0.7236 - val_loss: 0.5035 - val_acc: 0.7642\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 527us/step - loss: 0.5615 - acc: 0.6972 - val_loss: 0.5010 - val_acc: 0.7619\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 463us/step - loss: 0.5463 - acc: 0.7202 - val_loss: 0.4826 - val_acc: 0.7785\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 629us/step - loss: 0.5123 - acc: 0.7539 - val_loss: 0.5148 - val_acc: 0.7440\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 468us/step - loss: 0.5793 - acc: 0.6934 - val_loss: 0.5176 - val_acc: 0.7476\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 576us/step - loss: 0.5263 - acc: 0.7346 - val_loss: 0.5030 - val_acc: 0.7601\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 467us/step - loss: 0.5279 - acc: 0.7278 - val_loss: 0.5247 - val_acc: 0.7368\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 552us/step - loss: 0.5645 - acc: 0.7073 - val_loss: 0.5151 - val_acc: 0.7476\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 528us/step - loss: 0.5422 - acc: 0.7179 - val_loss: 0.5361 - val_acc: 0.7277\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 615us/step - loss: 0.4973 - acc: 0.7667 - val_loss: 0.4656 - val_acc: 0.7949\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 587us/step - loss: 0.5125 - acc: 0.7512 - val_loss: 0.5190 - val_acc: 0.7407\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 462us/step - loss: 0.5554 - acc: 0.7178 - val_loss: 0.5213 - val_acc: 0.7435\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 461us/step - loss: 0.5014 - acc: 0.7575 - val_loss: 0.4783 - val_acc: 0.7940\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 701us/step - loss: 0.5372 - acc: 0.7291 - val_loss: 0.5075 - val_acc: 0.7502\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 626us/step - loss: 0.4990 - acc: 0.7524 - val_loss: 0.4742 - val_acc: 0.7782\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 609us/step - loss: 0.5479 - acc: 0.7203 - val_loss: 0.5127 - val_acc: 0.7465\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 567us/step - loss: 0.4691 - acc: 0.7869 - val_loss: 0.4549 - val_acc: 0.7952\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 620us/step - loss: 0.5657 - acc: 0.7376 - val_loss: 0.5832 - val_acc: 0.7065\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 672us/step - loss: 0.6091 - acc: 0.6802 - val_loss: 0.5856 - val_acc: 0.7005\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 550us/step - loss: 0.5724 - acc: 0.7116 - val_loss: 0.5604 - val_acc: 0.7206\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 447us/step - loss: 0.5840 - acc: 0.7176 - val_loss: 0.5791 - val_acc: 0.7098\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 625us/step - loss: 0.5679 - acc: 0.7232 - val_loss: 0.5270 - val_acc: 0.7566\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 504us/step - loss: 0.5391 - acc: 0.7391 - val_loss: 0.5279 - val_acc: 0.7451\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 600us/step - loss: 0.5551 - acc: 0.7159 - val_loss: 0.5509 - val_acc: 0.7199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 481us/step - loss: 0.5675 - acc: 0.7074 - val_loss: 0.5342 - val_acc: 0.7280\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 524us/step - loss: 0.5408 - acc: 0.7351 - val_loss: 0.5299 - val_acc: 0.7406\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 578us/step - loss: 0.5399 - acc: 0.7415 - val_loss: 0.5462 - val_acc: 0.7274\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 466us/step - loss: 0.5467 - acc: 0.7295 - val_loss: 0.5322 - val_acc: 0.7449\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 568us/step - loss: 0.5334 - acc: 0.7375 - val_loss: 0.5335 - val_acc: 0.7364\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 470us/step - loss: 0.5570 - acc: 0.7203 - val_loss: 0.5197 - val_acc: 0.7505\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 474us/step - loss: 0.5750 - acc: 0.7042 - val_loss: 0.5427 - val_acc: 0.7260\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 595us/step - loss: 0.5628 - acc: 0.7122 - val_loss: 0.5096 - val_acc: 0.7567\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.5346 - acc: 0.7385 - val_loss: 0.5431 - val_acc: 0.7300\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 600us/step - loss: 0.5577 - acc: 0.7242 - val_loss: 0.5428 - val_acc: 0.7319\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 522us/step - loss: 0.5682 - acc: 0.7029 - val_loss: 0.5005 - val_acc: 0.7706\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 571us/step - loss: 0.5580 - acc: 0.7255 - val_loss: 0.5360 - val_acc: 0.7422\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 686us/step - loss: 0.5563 - acc: 0.7265 - val_loss: 0.5378 - val_acc: 0.7300\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 594us/step - loss: 0.5440 - acc: 0.7221 - val_loss: 0.5290 - val_acc: 0.7471\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 573us/step - loss: 0.4841 - acc: 0.7743 - val_loss: 0.4685 - val_acc: 0.7904\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 577us/step - loss: 0.5725 - acc: 0.7075 - val_loss: 0.5123 - val_acc: 0.7487\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 585us/step - loss: 0.5107 - acc: 0.7541 - val_loss: 0.4898 - val_acc: 0.7694\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 630us/step - loss: 0.5306 - acc: 0.7396 - val_loss: 0.5182 - val_acc: 0.7486\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 480us/step - loss: 0.5352 - acc: 0.7290 - val_loss: 0.5139 - val_acc: 0.7529\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 562us/step - loss: 0.5804 - acc: 0.6885 - val_loss: 0.5508 - val_acc: 0.7231\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 542us/step - loss: 0.5528 - acc: 0.7175 - val_loss: 0.5334 - val_acc: 0.7357\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 541us/step - loss: 0.5425 - acc: 0.7348 - val_loss: 0.5522 - val_acc: 0.7338\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 525us/step - loss: 0.4919 - acc: 0.7749 - val_loss: 0.4988 - val_acc: 0.7615\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 503us/step - loss: 0.5373 - acc: 0.7332 - val_loss: 0.5029 - val_acc: 0.7682\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 586us/step - loss: 0.5296 - acc: 0.7501 - val_loss: 0.5057 - val_acc: 0.7632\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 561us/step - loss: 0.5262 - acc: 0.7413 - val_loss: 0.5392 - val_acc: 0.7318\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 637us/step - loss: 0.4989 - acc: 0.7761 - val_loss: 0.5034 - val_acc: 0.7647\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 514us/step - loss: 0.4972 - acc: 0.7644 - val_loss: 0.5134 - val_acc: 0.7458\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 620us/step - loss: 0.5841 - acc: 0.6986 - val_loss: 0.5223 - val_acc: 0.7435\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 477us/step - loss: 0.5496 - acc: 0.7296 - val_loss: 0.5072 - val_acc: 0.7654\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 566us/step - loss: 0.5430 - acc: 0.7209 - val_loss: 0.5321 - val_acc: 0.7281\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 615us/step - loss: 0.5206 - acc: 0.7294 - val_loss: 0.5078 - val_acc: 0.7606\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 504us/step - loss: 0.5276 - acc: 0.7489 - val_loss: 0.5407 - val_acc: 0.7297\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 613us/step - loss: 0.5788 - acc: 0.7021 - val_loss: 0.5637 - val_acc: 0.7141\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 724us/step - loss: 0.5088 - acc: 0.7562 - val_loss: 0.5145 - val_acc: 0.7517\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 484us/step - loss: 0.5381 - acc: 0.7340 - val_loss: 0.5387 - val_acc: 0.7299\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 641us/step - loss: 0.5623 - acc: 0.7139 - val_loss: 0.5764 - val_acc: 0.7057\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 561us/step - loss: 0.5613 - acc: 0.7140 - val_loss: 0.5454 - val_acc: 0.7180\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 517us/step - loss: 0.5377 - acc: 0.7281 - val_loss: 0.5330 - val_acc: 0.7296\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 608us/step - loss: 0.5468 - acc: 0.7167 - val_loss: 0.5137 - val_acc: 0.7432\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 595us/step - loss: 0.5977 - acc: 0.6881 - val_loss: 0.5287 - val_acc: 0.7397\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 618us/step - loss: 0.5246 - acc: 0.7460 - val_loss: 0.5298 - val_acc: 0.7420\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 502us/step - loss: 0.5290 - acc: 0.7369 - val_loss: 0.5120 - val_acc: 0.7529\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.5687 - acc: 0.7232 - val_loss: 0.5675 - val_acc: 0.7214\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 591us/step - loss: 0.5526 - acc: 0.7301 - val_loss: 0.5389 - val_acc: 0.7365\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 512us/step - loss: 0.5301 - acc: 0.7361 - val_loss: 0.5314 - val_acc: 0.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 566us/step - loss: 0.5098 - acc: 0.7538 - val_loss: 0.4728 - val_acc: 0.7820\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 509us/step - loss: 0.5086 - acc: 0.7649 - val_loss: 0.5134 - val_acc: 0.7574\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 574us/step - loss: 0.5550 - acc: 0.7154 - val_loss: 0.5036 - val_acc: 0.7561\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 521us/step - loss: 0.5390 - acc: 0.7331 - val_loss: 0.5150 - val_acc: 0.7532\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 604us/step - loss: 0.5244 - acc: 0.7523 - val_loss: 0.5321 - val_acc: 0.7482\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 511us/step - loss: 0.5412 - acc: 0.7267 - val_loss: 0.4916 - val_acc: 0.7700\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 604us/step - loss: 0.5026 - acc: 0.7611 - val_loss: 0.4869 - val_acc: 0.7651\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 491us/step - loss: 0.5547 - acc: 0.7146 - val_loss: 0.5211 - val_acc: 0.7455\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 681us/step - loss: 0.5501 - acc: 0.7184 - val_loss: 0.6006 - val_acc: 0.6738\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 471us/step - loss: 0.5938 - acc: 0.6820 - val_loss: 0.5746 - val_acc: 0.6954\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 498us/step - loss: 0.5517 - acc: 0.7163 - val_loss: 0.5491 - val_acc: 0.7232\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 531us/step - loss: 0.5507 - acc: 0.7225 - val_loss: 0.5301 - val_acc: 0.7335\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 583us/step - loss: 0.5203 - acc: 0.7435 - val_loss: 0.5107 - val_acc: 0.7457\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 473us/step - loss: 0.5740 - acc: 0.7072 - val_loss: 0.5387 - val_acc: 0.7272\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 569us/step - loss: 0.5696 - acc: 0.7094 - val_loss: 0.5539 - val_acc: 0.7170\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 461us/step - loss: 0.5308 - acc: 0.7275 - val_loss: 0.5038 - val_acc: 0.7645\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 539us/step - loss: 0.5511 - acc: 0.7201 - val_loss: 0.4874 - val_acc: 0.7771\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 554us/step - loss: 0.5582 - acc: 0.7110 - val_loss: 0.5124 - val_acc: 0.7577\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 556us/step - loss: 0.5553 - acc: 0.7226 - val_loss: 0.5361 - val_acc: 0.7395\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 540us/step - loss: 0.5116 - acc: 0.7515 - val_loss: 0.4997 - val_acc: 0.7646\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 629us/step - loss: 0.5131 - acc: 0.7544 - val_loss: 0.4914 - val_acc: 0.7699\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.5290 - acc: 0.7425 - val_loss: 0.5198 - val_acc: 0.7471\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 583us/step - loss: 0.5025 - acc: 0.7495 - val_loss: 0.4996 - val_acc: 0.7624\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 513us/step - loss: 0.5351 - acc: 0.7429 - val_loss: 0.5049 - val_acc: 0.7614\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 628us/step - loss: 0.5329 - acc: 0.7413 - val_loss: 0.5298 - val_acc: 0.7564\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 578us/step - loss: 0.5426 - acc: 0.7189 - val_loss: 0.5070 - val_acc: 0.7512\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 539us/step - loss: 0.5613 - acc: 0.7210 - val_loss: 0.5304 - val_acc: 0.7410\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 653us/step - loss: 0.4819 - acc: 0.7735 - val_loss: 0.5193 - val_acc: 0.7457\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 567us/step - loss: 0.5197 - acc: 0.7553 - val_loss: 0.4994 - val_acc: 0.7665\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 636us/step - loss: 0.4973 - acc: 0.7689 - val_loss: 0.5056 - val_acc: 0.7513\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 634us/step - loss: 0.5136 - acc: 0.7538 - val_loss: 0.5207 - val_acc: 0.7469\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 486us/step - loss: 0.5091 - acc: 0.7583 - val_loss: 0.5269 - val_acc: 0.7401\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 626us/step - loss: 0.4972 - acc: 0.7628 - val_loss: 0.5539 - val_acc: 0.7089\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 521us/step - loss: 0.5675 - acc: 0.7098 - val_loss: 0.5112 - val_acc: 0.7497\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 481us/step - loss: 0.5545 - acc: 0.7135 - val_loss: 0.5247 - val_acc: 0.7411\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 571us/step - loss: 0.5205 - acc: 0.7374 - val_loss: 0.5028 - val_acc: 0.7538\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 533us/step - loss: 0.5337 - acc: 0.7350 - val_loss: 0.5256 - val_acc: 0.7364\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 484us/step - loss: 0.6198 - acc: 0.6667 - val_loss: 0.5754 - val_acc: 0.7207\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 609us/step - loss: 0.5596 - acc: 0.7212 - val_loss: 0.5589 - val_acc: 0.7153\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 544us/step - loss: 0.5505 - acc: 0.7216 - val_loss: 0.4963 - val_acc: 0.7616\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 555us/step - loss: 0.5318 - acc: 0.7388 - val_loss: 0.5275 - val_acc: 0.7381\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 570us/step - loss: 0.6511 - acc: 0.6437 - val_loss: 0.5793 - val_acc: 0.6984\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 538us/step - loss: 0.5105 - acc: 0.7502 - val_loss: 0.4831 - val_acc: 0.7764\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 576us/step - loss: 0.5662 - acc: 0.7262 - val_loss: 0.5556 - val_acc: 0.7276\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 476us/step - loss: 0.5308 - acc: 0.7515 - val_loss: 0.5389 - val_acc: 0.7461\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 606us/step - loss: 0.5474 - acc: 0.7320 - val_loss: 0.5018 - val_acc: 0.7676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 502us/step - loss: 0.5279 - acc: 0.7437 - val_loss: 0.5434 - val_acc: 0.7308\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 595us/step - loss: 0.5294 - acc: 0.7368 - val_loss: 0.5332 - val_acc: 0.7310\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 557us/step - loss: 0.5702 - acc: 0.7000 - val_loss: 0.5779 - val_acc: 0.6949\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 507us/step - loss: 0.5678 - acc: 0.7008 - val_loss: 0.4908 - val_acc: 0.7676\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 542us/step - loss: 0.5466 - acc: 0.7239 - val_loss: 0.5009 - val_acc: 0.7651\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 503us/step - loss: 0.5640 - acc: 0.6941 - val_loss: 0.4970 - val_acc: 0.7636\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 455us/step - loss: 0.5397 - acc: 0.7218 - val_loss: 0.4823 - val_acc: 0.7752\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 607us/step - loss: 0.5107 - acc: 0.7561 - val_loss: 0.5101 - val_acc: 0.7499\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 460us/step - loss: 0.5735 - acc: 0.7008 - val_loss: 0.5147 - val_acc: 0.7482\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 594us/step - loss: 0.5263 - acc: 0.7349 - val_loss: 0.4998 - val_acc: 0.7593\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 463us/step - loss: 0.5261 - acc: 0.7342 - val_loss: 0.5216 - val_acc: 0.7405\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 545us/step - loss: 0.5630 - acc: 0.7089 - val_loss: 0.5108 - val_acc: 0.7531\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 524us/step - loss: 0.5412 - acc: 0.7214 - val_loss: 0.5329 - val_acc: 0.7307\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 624us/step - loss: 0.4853 - acc: 0.7737 - val_loss: 0.4641 - val_acc: 0.7941\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 575us/step - loss: 0.5077 - acc: 0.7568 - val_loss: 0.5125 - val_acc: 0.7456\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 477us/step - loss: 0.5573 - acc: 0.7101 - val_loss: 0.5158 - val_acc: 0.7473\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 474us/step - loss: 0.4954 - acc: 0.7577 - val_loss: 0.4752 - val_acc: 0.7942\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 757us/step - loss: 0.5289 - acc: 0.7284 - val_loss: 0.5044 - val_acc: 0.7523\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 629us/step - loss: 0.4921 - acc: 0.7601 - val_loss: 0.4709 - val_acc: 0.7783\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 613us/step - loss: 0.5461 - acc: 0.7225 - val_loss: 0.5048 - val_acc: 0.7495\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 577us/step - loss: 0.4726 - acc: 0.7828 - val_loss: 0.4540 - val_acc: 0.8001\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 604us/step - loss: 0.5398 - acc: 0.7532 - val_loss: 0.5554 - val_acc: 0.7286\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 601us/step - loss: 0.5884 - acc: 0.6963 - val_loss: 0.5733 - val_acc: 0.7120\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 558us/step - loss: 0.5574 - acc: 0.7191 - val_loss: 0.5452 - val_acc: 0.7384\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 466us/step - loss: 0.5828 - acc: 0.7152 - val_loss: 0.5647 - val_acc: 0.7224\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 645us/step - loss: 0.5592 - acc: 0.7340 - val_loss: 0.5151 - val_acc: 0.7645\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 520us/step - loss: 0.5396 - acc: 0.7326 - val_loss: 0.5225 - val_acc: 0.7462\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 667us/step - loss: 0.5483 - acc: 0.7239 - val_loss: 0.5448 - val_acc: 0.7257\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 544us/step - loss: 0.5639 - acc: 0.7066 - val_loss: 0.5304 - val_acc: 0.7326\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 515us/step - loss: 0.5271 - acc: 0.7448 - val_loss: 0.5246 - val_acc: 0.7414\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 589us/step - loss: 0.5406 - acc: 0.7417 - val_loss: 0.5391 - val_acc: 0.7361\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 469us/step - loss: 0.5521 - acc: 0.7258 - val_loss: 0.5367 - val_acc: 0.7418\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 586us/step - loss: 0.5247 - acc: 0.7455 - val_loss: 0.5291 - val_acc: 0.7374\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 521us/step - loss: 0.5524 - acc: 0.7230 - val_loss: 0.5150 - val_acc: 0.7508\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 504us/step - loss: 0.5756 - acc: 0.7024 - val_loss: 0.5373 - val_acc: 0.7310\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 634us/step - loss: 0.5641 - acc: 0.7107 - val_loss: 0.5052 - val_acc: 0.7565\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 647us/step - loss: 0.5238 - acc: 0.7460 - val_loss: 0.5358 - val_acc: 0.7348\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 593us/step - loss: 0.5512 - acc: 0.7338 - val_loss: 0.5371 - val_acc: 0.7358\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 657us/step - loss: 0.5621 - acc: 0.7101 - val_loss: 0.4954 - val_acc: 0.7728\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 656us/step - loss: 0.5479 - acc: 0.7322 - val_loss: 0.5308 - val_acc: 0.7444\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 890us/step - loss: 0.5505 - acc: 0.7277 - val_loss: 0.5345 - val_acc: 0.7303\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 641us/step - loss: 0.5328 - acc: 0.7333 - val_loss: 0.5240 - val_acc: 0.7511\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 592us/step - loss: 0.4741 - acc: 0.7849 - val_loss: 0.4623 - val_acc: 0.7930\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 638us/step - loss: 0.5711 - acc: 0.7099 - val_loss: 0.5089 - val_acc: 0.7496\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 610us/step - loss: 0.5031 - acc: 0.7577 - val_loss: 0.4870 - val_acc: 0.7689\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 615us/step - loss: 0.5297 - acc: 0.7381 - val_loss: 0.5142 - val_acc: 0.7508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 482us/step - loss: 0.5266 - acc: 0.7372 - val_loss: 0.5104 - val_acc: 0.7554\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 519us/step - loss: 0.5770 - acc: 0.6914 - val_loss: 0.5487 - val_acc: 0.7243\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 517us/step - loss: 0.5456 - acc: 0.7234 - val_loss: 0.5290 - val_acc: 0.7382\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 518us/step - loss: 0.5323 - acc: 0.7420 - val_loss: 0.5408 - val_acc: 0.7430\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 481us/step - loss: 0.4890 - acc: 0.7742 - val_loss: 0.4947 - val_acc: 0.7629\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 503us/step - loss: 0.5360 - acc: 0.7358 - val_loss: 0.4977 - val_acc: 0.7713\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 609us/step - loss: 0.5260 - acc: 0.7563 - val_loss: 0.5014 - val_acc: 0.7653\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 563us/step - loss: 0.5181 - acc: 0.7516 - val_loss: 0.5354 - val_acc: 0.7352\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 628us/step - loss: 0.4915 - acc: 0.7839 - val_loss: 0.4982 - val_acc: 0.7680\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 487us/step - loss: 0.4947 - acc: 0.7646 - val_loss: 0.5116 - val_acc: 0.7455\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 563us/step - loss: 0.5910 - acc: 0.6971 - val_loss: 0.5176 - val_acc: 0.7463\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 489us/step - loss: 0.5448 - acc: 0.7318 - val_loss: 0.5025 - val_acc: 0.7674\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 567us/step - loss: 0.5418 - acc: 0.7240 - val_loss: 0.5293 - val_acc: 0.7301\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 617us/step - loss: 0.5120 - acc: 0.7400 - val_loss: 0.5036 - val_acc: 0.7607\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 502us/step - loss: 0.5226 - acc: 0.7485 - val_loss: 0.5381 - val_acc: 0.7327\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 576us/step - loss: 0.5752 - acc: 0.7087 - val_loss: 0.5620 - val_acc: 0.7166\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 757us/step - loss: 0.4971 - acc: 0.7662 - val_loss: 0.5121 - val_acc: 0.7530\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 484us/step - loss: 0.5367 - acc: 0.7354 - val_loss: 0.5334 - val_acc: 0.7337\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 610us/step - loss: 0.5556 - acc: 0.7225 - val_loss: 0.5704 - val_acc: 0.7092\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 567us/step - loss: 0.5529 - acc: 0.7209 - val_loss: 0.5370 - val_acc: 0.7226\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 504us/step - loss: 0.5369 - acc: 0.7261 - val_loss: 0.5260 - val_acc: 0.7337\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 611us/step - loss: 0.5361 - acc: 0.7233 - val_loss: 0.5085 - val_acc: 0.7444\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 574us/step - loss: 0.5926 - acc: 0.6885 - val_loss: 0.5239 - val_acc: 0.7446\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 613us/step - loss: 0.5240 - acc: 0.7443 - val_loss: 0.5285 - val_acc: 0.7443\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 524us/step - loss: 0.5174 - acc: 0.7487 - val_loss: 0.5035 - val_acc: 0.7585\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5720 - acc: 0.7191 - val_loss: 0.5708 - val_acc: 0.7197\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 591us/step - loss: 0.5525 - acc: 0.7324 - val_loss: 0.5336 - val_acc: 0.7412\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 500us/step - loss: 0.5277 - acc: 0.7411 - val_loss: 0.5242 - val_acc: 0.7446\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 565us/step - loss: 0.5079 - acc: 0.7502 - val_loss: 0.4670 - val_acc: 0.7846\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 494us/step - loss: 0.5044 - acc: 0.7690 - val_loss: 0.5084 - val_acc: 0.7586\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 540us/step - loss: 0.5563 - acc: 0.7153 - val_loss: 0.4997 - val_acc: 0.7566\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 526us/step - loss: 0.5335 - acc: 0.7382 - val_loss: 0.5109 - val_acc: 0.7534\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 591us/step - loss: 0.5191 - acc: 0.7559 - val_loss: 0.5270 - val_acc: 0.7493\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 506us/step - loss: 0.5410 - acc: 0.7291 - val_loss: 0.4858 - val_acc: 0.7732\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 577us/step - loss: 0.5008 - acc: 0.7635 - val_loss: 0.4838 - val_acc: 0.7678\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 454us/step - loss: 0.5510 - acc: 0.7140 - val_loss: 0.5116 - val_acc: 0.7524\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 675us/step - loss: 0.5413 - acc: 0.7272 - val_loss: 0.5885 - val_acc: 0.6829\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 466us/step - loss: 0.5811 - acc: 0.6894 - val_loss: 0.5601 - val_acc: 0.7053\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 513us/step - loss: 0.5437 - acc: 0.7195 - val_loss: 0.5344 - val_acc: 0.7334\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 541us/step - loss: 0.5397 - acc: 0.7298 - val_loss: 0.5208 - val_acc: 0.7424\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 604us/step - loss: 0.5136 - acc: 0.7519 - val_loss: 0.5050 - val_acc: 0.7512\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 485us/step - loss: 0.5629 - acc: 0.7150 - val_loss: 0.5304 - val_acc: 0.7323\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 579us/step - loss: 0.5652 - acc: 0.7138 - val_loss: 0.5530 - val_acc: 0.7162\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 493us/step - loss: 0.5294 - acc: 0.7357 - val_loss: 0.5045 - val_acc: 0.7642\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 608us/step - loss: 0.5389 - acc: 0.7226 - val_loss: 0.4903 - val_acc: 0.7769\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 567us/step - loss: 0.5599 - acc: 0.7125 - val_loss: 0.5306 - val_acc: 0.7512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 552us/step - loss: 0.5614 - acc: 0.7126 - val_loss: 0.5449 - val_acc: 0.7350\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 561us/step - loss: 0.5294 - acc: 0.7386 - val_loss: 0.5068 - val_acc: 0.7574\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 595us/step - loss: 0.5166 - acc: 0.7500 - val_loss: 0.4904 - val_acc: 0.7680\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.5394 - acc: 0.7346 - val_loss: 0.5218 - val_acc: 0.7464\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 562us/step - loss: 0.4972 - acc: 0.7522 - val_loss: 0.4952 - val_acc: 0.7657\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 456us/step - loss: 0.5369 - acc: 0.7358 - val_loss: 0.5044 - val_acc: 0.7636\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 566us/step - loss: 0.5269 - acc: 0.7424 - val_loss: 0.5269 - val_acc: 0.7564\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 568us/step - loss: 0.5431 - acc: 0.7185 - val_loss: 0.5051 - val_acc: 0.7518\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 508us/step - loss: 0.5616 - acc: 0.7198 - val_loss: 0.5262 - val_acc: 0.7433\n"
     ]
    }
   ],
   "source": [
    "Max_RNN=5\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(GRU(Max_RNN, return_sequences=True), input_shape=(Max_RNN,513)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(GRU(Max_RNN, return_sequences=True)))\n",
    "# model.add(GRU(output_dim = 513, input_length = 5, input_dim = 513, return_sequences=True))\n",
    "\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(TimeDistributed(Dense(513, activation='sigmoid')))\n",
    "model.add(Dense(513, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "for e in range(10):\n",
    "    for (b_x,b_y), (v_x,v_y) in zip(next_batch(data_train_x, data_train_M), next_batch(data_val_x, data_val_M)):\n",
    "        model.fit(b_x, b_y, validation_data=(v_x,v_y), shuffle=True, batch_size=100)\n",
    "\n",
    "#     model.fit( , epochs=20, steps_per_epoch=700, validation_data=next_batch_mb(DATA_val_x, DATA_val_x,10), validation_steps=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  74.60236812739446\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for v_x,v_y in next_batch(data_val_x, data_val_M):\n",
    "    scores.append( model.evaluate(v_x, v_y,verbose=0)[1] )\n",
    "scores=np.mean(scores)\n",
    "print(\"Accuracy: \",  scores*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.631143355294444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.600433949289625"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_s = 0.0\n",
    "sum_s_diff = 0.0\n",
    "\n",
    "for v_s,v_x,v_x_cmplx,v_s_cmplx in next_batchXSCmplx(data_val_s,data_val_x,val_complx_X,val_complx_S):\n",
    "    \n",
    "#     print(v_s.shape)\n",
    "#     print(v_x.shape)\n",
    "#     print(v_x_cmplx.shape)\n",
    "#     print('v_s_cmplx',v_s_cmplx.shape)\n",
    "    \n",
    "    mask = model.predict(v_x)\n",
    "    S_hat = (mask) * v_x_cmplx\n",
    "    S_hat = S_hat.reshape(-1,513).T\n",
    "    S = v_s_cmplx.T\n",
    "#     S=S.reshape(-1,513)\n",
    "    \n",
    "#     print('S.shape',S.shape)\n",
    "#     print('S_hat.shape',S_hat.shape)\n",
    "\n",
    "    S_org = librosa.istft(S, hop_length=512)\n",
    "    S_pred = librosa.istft(S_hat, hop_length=512)\n",
    "\n",
    "    sum_s += np.sum(S_org*S_org)\n",
    "    sum_s_diff += np.sum((S_org-S_pred)*(S_org-S_pred))\n",
    "    \n",
    "acc = sum_s/ sum_s_diff\n",
    "print(acc)\n",
    "\n",
    "10*np.log10(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write into audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_audio1(file_name):\n",
    "    for i in range(len(file_name)):\n",
    "        audio_fname=file_name[i].replace(\"/opt/e533/timit-homework/te/\", \"\").replace(\".wav\",\"\")\n",
    "        print(audio_fname)\n",
    "        sn, sr=librosa.load(file_name[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "        print(mag_Sn.shape)\n",
    "#         mag_Sn=mag_Sn.reshape(-1, 5, 513)\n",
    "        Stest_hat=model.predict(mag_Sn.reshape(-1, 5, 513))\n",
    "        Stest_hat=Stest_hat.reshape(-1,513)\n",
    "        S_hat=(Sn/mag_Sn)*Stest_hat.T\n",
    "\n",
    "        S_time=librosa.istft(S_hat, hop_length=512)\n",
    "        audio_fname=audio_fname + \"_recons.wav\"\n",
    "        print(audio_fname)\n",
    "        librosa.output.write_wav(audio_fname, S_time, sr)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_audio(fname_test):\n",
    "    mags = None\n",
    "    cmplxs = None\n",
    "    count=0\n",
    "    for e, file_x in enumerate(fname_test):\n",
    "        print(e)\n",
    "        \n",
    "        sn, sr = librosa.load(file_x, sr=None)\n",
    "        Sn = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "        \n",
    "        mags = np.array(mag_Sn.T) if mags is None else np.concatenate( (mags,mag_Sn.T), axis=0)\n",
    "        cmplxs = np.array(Sn.T) if cmplxs is None else np.concatenate( (cmplxs,Sn.T), axis=0)\n",
    "        \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp, mags = mags, None\n",
    "            temp_cmplx, cmplxs = cmplxs, None\n",
    "            \n",
    "            temp = temp.reshape((-1,Max_RNN,513))\n",
    "            mask = model.predict(temp)\n",
    "            \n",
    "            mask=mask.reshape(-1,513)\n",
    "            S_hat = (mask) * temp_cmplx\n",
    "            S_hat = S_hat.T\n",
    "            \n",
    "            lenght_w = S_hat.shape[1]//10\n",
    "            print(S_hat.shape[1])\n",
    "            for clip in range(10):\n",
    "                start_w = clip*lenght_w\n",
    "                end_w = (clip+1)*lenght_w\n",
    "                \n",
    "                wav = S_hat[:,start_w:end_w].T\n",
    "                S_time=librosa.istft(wav, hop_length=512)\n",
    "#                 fname = PATH_directory+PATH_denoise+ e + \"_redoise.wav\"\n",
    "#                 audio_fname=file_x.replace(\"/opt/e533/timit-homework/te/\", \"\").replace(\".wav\",\"\")\n",
    "                audio_fname=\"./data/\"+ str(count) + \"_recons.wav\"\n",
    "                print(audio_fname)\n",
    "                count+=1\n",
    "                librosa.output.write_wav(audio_fname, S_time, sr)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "1100\n",
      "./data/0_recons.wav\n",
      "./data/1_recons.wav\n",
      "./data/2_recons.wav\n",
      "./data/3_recons.wav\n",
      "./data/4_recons.wav\n",
      "./data/5_recons.wav\n",
      "./data/6_recons.wav\n",
      "./data/7_recons.wav\n",
      "./data/8_recons.wav\n",
      "./data/9_recons.wav\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "1090\n",
      "./data/10_recons.wav\n",
      "./data/11_recons.wav\n",
      "./data/12_recons.wav\n",
      "./data/13_recons.wav\n",
      "./data/14_recons.wav\n",
      "./data/15_recons.wav\n",
      "./data/16_recons.wav\n",
      "./data/17_recons.wav\n",
      "./data/18_recons.wav\n",
      "./data/19_recons.wav\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "1730\n",
      "./data/20_recons.wav\n",
      "./data/21_recons.wav\n",
      "./data/22_recons.wav\n",
      "./data/23_recons.wav\n",
      "./data/24_recons.wav\n",
      "./data/25_recons.wav\n",
      "./data/26_recons.wav\n",
      "./data/27_recons.wav\n",
      "./data/28_recons.wav\n",
      "./data/29_recons.wav\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "1650\n",
      "./data/30_recons.wav\n",
      "./data/31_recons.wav\n",
      "./data/32_recons.wav\n",
      "./data/33_recons.wav\n",
      "./data/34_recons.wav\n",
      "./data/35_recons.wav\n",
      "./data/36_recons.wav\n",
      "./data/37_recons.wav\n",
      "./data/38_recons.wav\n",
      "./data/39_recons.wav\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "1080\n",
      "./data/40_recons.wav\n",
      "./data/41_recons.wav\n",
      "./data/42_recons.wav\n",
      "./data/43_recons.wav\n",
      "./data/44_recons.wav\n",
      "./data/45_recons.wav\n",
      "./data/46_recons.wav\n",
      "./data/47_recons.wav\n",
      "./data/48_recons.wav\n",
      "./data/49_recons.wav\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "1160\n",
      "./data/50_recons.wav\n",
      "./data/51_recons.wav\n",
      "./data/52_recons.wav\n",
      "./data/53_recons.wav\n",
      "./data/54_recons.wav\n",
      "./data/55_recons.wav\n",
      "./data/56_recons.wav\n",
      "./data/57_recons.wav\n",
      "./data/58_recons.wav\n",
      "./data/59_recons.wav\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "1510\n",
      "./data/60_recons.wav\n",
      "./data/61_recons.wav\n",
      "./data/62_recons.wav\n",
      "./data/63_recons.wav\n",
      "./data/64_recons.wav\n",
      "./data/65_recons.wav\n",
      "./data/66_recons.wav\n",
      "./data/67_recons.wav\n",
      "./data/68_recons.wav\n",
      "./data/69_recons.wav\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "1440\n",
      "./data/70_recons.wav\n",
      "./data/71_recons.wav\n",
      "./data/72_recons.wav\n",
      "./data/73_recons.wav\n",
      "./data/74_recons.wav\n",
      "./data/75_recons.wav\n",
      "./data/76_recons.wav\n",
      "./data/77_recons.wav\n",
      "./data/78_recons.wav\n",
      "./data/79_recons.wav\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "980\n",
      "./data/80_recons.wav\n",
      "./data/81_recons.wav\n",
      "./data/82_recons.wav\n",
      "./data/83_recons.wav\n",
      "./data/84_recons.wav\n",
      "./data/85_recons.wav\n",
      "./data/86_recons.wav\n",
      "./data/87_recons.wav\n",
      "./data/88_recons.wav\n",
      "./data/89_recons.wav\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "1040\n",
      "./data/90_recons.wav\n",
      "./data/91_recons.wav\n",
      "./data/92_recons.wav\n",
      "./data/93_recons.wav\n",
      "./data/94_recons.wav\n",
      "./data/95_recons.wav\n",
      "./data/96_recons.wav\n",
      "./data/97_recons.wav\n",
      "./data/98_recons.wav\n",
      "./data/99_recons.wav\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "1080\n",
      "./data/100_recons.wav\n",
      "./data/101_recons.wav\n",
      "./data/102_recons.wav\n",
      "./data/103_recons.wav\n",
      "./data/104_recons.wav\n",
      "./data/105_recons.wav\n",
      "./data/106_recons.wav\n",
      "./data/107_recons.wav\n",
      "./data/108_recons.wav\n",
      "./data/109_recons.wav\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "1200\n",
      "./data/110_recons.wav\n",
      "./data/111_recons.wav\n",
      "./data/112_recons.wav\n",
      "./data/113_recons.wav\n",
      "./data/114_recons.wav\n",
      "./data/115_recons.wav\n",
      "./data/116_recons.wav\n",
      "./data/117_recons.wav\n",
      "./data/118_recons.wav\n",
      "./data/119_recons.wav\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "1060\n",
      "./data/120_recons.wav\n",
      "./data/121_recons.wav\n",
      "./data/122_recons.wav\n",
      "./data/123_recons.wav\n",
      "./data/124_recons.wav\n",
      "./data/125_recons.wav\n",
      "./data/126_recons.wav\n",
      "./data/127_recons.wav\n",
      "./data/128_recons.wav\n",
      "./data/129_recons.wav\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "790\n",
      "./data/130_recons.wav\n",
      "./data/131_recons.wav\n",
      "./data/132_recons.wav\n",
      "./data/133_recons.wav\n",
      "./data/134_recons.wav\n",
      "./data/135_recons.wav\n",
      "./data/136_recons.wav\n",
      "./data/137_recons.wav\n",
      "./data/138_recons.wav\n",
      "./data/139_recons.wav\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "1190\n",
      "./data/140_recons.wav\n",
      "./data/141_recons.wav\n",
      "./data/142_recons.wav\n",
      "./data/143_recons.wav\n",
      "./data/144_recons.wav\n",
      "./data/145_recons.wav\n",
      "./data/146_recons.wav\n",
      "./data/147_recons.wav\n",
      "./data/148_recons.wav\n",
      "./data/149_recons.wav\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "880\n",
      "./data/150_recons.wav\n",
      "./data/151_recons.wav\n",
      "./data/152_recons.wav\n",
      "./data/153_recons.wav\n",
      "./data/154_recons.wav\n",
      "./data/155_recons.wav\n",
      "./data/156_recons.wav\n",
      "./data/157_recons.wav\n",
      "./data/158_recons.wav\n",
      "./data/159_recons.wav\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "960\n",
      "./data/160_recons.wav\n",
      "./data/161_recons.wav\n",
      "./data/162_recons.wav\n",
      "./data/163_recons.wav\n",
      "./data/164_recons.wav\n",
      "./data/165_recons.wav\n",
      "./data/166_recons.wav\n",
      "./data/167_recons.wav\n",
      "./data/168_recons.wav\n",
      "./data/169_recons.wav\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "570\n",
      "./data/170_recons.wav\n",
      "./data/171_recons.wav\n",
      "./data/172_recons.wav\n",
      "./data/173_recons.wav\n",
      "./data/174_recons.wav\n",
      "./data/175_recons.wav\n",
      "./data/176_recons.wav\n",
      "./data/177_recons.wav\n",
      "./data/178_recons.wav\n",
      "./data/179_recons.wav\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "890\n",
      "./data/180_recons.wav\n",
      "./data/181_recons.wav\n",
      "./data/182_recons.wav\n",
      "./data/183_recons.wav\n",
      "./data/184_recons.wav\n",
      "./data/185_recons.wav\n",
      "./data/186_recons.wav\n",
      "./data/187_recons.wav\n",
      "./data/188_recons.wav\n",
      "./data/189_recons.wav\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "890\n",
      "./data/190_recons.wav\n",
      "./data/191_recons.wav\n",
      "./data/192_recons.wav\n",
      "./data/193_recons.wav\n",
      "./data/194_recons.wav\n",
      "./data/195_recons.wav\n",
      "./data/196_recons.wav\n",
      "./data/197_recons.wav\n",
      "./data/198_recons.wav\n",
      "./data/199_recons.wav\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "980\n",
      "./data/200_recons.wav\n",
      "./data/201_recons.wav\n",
      "./data/202_recons.wav\n",
      "./data/203_recons.wav\n",
      "./data/204_recons.wav\n",
      "./data/205_recons.wav\n",
      "./data/206_recons.wav\n",
      "./data/207_recons.wav\n",
      "./data/208_recons.wav\n",
      "./data/209_recons.wav\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "780\n",
      "./data/210_recons.wav\n",
      "./data/211_recons.wav\n",
      "./data/212_recons.wav\n",
      "./data/213_recons.wav\n",
      "./data/214_recons.wav\n",
      "./data/215_recons.wav\n",
      "./data/216_recons.wav\n",
      "./data/217_recons.wav\n",
      "./data/218_recons.wav\n",
      "./data/219_recons.wav\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "1250\n",
      "./data/220_recons.wav\n",
      "./data/221_recons.wav\n",
      "./data/222_recons.wav\n",
      "./data/223_recons.wav\n",
      "./data/224_recons.wav\n",
      "./data/225_recons.wav\n",
      "./data/226_recons.wav\n",
      "./data/227_recons.wav\n",
      "./data/228_recons.wav\n",
      "./data/229_recons.wav\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "1950\n",
      "./data/230_recons.wav\n",
      "./data/231_recons.wav\n",
      "./data/232_recons.wav\n",
      "./data/233_recons.wav\n",
      "./data/234_recons.wav\n",
      "./data/235_recons.wav\n",
      "./data/236_recons.wav\n",
      "./data/237_recons.wav\n",
      "./data/238_recons.wav\n",
      "./data/239_recons.wav\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "1010\n",
      "./data/240_recons.wav\n",
      "./data/241_recons.wav\n",
      "./data/242_recons.wav\n",
      "./data/243_recons.wav\n",
      "./data/244_recons.wav\n",
      "./data/245_recons.wav\n",
      "./data/246_recons.wav\n",
      "./data/247_recons.wav\n",
      "./data/248_recons.wav\n",
      "./data/249_recons.wav\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "850\n",
      "./data/250_recons.wav\n",
      "./data/251_recons.wav\n",
      "./data/252_recons.wav\n",
      "./data/253_recons.wav\n",
      "./data/254_recons.wav\n",
      "./data/255_recons.wav\n",
      "./data/256_recons.wav\n",
      "./data/257_recons.wav\n",
      "./data/258_recons.wav\n",
      "./data/259_recons.wav\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "780\n",
      "./data/260_recons.wav\n",
      "./data/261_recons.wav\n",
      "./data/262_recons.wav\n",
      "./data/263_recons.wav\n",
      "./data/264_recons.wav\n",
      "./data/265_recons.wav\n",
      "./data/266_recons.wav\n",
      "./data/267_recons.wav\n",
      "./data/268_recons.wav\n",
      "./data/269_recons.wav\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "1010\n",
      "./data/270_recons.wav\n",
      "./data/271_recons.wav\n",
      "./data/272_recons.wav\n",
      "./data/273_recons.wav\n",
      "./data/274_recons.wav\n",
      "./data/275_recons.wav\n",
      "./data/276_recons.wav\n",
      "./data/277_recons.wav\n",
      "./data/278_recons.wav\n",
      "./data/279_recons.wav\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "880\n",
      "./data/280_recons.wav\n",
      "./data/281_recons.wav\n",
      "./data/282_recons.wav\n",
      "./data/283_recons.wav\n",
      "./data/284_recons.wav\n",
      "./data/285_recons.wav\n",
      "./data/286_recons.wav\n",
      "./data/287_recons.wav\n",
      "./data/288_recons.wav\n",
      "./data/289_recons.wav\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "810\n",
      "./data/290_recons.wav\n",
      "./data/291_recons.wav\n",
      "./data/292_recons.wav\n",
      "./data/293_recons.wav\n",
      "./data/294_recons.wav\n",
      "./data/295_recons.wav\n",
      "./data/296_recons.wav\n",
      "./data/297_recons.wav\n",
      "./data/298_recons.wav\n",
      "./data/299_recons.wav\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "1390\n",
      "./data/300_recons.wav\n",
      "./data/301_recons.wav\n",
      "./data/302_recons.wav\n",
      "./data/303_recons.wav\n",
      "./data/304_recons.wav\n",
      "./data/305_recons.wav\n",
      "./data/306_recons.wav\n",
      "./data/307_recons.wav\n",
      "./data/308_recons.wav\n",
      "./data/309_recons.wav\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "1400\n",
      "./data/310_recons.wav\n",
      "./data/311_recons.wav\n",
      "./data/312_recons.wav\n",
      "./data/313_recons.wav\n",
      "./data/314_recons.wav\n",
      "./data/315_recons.wav\n",
      "./data/316_recons.wav\n",
      "./data/317_recons.wav\n",
      "./data/318_recons.wav\n",
      "./data/319_recons.wav\n",
      "320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "1610\n",
      "./data/320_recons.wav\n",
      "./data/321_recons.wav\n",
      "./data/322_recons.wav\n",
      "./data/323_recons.wav\n",
      "./data/324_recons.wav\n",
      "./data/325_recons.wav\n",
      "./data/326_recons.wav\n",
      "./data/327_recons.wav\n",
      "./data/328_recons.wav\n",
      "./data/329_recons.wav\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "1180\n",
      "./data/330_recons.wav\n",
      "./data/331_recons.wav\n",
      "./data/332_recons.wav\n",
      "./data/333_recons.wav\n",
      "./data/334_recons.wav\n",
      "./data/335_recons.wav\n",
      "./data/336_recons.wav\n",
      "./data/337_recons.wav\n",
      "./data/338_recons.wav\n",
      "./data/339_recons.wav\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "560\n",
      "./data/340_recons.wav\n",
      "./data/341_recons.wav\n",
      "./data/342_recons.wav\n",
      "./data/343_recons.wav\n",
      "./data/344_recons.wav\n",
      "./data/345_recons.wav\n",
      "./data/346_recons.wav\n",
      "./data/347_recons.wav\n",
      "./data/348_recons.wav\n",
      "./data/349_recons.wav\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "1200\n",
      "./data/350_recons.wav\n",
      "./data/351_recons.wav\n",
      "./data/352_recons.wav\n",
      "./data/353_recons.wav\n",
      "./data/354_recons.wav\n",
      "./data/355_recons.wav\n",
      "./data/356_recons.wav\n",
      "./data/357_recons.wav\n",
      "./data/358_recons.wav\n",
      "./data/359_recons.wav\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "880\n",
      "./data/360_recons.wav\n",
      "./data/361_recons.wav\n",
      "./data/362_recons.wav\n",
      "./data/363_recons.wav\n",
      "./data/364_recons.wav\n",
      "./data/365_recons.wav\n",
      "./data/366_recons.wav\n",
      "./data/367_recons.wav\n",
      "./data/368_recons.wav\n",
      "./data/369_recons.wav\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "1560\n",
      "./data/370_recons.wav\n",
      "./data/371_recons.wav\n",
      "./data/372_recons.wav\n",
      "./data/373_recons.wav\n",
      "./data/374_recons.wav\n",
      "./data/375_recons.wav\n",
      "./data/376_recons.wav\n",
      "./data/377_recons.wav\n",
      "./data/378_recons.wav\n",
      "./data/379_recons.wav\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "680\n",
      "./data/380_recons.wav\n",
      "./data/381_recons.wav\n",
      "./data/382_recons.wav\n",
      "./data/383_recons.wav\n",
      "./data/384_recons.wav\n",
      "./data/385_recons.wav\n",
      "./data/386_recons.wav\n",
      "./data/387_recons.wav\n",
      "./data/388_recons.wav\n",
      "./data/389_recons.wav\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "1100\n",
      "./data/390_recons.wav\n",
      "./data/391_recons.wav\n",
      "./data/392_recons.wav\n",
      "./data/393_recons.wav\n",
      "./data/394_recons.wav\n",
      "./data/395_recons.wav\n",
      "./data/396_recons.wav\n",
      "./data/397_recons.wav\n",
      "./data/398_recons.wav\n",
      "./data/399_recons.wav\n"
     ]
    }
   ],
   "source": [
    "write_audio(fname_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
