{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hw-2: Task 2\n",
    "### Taslima Akter\n",
    "### ID: takter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file names for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/e533/timit-homework/tr/trx0100.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### File names for Training Data\n",
    "\n",
    "import glob\n",
    "import librosa\n",
    "fname_trn=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/tr/trn*.wav'):\n",
    "    (fname_trn.append(filename))\n",
    "fname_trn.sort()\n",
    "# fname_trn\n",
    "\n",
    "fname_trs=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/tr/trs*.wav'):\n",
    "    (fname_trs.append(filename))\n",
    "fname_trs.sort()\n",
    "# fname_trs\n",
    "\n",
    "fname_trx=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/tr/trx*.wav'):\n",
    "    (fname_trx.append(filename))\n",
    "fname_trx.sort()\n",
    "fname_trx[100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file names for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### File names for validation Data\n",
    "\n",
    "fname_val_n=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/v/vn*.wav'):\n",
    "    (fname_val_n.append(filename))\n",
    "fname_val_n.sort()\n",
    "# print(fname_val_n)\n",
    "\n",
    "fname_val_s=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/v/vs*.wav'):\n",
    "    (fname_val_s.append(filename))\n",
    "fname_val_s.sort()\n",
    "# fname_trs\n",
    "\n",
    "fname_val_x=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/v/vx*.wav'):\n",
    "    (fname_val_x.append(filename))\n",
    "fname_val_x.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file names for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### File names for Test Data\n",
    "\n",
    "fname_test=[]\n",
    "for filename in glob.glob('/opt/e533/timit-homework/te/tex*.wav'):\n",
    "    (fname_test.append(filename))\n",
    "fname_test.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data into txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function For writing file\n",
    "import librosa\n",
    "def write_file(file_name, fname_list):\n",
    "    ### Writing training data S\n",
    "\n",
    "    with open(file_name, 'wb') as fs:\n",
    "        for i in range(len(fname_list)):\n",
    "            sn, sr=librosa.load(fname_list[i], sr=None)\n",
    "            Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "            mag_Sn=np.abs(Sn)\n",
    "    #         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "            np.savetxt(fs, mag_Sn, fmt='%.5f')\n",
    "            fs.write(b'\\n')\n",
    "    fs.close()            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing complex data X into file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function For writing just X into file\n",
    "import librosa\n",
    "def write_file_X(file_name, fname_list):\n",
    "    ### Writing training data S\n",
    "\n",
    "    with open(file_name, 'wb') as fs:\n",
    "        for i in range(len(fname_list)):\n",
    "            sn, sr=librosa.load(fname_list[i], sr=None)\n",
    "            Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "#             mag_Sn=np.abs(Sn)\n",
    "    #         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "            np.savetxt(fs, Sn, fmt='%.5f')\n",
    "            fs.write(b'\\n')\n",
    "    fs.close()            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n"
     ]
    }
   ],
   "source": [
    "### Writing training data S\n",
    "Train_complx_X=[]\n",
    "\n",
    "for i in range(len(fname_trx)):\n",
    "    print(i)\n",
    "    \n",
    "    sn, sr=librosa.load(fname_trx[i], sr=None)\n",
    "    Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    Train_complx_X.append(np.array(Sn))\n",
    "\n",
    "\n",
    "#             mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n"
     ]
    }
   ],
   "source": [
    "### Writing training data S\n",
    "val_complx_X=[]\n",
    "\n",
    "for i in range(len(fname_val_x)):\n",
    "    print(i)\n",
    "    \n",
    "    sn, sr=librosa.load(fname_val_x[i], sr=None)\n",
    "    Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    val_complx_X.append(np.array(Sn))\n",
    "\n",
    "\n",
    "#             mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n"
     ]
    }
   ],
   "source": [
    "### Writing training data S\n",
    "val_complx_S=[]\n",
    "\n",
    "for i in range(len(fname_val_s)):\n",
    "    print(i)\n",
    "    \n",
    "    sn, sr=librosa.load(fname_val_s[i], sr=None)\n",
    "    Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    val_complx_S.append(np.array(Sn))\n",
    "\n",
    "\n",
    "#             mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "### Writing training data S\n",
    "test_complx_S=[]\n",
    "\n",
    "for i in range(len(fname_test)):\n",
    "    print(i)\n",
    "    \n",
    "    sn, sr=librosa.load(fname_test[i], sr=None)\n",
    "    Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    test_complx_S.append(np.array(Sn))\n",
    "\n",
    "\n",
    "#             mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling functions to write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"train_s.txt\", fname_trs)\n",
    "write_file(\"train_n.txt\", fname_trn)\n",
    "write_file(\"train_x.txt\", fname_trx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write validation files\n",
    "\n",
    "write_file(\"validation_s.txt\", fname_val_s)\n",
    "write_file(\"validation_n.txt\", fname_val_n)\n",
    "write_file(\"validation_x.txt\", fname_val_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file_X(\"train_x_tr.txt\", fname_trx)\n",
    "write_file_X(\"validation_x_tr.txt\", fname_trx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"test_data.txt\", fname_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing training data N\n",
    "import librosa\n",
    "\n",
    "count=0\n",
    "total_train_s=[]\n",
    "with open('train_n.txt', 'wb') as fn:\n",
    "    for i in range(len(fname_trn)):\n",
    "        sn, sr=librosa.load(fname_trn[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "        np.savetxt(fn, mag_Sn, fmt='%.5f')\n",
    "        fn.write(b'\\n')\n",
    "fn.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing training data S\n",
    "\n",
    "with open('train_s.txt', 'wb') as fs:\n",
    "    for i in range(len(fname_trs)):\n",
    "        sn, sr=librosa.load(fname_trs[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "        np.savetxt(fs, mag_Sn, fmt='%.5f')\n",
    "        fs.write(b'\\n')\n",
    "fs.close()            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing training file X\n",
    "\n",
    "with open('train_x.txt', 'wb') as fs:\n",
    "    for i in range(len(fname_trx)):\n",
    "        sn, sr=librosa.load(fname_trx[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "#         trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "        np.savetxt(fs, mag_Sn, fmt='%.5f')\n",
    "        fs.write(b'\\n')\n",
    "fs.close()            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for Reading file\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name) as f:\n",
    "        lines=f.readlines()\n",
    "        print(len(lines))\n",
    "        sentence_full=[]\n",
    "        count = 0\n",
    "        sentence=[]\n",
    "        for line in lines:\n",
    "\n",
    "            if count < 513:\n",
    "                if count ==0:\n",
    "                    sentence=np.array(np.fromstring(line, dtype=complex_, sep=' '), ndmin=2)\n",
    "                    count+=1\n",
    "                else:\n",
    "                    myarray = np.array(np.fromstring(line, dtype=complex_, sep=' '), ndmin=2)\n",
    "                    sentence=np.concatenate((sentence, myarray), axis=0)\n",
    "                    count+=1\n",
    "            else:\n",
    "                sentence_full.append(sentence) \n",
    "                count=0\n",
    "                sentence=[]\n",
    "        return sentence_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616800\n",
      "616800\n",
      "616800\n"
     ]
    }
   ],
   "source": [
    "data_train_n = read_file(\"train_n.txt\")\n",
    "data_train_s = read_file(\"train_s.txt\")\n",
    "data_train_x = read_file(\"train_x.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616800\n",
      "616800\n",
      "616800\n"
     ]
    }
   ],
   "source": [
    "data_val_n = read_file(\"validation_n.txt\")\n",
    "data_val_s = read_file(\"validation_s.txt\")\n",
    "data_val_x = read_file(\"validation_x.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read complex X from training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616800\n",
      "616800\n"
     ]
    }
   ],
   "source": [
    "data_train_xtr = read_file(\"train_x_tr.txt\")\n",
    "data_val_xtr = read_file(\"validation_x_tr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_val_xtr)\n",
    "data_val_xtr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205600\n"
     ]
    }
   ],
   "source": [
    "data_test = read_file(\"test_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating M for training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating M:\n",
    "data_train_M=[]\n",
    "data_val_M=[]\n",
    "for i in range(len(data_train_s)):\n",
    "    data_train_M.append(1*(data_train_s[i]>data_train_n[i]))\n",
    "    data_val_M.append(1*(data_val_s[i]>data_val_n[i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 65)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_M[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batchXSCmplx(X_, S_, X_cmplx, S_cmplx):\n",
    "    \n",
    "    batch_x = None\n",
    "    batch_s = None\n",
    "    batch_x_cmplx = None\n",
    "    batch_s_cmplx = None\n",
    "    \n",
    "    for e,(x, s, x_cmplx, s_cmplx) in enumerate(zip(X_, S_, X_cmplx, S_cmplx)): \n",
    "        batch_x = np.array(x.T) if batch_x is None else np.concatenate( (batch_x,x.T), axis=0)\n",
    "        batch_s = np.array(s.T) if batch_s is None else np.concatenate( (batch_s,s.T), axis=0)\n",
    "        batch_x_cmplx = np.array(x_cmplx.T) if batch_x_cmplx is None else np.concatenate( (batch_x_cmplx,x_cmplx.T), axis=0)\n",
    "        batch_s_cmplx = np.array(s_cmplx.T) if batch_s_cmplx is None else np.concatenate( (batch_s_cmplx,s_cmplx.T), axis=0)\n",
    " \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp_x, batch_x = batch_x, None\n",
    "            temp_s, batch_s = batch_s, None\n",
    "            temp_x_cmplx, batch_x_cmplx = batch_x_cmplx, None\n",
    "            temp_s_cmplx, batch_s_cmplx = batch_s_cmplx, None\n",
    "            \n",
    "            temp_x = temp_x.reshape((-1,Max_RNN,513))\n",
    "            temp_s = temp_s.reshape((-1,Max_RNN,513))\n",
    "            temp_x_cmplx = temp_x_cmplx.reshape((-1,Max_RNN,513))\n",
    "#             temp_s_cmplx = temp_s_cmplx.reshape((-1,Max_RNN,513))\n",
    "\n",
    "            yield temp_x, temp_s, temp_x_cmplx, temp_s_cmplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batchX(X_):\n",
    "    \n",
    "    batch_x = None\n",
    "    \n",
    "    for e,x in enumerate(X_): \n",
    "        batch_x = np.array(x.T) if batch_x is None else np.concatenate( (batch_x,x.T), axis=0)\n",
    "        \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp_x, batch_x = batch_x, None\n",
    "            \n",
    "            temp_x = temp_x.reshape((-1,Max_RNN,513))\n",
    "\n",
    "            yield temp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X_,Y_):\n",
    "    \n",
    "    batch_x, batch_y = None, None\n",
    "    \n",
    "    for e,(x,y) in enumerate(zip(X_,Y_)):\n",
    "#         print(e)\n",
    "        \n",
    "        batch_x = np.array(x.T) if batch_x is None else np.concatenate( (batch_x,x.T), axis=0)\n",
    "        batch_y = np.array(y.T) if batch_y is None else np.concatenate( (batch_y,y.T), axis=0)\n",
    "        \n",
    "#         print('batch_x',batch_x.shape)\n",
    "#         print('batch_y',batch_y.shape)\n",
    "        \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp_x, batch_x = batch_x, None\n",
    "            temp_y, batch_y = batch_y, None\n",
    "            \n",
    "            temp_x = temp_x.reshape((-1,Max_RNN,513))\n",
    "            temp_y = temp_y.reshape((-1,Max_RNN,513))\n",
    "\n",
    "#             print('temp_x',temp_x.shape)\n",
    "#             print('temp_y',temp_y.shape)\n",
    "        \n",
    "            yield temp_x,temp_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_9 (Bidirection (None, 5, 10)             20760     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 10)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 5, 10)             640       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5, 513)            5643      \n",
      "=================================================================\n",
      "Total params: 27,043\n",
      "Trainable params: 27,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.6931 - acc: 0.5045 - val_loss: 0.6929 - val_acc: 0.5286\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 615us/step - loss: 0.6927 - acc: 0.5407 - val_loss: 0.6926 - val_acc: 0.5294\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 679us/step - loss: 0.6920 - acc: 0.5727 - val_loss: 0.6920 - val_acc: 0.5427\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 729us/step - loss: 0.6916 - acc: 0.5698 - val_loss: 0.6921 - val_acc: 0.5219\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 589us/step - loss: 0.6912 - acc: 0.5456 - val_loss: 0.6911 - val_acc: 0.5452\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 759us/step - loss: 0.6895 - acc: 0.6045 - val_loss: 0.6913 - val_acc: 0.5310\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 613us/step - loss: 0.6898 - acc: 0.5655 - val_loss: 0.6885 - val_acc: 0.5915\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 586us/step - loss: 0.6893 - acc: 0.5703 - val_loss: 0.6898 - val_acc: 0.5420\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 681us/step - loss: 0.6883 - acc: 0.5832 - val_loss: 0.6889 - val_acc: 0.5561\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 649us/step - loss: 0.6891 - acc: 0.5608 - val_loss: 0.6931 - val_acc: 0.4854\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 579us/step - loss: 0.6924 - acc: 0.5034 - val_loss: 0.6938 - val_acc: 0.4787\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 734us/step - loss: 0.6843 - acc: 0.6064 - val_loss: 0.6897 - val_acc: 0.5263\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 660us/step - loss: 0.6860 - acc: 0.5855 - val_loss: 0.6864 - val_acc: 0.5635\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 685us/step - loss: 0.6824 - acc: 0.6231 - val_loss: 0.6858 - val_acc: 0.5595\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 649us/step - loss: 0.6892 - acc: 0.5434 - val_loss: 0.6943 - val_acc: 0.4828\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 689us/step - loss: 0.6810 - acc: 0.6053 - val_loss: 0.6818 - val_acc: 0.5773\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 658us/step - loss: 0.6876 - acc: 0.5463 - val_loss: 0.7012 - val_acc: 0.4209\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 599us/step - loss: 0.6891 - acc: 0.5274 - val_loss: 0.6853 - val_acc: 0.5548\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 696us/step - loss: 0.6822 - acc: 0.5796 - val_loss: 0.6850 - val_acc: 0.5376\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 598us/step - loss: 0.6810 - acc: 0.5770 - val_loss: 0.6856 - val_acc: 0.5394\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 742us/step - loss: 0.6832 - acc: 0.5742 - val_loss: 0.6806 - val_acc: 0.5727\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 649us/step - loss: 0.6869 - acc: 0.5568 - val_loss: 0.6878 - val_acc: 0.5274\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 589us/step - loss: 0.6812 - acc: 0.5962 - val_loss: 0.6660 - val_acc: 0.6582\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 629us/step - loss: 0.6725 - acc: 0.6365 - val_loss: 0.6762 - val_acc: 0.5889\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 639us/step - loss: 0.6779 - acc: 0.5979 - val_loss: 0.6707 - val_acc: 0.6025\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 565us/step - loss: 0.6765 - acc: 0.6126 - val_loss: 0.6750 - val_acc: 0.5816\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 747us/step - loss: 0.6781 - acc: 0.5743 - val_loss: 0.6850 - val_acc: 0.5323\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 577us/step - loss: 0.6731 - acc: 0.6184 - val_loss: 0.6748 - val_acc: 0.5954\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 716us/step - loss: 0.6740 - acc: 0.6067 - val_loss: 0.6744 - val_acc: 0.5821\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 577us/step - loss: 0.6626 - acc: 0.6237 - val_loss: 0.6648 - val_acc: 0.6105\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 686us/step - loss: 0.6634 - acc: 0.6388 - val_loss: 0.6730 - val_acc: 0.5917\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 662us/step - loss: 0.6763 - acc: 0.5815 - val_loss: 0.6765 - val_acc: 0.5737\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 748us/step - loss: 0.6720 - acc: 0.5976 - val_loss: 0.6653 - val_acc: 0.6103\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 717us/step - loss: 0.6687 - acc: 0.5837 - val_loss: 0.6730 - val_acc: 0.5703\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 564us/step - loss: 0.6951 - acc: 0.5090 - val_loss: 0.6889 - val_acc: 0.5137\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 560us/step - loss: 0.6576 - acc: 0.6352 - val_loss: 0.6607 - val_acc: 0.5963\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 868us/step - loss: 0.6595 - acc: 0.5955 - val_loss: 0.6551 - val_acc: 0.6170\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 784us/step - loss: 0.6604 - acc: 0.5973 - val_loss: 0.6619 - val_acc: 0.5804\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 781us/step - loss: 0.6693 - acc: 0.5618 - val_loss: 0.6600 - val_acc: 0.5740\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 671us/step - loss: 0.6530 - acc: 0.6641 - val_loss: 0.6355 - val_acc: 0.6706\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 735us/step - loss: 0.6717 - acc: 0.5651 - val_loss: 0.6914 - val_acc: 0.5012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 740us/step - loss: 0.6770 - acc: 0.5557 - val_loss: 0.6715 - val_acc: 0.5570\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 668us/step - loss: 0.6558 - acc: 0.6350 - val_loss: 0.6667 - val_acc: 0.5627\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 601us/step - loss: 0.6563 - acc: 0.6127 - val_loss: 0.6635 - val_acc: 0.5837\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 744us/step - loss: 0.6847 - acc: 0.5008 - val_loss: 0.6723 - val_acc: 0.5474\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 646us/step - loss: 0.6611 - acc: 0.5799 - val_loss: 0.6523 - val_acc: 0.6077\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 747us/step - loss: 0.6627 - acc: 0.5845 - val_loss: 0.6645 - val_acc: 0.5787\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 596us/step - loss: 0.6488 - acc: 0.6225 - val_loss: 0.6522 - val_acc: 0.6007\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 604us/step - loss: 0.6562 - acc: 0.6026 - val_loss: 0.6547 - val_acc: 0.5767\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 724us/step - loss: 0.6612 - acc: 0.5733 - val_loss: 0.6523 - val_acc: 0.6052\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 603us/step - loss: 0.7122 - acc: 0.4742 - val_loss: 0.7129 - val_acc: 0.4622\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 679us/step - loss: 0.6889 - acc: 0.5016 - val_loss: 0.6862 - val_acc: 0.5141\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 562us/step - loss: 0.6806 - acc: 0.5641 - val_loss: 0.6897 - val_acc: 0.5354\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 588us/step - loss: 0.6802 - acc: 0.5600 - val_loss: 0.6805 - val_acc: 0.5457\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 718us/step - loss: 0.6791 - acc: 0.5595 - val_loss: 0.6855 - val_acc: 0.5487\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 914us/step - loss: 0.6816 - acc: 0.5694 - val_loss: 0.6797 - val_acc: 0.5530\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 718us/step - loss: 0.6769 - acc: 0.5960 - val_loss: 0.6855 - val_acc: 0.5658\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 638us/step - loss: 0.6754 - acc: 0.5775 - val_loss: 0.6648 - val_acc: 0.5811\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 691us/step - loss: 0.6643 - acc: 0.5798 - val_loss: 0.6814 - val_acc: 0.5264\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 879us/step - loss: 0.6697 - acc: 0.5683 - val_loss: 0.6730 - val_acc: 0.5667\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 751us/step - loss: 0.6610 - acc: 0.5879 - val_loss: 0.6823 - val_acc: 0.5123\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 748us/step - loss: 0.6348 - acc: 0.6509 - val_loss: 0.6484 - val_acc: 0.5826\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 855us/step - loss: 0.6764 - acc: 0.5592 - val_loss: 0.6889 - val_acc: 0.5114\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 721us/step - loss: 0.6477 - acc: 0.6166 - val_loss: 0.6549 - val_acc: 0.5908\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 793us/step - loss: 0.6754 - acc: 0.5323 - val_loss: 0.6448 - val_acc: 0.6184\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 598us/step - loss: 0.6513 - acc: 0.5919 - val_loss: 0.6566 - val_acc: 0.5798\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 665us/step - loss: 0.6728 - acc: 0.5694 - val_loss: 0.6656 - val_acc: 0.5779\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 629us/step - loss: 0.6624 - acc: 0.5860 - val_loss: 0.6505 - val_acc: 0.5923\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 627us/step - loss: 0.6731 - acc: 0.5657 - val_loss: 0.6741 - val_acc: 0.5728\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 592us/step - loss: 0.6326 - acc: 0.6498 - val_loss: 0.6336 - val_acc: 0.6718\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 582us/step - loss: 0.6527 - acc: 0.6411 - val_loss: 0.6395 - val_acc: 0.6691\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 751us/step - loss: 0.6491 - acc: 0.6295 - val_loss: 0.6530 - val_acc: 0.6320\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 682us/step - loss: 0.6399 - acc: 0.6445 - val_loss: 0.6427 - val_acc: 0.6282\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 767us/step - loss: 0.6266 - acc: 0.6640 - val_loss: 0.6327 - val_acc: 0.6561\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 599us/step - loss: 0.6131 - acc: 0.6752 - val_loss: 0.6334 - val_acc: 0.6342\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 817us/step - loss: 0.6897 - acc: 0.5279 - val_loss: 0.6501 - val_acc: 0.6007\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 588us/step - loss: 0.6518 - acc: 0.6108 - val_loss: 0.6371 - val_acc: 0.6527\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 695us/step - loss: 0.6259 - acc: 0.6715 - val_loss: 0.6464 - val_acc: 0.6504\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 737us/step - loss: 0.6164 - acc: 0.6770 - val_loss: 0.6352 - val_acc: 0.6442\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 599us/step - loss: 0.6408 - acc: 0.6181 - val_loss: 0.6580 - val_acc: 0.6037\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 721us/step - loss: 0.6892 - acc: 0.5600 - val_loss: 0.6904 - val_acc: 0.5754\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 987us/step - loss: 0.6678 - acc: 0.5713 - val_loss: 0.6421 - val_acc: 0.6323\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 610us/step - loss: 0.6639 - acc: 0.6062 - val_loss: 0.6532 - val_acc: 0.6360\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 774us/step - loss: 0.6625 - acc: 0.6264 - val_loss: 0.6691 - val_acc: 0.5800\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 678us/step - loss: 0.6732 - acc: 0.5747 - val_loss: 0.6632 - val_acc: 0.5704\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 642us/step - loss: 0.6703 - acc: 0.5981 - val_loss: 0.6592 - val_acc: 0.6035\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 776us/step - loss: 0.6665 - acc: 0.5992 - val_loss: 0.6461 - val_acc: 0.6044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 687us/step - loss: 0.6811 - acc: 0.5430 - val_loss: 0.6607 - val_acc: 0.6203\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 757us/step - loss: 0.6468 - acc: 0.6444 - val_loss: 0.6447 - val_acc: 0.6357\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 598us/step - loss: 0.6570 - acc: 0.5971 - val_loss: 0.6479 - val_acc: 0.6475\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.7030 - acc: 0.5378 - val_loss: 0.6988 - val_acc: 0.5683\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 695us/step - loss: 0.6511 - acc: 0.6339 - val_loss: 0.6502 - val_acc: 0.6327\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 617us/step - loss: 0.6601 - acc: 0.6273 - val_loss: 0.6571 - val_acc: 0.6207\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 671us/step - loss: 0.6591 - acc: 0.6681 - val_loss: 0.6471 - val_acc: 0.7082\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 606us/step - loss: 0.6607 - acc: 0.6363 - val_loss: 0.6551 - val_acc: 0.6514\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 683us/step - loss: 0.6567 - acc: 0.6269 - val_loss: 0.6442 - val_acc: 0.6782\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 623us/step - loss: 0.6510 - acc: 0.6470 - val_loss: 0.6346 - val_acc: 0.6875\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 717us/step - loss: 0.6498 - acc: 0.6830 - val_loss: 0.6472 - val_acc: 0.6633\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 617us/step - loss: 0.6458 - acc: 0.6579 - val_loss: 0.6376 - val_acc: 0.7064\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.6404 - acc: 0.6937 - val_loss: 0.6225 - val_acc: 0.7189\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 545us/step - loss: 0.6441 - acc: 0.6336 - val_loss: 0.6222 - val_acc: 0.6572\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 829us/step - loss: 0.6361 - acc: 0.6418 - val_loss: 0.6463 - val_acc: 0.6102\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 572us/step - loss: 0.6435 - acc: 0.6192 - val_loss: 0.6231 - val_acc: 0.6581\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 625us/step - loss: 0.6314 - acc: 0.6509 - val_loss: 0.6319 - val_acc: 0.6516\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 578us/step - loss: 0.6257 - acc: 0.6809 - val_loss: 0.6227 - val_acc: 0.6653\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 728us/step - loss: 0.6186 - acc: 0.6760 - val_loss: 0.6251 - val_acc: 0.6821\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 579us/step - loss: 0.6313 - acc: 0.6431 - val_loss: 0.6314 - val_acc: 0.6465\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 701us/step - loss: 0.6835 - acc: 0.5779 - val_loss: 0.6593 - val_acc: 0.6240\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 577us/step - loss: 0.6254 - acc: 0.6683 - val_loss: 0.6181 - val_acc: 0.6964\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 657us/step - loss: 0.6303 - acc: 0.6483 - val_loss: 0.5978 - val_acc: 0.7242\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 669us/step - loss: 0.6318 - acc: 0.6216 - val_loss: 0.6045 - val_acc: 0.7028\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 668us/step - loss: 0.6461 - acc: 0.6184 - val_loss: 0.6280 - val_acc: 0.6474\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 647us/step - loss: 0.6291 - acc: 0.6566 - val_loss: 0.6079 - val_acc: 0.6864\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 708us/step - loss: 0.6149 - acc: 0.6749 - val_loss: 0.5952 - val_acc: 0.6857\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 579us/step - loss: 0.6081 - acc: 0.6884 - val_loss: 0.6228 - val_acc: 0.6636\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 684us/step - loss: 0.5899 - acc: 0.7032 - val_loss: 0.5824 - val_acc: 0.7144\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 545us/step - loss: 0.6366 - acc: 0.6471 - val_loss: 0.6119 - val_acc: 0.6782\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 684us/step - loss: 0.6616 - acc: 0.6299 - val_loss: 0.6424 - val_acc: 0.6555\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 677us/step - loss: 0.6073 - acc: 0.6763 - val_loss: 0.6030 - val_acc: 0.6654\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 595us/step - loss: 0.6455 - acc: 0.6193 - val_loss: 0.6267 - val_acc: 0.6676\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.5586 - acc: 0.7341 - val_loss: 0.5971 - val_acc: 0.6861\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 653us/step - loss: 0.6191 - acc: 0.6646 - val_loss: 0.6032 - val_acc: 0.7089\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 679us/step - loss: 0.5974 - acc: 0.6902 - val_loss: 0.6120 - val_acc: 0.6653\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 815us/step - loss: 0.5926 - acc: 0.6925 - val_loss: 0.6022 - val_acc: 0.6952\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 597us/step - loss: 0.5847 - acc: 0.7030 - val_loss: 0.6082 - val_acc: 0.6727\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 760us/step - loss: 0.5899 - acc: 0.6968 - val_loss: 0.6201 - val_acc: 0.6584\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 609us/step - loss: 0.6134 - acc: 0.6706 - val_loss: 0.5975 - val_acc: 0.6906\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 606us/step - loss: 0.6226 - acc: 0.6507 - val_loss: 0.6102 - val_acc: 0.6812\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 682us/step - loss: 0.6162 - acc: 0.6403 - val_loss: 0.6158 - val_acc: 0.6637\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 666us/step - loss: 0.6291 - acc: 0.6694 - val_loss: 0.6251 - val_acc: 0.6987\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 591us/step - loss: 0.6763 - acc: 0.5862 - val_loss: 0.6357 - val_acc: 0.6594\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 744us/step - loss: 0.6254 - acc: 0.6630 - val_loss: 0.6325 - val_acc: 0.6558\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 677us/step - loss: 0.6178 - acc: 0.6723 - val_loss: 0.5988 - val_acc: 0.6904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 687us/step - loss: 0.6252 - acc: 0.6312 - val_loss: 0.6186 - val_acc: 0.6789\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 662us/step - loss: 0.6648 - acc: 0.5967 - val_loss: 0.6442 - val_acc: 0.6556\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 678us/step - loss: 0.6021 - acc: 0.7044 - val_loss: 0.5761 - val_acc: 0.7391\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 670us/step - loss: 0.6434 - acc: 0.6392 - val_loss: 0.6698 - val_acc: 0.6402\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 617us/step - loss: 0.6164 - acc: 0.6907 - val_loss: 0.6093 - val_acc: 0.6994\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 746us/step - loss: 0.6217 - acc: 0.6686 - val_loss: 0.5943 - val_acc: 0.7396\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 627us/step - loss: 0.6049 - acc: 0.6948 - val_loss: 0.6151 - val_acc: 0.6773\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 746us/step - loss: 0.6124 - acc: 0.6673 - val_loss: 0.6225 - val_acc: 0.6718\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 676us/step - loss: 0.6598 - acc: 0.5980 - val_loss: 0.6423 - val_acc: 0.6278\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 604us/step - loss: 0.6543 - acc: 0.5736 - val_loss: 0.5761 - val_acc: 0.7235\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 685us/step - loss: 0.6337 - acc: 0.6133 - val_loss: 0.6001 - val_acc: 0.6995\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 606us/step - loss: 0.6267 - acc: 0.6235 - val_loss: 0.5817 - val_acc: 0.7199\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 571us/step - loss: 0.6310 - acc: 0.6306 - val_loss: 0.5784 - val_acc: 0.7303\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 767us/step - loss: 0.6035 - acc: 0.6812 - val_loss: 0.5991 - val_acc: 0.6956\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 582us/step - loss: 0.6323 - acc: 0.6330 - val_loss: 0.6004 - val_acc: 0.6916\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 701us/step - loss: 0.6065 - acc: 0.6727 - val_loss: 0.5975 - val_acc: 0.6936\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 583us/step - loss: 0.5870 - acc: 0.6912 - val_loss: 0.5896 - val_acc: 0.6824\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 696us/step - loss: 0.5986 - acc: 0.6584 - val_loss: 0.5997 - val_acc: 0.6930\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 659us/step - loss: 0.6160 - acc: 0.6336 - val_loss: 0.6094 - val_acc: 0.6697\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 749us/step - loss: 0.5800 - acc: 0.6854 - val_loss: 0.5538 - val_acc: 0.7530\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 709us/step - loss: 0.5937 - acc: 0.6841 - val_loss: 0.6066 - val_acc: 0.6715\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 552us/step - loss: 0.6320 - acc: 0.6549 - val_loss: 0.6043 - val_acc: 0.6964\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 572us/step - loss: 0.5915 - acc: 0.6810 - val_loss: 0.5823 - val_acc: 0.7228\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 970us/step - loss: 0.5971 - acc: 0.6715 - val_loss: 0.5746 - val_acc: 0.6960\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 766us/step - loss: 0.5843 - acc: 0.7104 - val_loss: 0.5768 - val_acc: 0.7177\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 764us/step - loss: 0.6233 - acc: 0.6478 - val_loss: 0.5950 - val_acc: 0.6824\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 693us/step - loss: 0.5706 - acc: 0.7271 - val_loss: 0.5372 - val_acc: 0.7587\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 735us/step - loss: 0.6481 - acc: 0.6572 - val_loss: 0.6963 - val_acc: 0.5904\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 741us/step - loss: 0.6685 - acc: 0.6138 - val_loss: 0.6385 - val_acc: 0.6448\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 659us/step - loss: 0.6058 - acc: 0.6658 - val_loss: 0.6184 - val_acc: 0.6625\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 703us/step - loss: 0.6334 - acc: 0.6613 - val_loss: 0.6343 - val_acc: 0.6577\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 817us/step - loss: 0.6281 - acc: 0.6613 - val_loss: 0.6096 - val_acc: 0.6937\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 698us/step - loss: 0.6181 - acc: 0.6690 - val_loss: 0.6092 - val_acc: 0.6802\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 700us/step - loss: 0.6357 - acc: 0.6358 - val_loss: 0.6442 - val_acc: 0.6167\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 574us/step - loss: 0.6368 - acc: 0.6130 - val_loss: 0.6147 - val_acc: 0.6703\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 596us/step - loss: 0.6122 - acc: 0.6666 - val_loss: 0.5988 - val_acc: 0.6975\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 722us/step - loss: 0.6050 - acc: 0.6762 - val_loss: 0.6107 - val_acc: 0.6740\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 586us/step - loss: 0.6329 - acc: 0.6635 - val_loss: 0.6228 - val_acc: 0.6809\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 680us/step - loss: 0.6034 - acc: 0.7092 - val_loss: 0.6124 - val_acc: 0.7077\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 592us/step - loss: 0.6365 - acc: 0.6498 - val_loss: 0.6259 - val_acc: 0.6709\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 603us/step - loss: 0.6366 - acc: 0.6421 - val_loss: 0.6181 - val_acc: 0.6742\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 736us/step - loss: 0.6272 - acc: 0.6620 - val_loss: 0.6249 - val_acc: 0.6989\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 796us/step - loss: 0.6036 - acc: 0.7205 - val_loss: 0.6177 - val_acc: 0.6841\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 688us/step - loss: 0.6178 - acc: 0.6922 - val_loss: 0.6329 - val_acc: 0.6689\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 636us/step - loss: 0.6306 - acc: 0.6615 - val_loss: 0.5937 - val_acc: 0.7227\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 682us/step - loss: 0.6179 - acc: 0.6790 - val_loss: 0.6260 - val_acc: 0.6820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 836us/step - loss: 0.6212 - acc: 0.6720 - val_loss: 0.6259 - val_acc: 0.6637\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 679us/step - loss: 0.6144 - acc: 0.6724 - val_loss: 0.6221 - val_acc: 0.6824\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 681us/step - loss: 0.5600 - acc: 0.7488 - val_loss: 0.5813 - val_acc: 0.7312\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 702us/step - loss: 0.6350 - acc: 0.6543 - val_loss: 0.6100 - val_acc: 0.6975\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 654us/step - loss: 0.5830 - acc: 0.7098 - val_loss: 0.5644 - val_acc: 0.7335\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 729us/step - loss: 0.6161 - acc: 0.6841 - val_loss: 0.5879 - val_acc: 0.7039\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 568us/step - loss: 0.5900 - acc: 0.6909 - val_loss: 0.5941 - val_acc: 0.7037\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 647us/step - loss: 0.6284 - acc: 0.6482 - val_loss: 0.6077 - val_acc: 0.6911\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 617us/step - loss: 0.6213 - acc: 0.6672 - val_loss: 0.5875 - val_acc: 0.7210\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 618us/step - loss: 0.6272 - acc: 0.6794 - val_loss: 0.6281 - val_acc: 0.6968\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 575us/step - loss: 0.5662 - acc: 0.7349 - val_loss: 0.5710 - val_acc: 0.7167\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 594us/step - loss: 0.6151 - acc: 0.6663 - val_loss: 0.5769 - val_acc: 0.7295\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.6036 - acc: 0.6899 - val_loss: 0.6076 - val_acc: 0.6830\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 675us/step - loss: 0.5858 - acc: 0.7020 - val_loss: 0.5883 - val_acc: 0.6824\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 780us/step - loss: 0.5738 - acc: 0.7267 - val_loss: 0.5771 - val_acc: 0.7236\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 581us/step - loss: 0.5459 - acc: 0.7355 - val_loss: 0.5731 - val_acc: 0.7090\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 688us/step - loss: 0.6487 - acc: 0.6268 - val_loss: 0.6052 - val_acc: 0.6815\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 560us/step - loss: 0.6192 - acc: 0.6765 - val_loss: 0.5911 - val_acc: 0.6971\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 681us/step - loss: 0.5838 - acc: 0.6858 - val_loss: 0.5986 - val_acc: 0.7040\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 760us/step - loss: 0.5845 - acc: 0.6761 - val_loss: 0.5939 - val_acc: 0.7008\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 624us/step - loss: 0.6072 - acc: 0.6907 - val_loss: 0.6270 - val_acc: 0.6744\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 732us/step - loss: 0.6474 - acc: 0.6323 - val_loss: 0.6485 - val_acc: 0.6532\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5893 - acc: 0.6945 - val_loss: 0.5912 - val_acc: 0.7032\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 586us/step - loss: 0.6021 - acc: 0.6979 - val_loss: 0.5907 - val_acc: 0.7012\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 763us/step - loss: 0.6031 - acc: 0.6988 - val_loss: 0.6237 - val_acc: 0.6613\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 674us/step - loss: 0.6464 - acc: 0.6269 - val_loss: 0.6207 - val_acc: 0.6504\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 624us/step - loss: 0.6205 - acc: 0.6688 - val_loss: 0.6095 - val_acc: 0.6703\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 712us/step - loss: 0.6296 - acc: 0.6386 - val_loss: 0.5786 - val_acc: 0.6984\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 688us/step - loss: 0.6445 - acc: 0.6271 - val_loss: 0.6121 - val_acc: 0.6883\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 752us/step - loss: 0.5857 - acc: 0.7001 - val_loss: 0.5863 - val_acc: 0.7130\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 593us/step - loss: 0.6028 - acc: 0.6751 - val_loss: 0.5847 - val_acc: 0.7142\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.6711 - acc: 0.6532 - val_loss: 0.6566 - val_acc: 0.6699\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 694us/step - loss: 0.5989 - acc: 0.7152 - val_loss: 0.5976 - val_acc: 0.7178\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 597us/step - loss: 0.6035 - acc: 0.6876 - val_loss: 0.6059 - val_acc: 0.6882\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 710us/step - loss: 0.5935 - acc: 0.7071 - val_loss: 0.5644 - val_acc: 0.7427\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 588us/step - loss: 0.5932 - acc: 0.7161 - val_loss: 0.5953 - val_acc: 0.7004\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 662us/step - loss: 0.6104 - acc: 0.6686 - val_loss: 0.5885 - val_acc: 0.7030\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 623us/step - loss: 0.6054 - acc: 0.6836 - val_loss: 0.5766 - val_acc: 0.7208\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 760us/step - loss: 0.6032 - acc: 0.7078 - val_loss: 0.6006 - val_acc: 0.6947\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 619us/step - loss: 0.6080 - acc: 0.6890 - val_loss: 0.5808 - val_acc: 0.7321\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.5817 - acc: 0.7051 - val_loss: 0.5610 - val_acc: 0.7290\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 548us/step - loss: 0.6431 - acc: 0.6192 - val_loss: 0.5947 - val_acc: 0.6602\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 887us/step - loss: 0.6198 - acc: 0.6561 - val_loss: 0.6472 - val_acc: 0.6264\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 575us/step - loss: 0.6420 - acc: 0.6299 - val_loss: 0.6091 - val_acc: 0.6622\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 600us/step - loss: 0.6129 - acc: 0.6580 - val_loss: 0.6117 - val_acc: 0.6590\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 582us/step - loss: 0.6027 - acc: 0.6825 - val_loss: 0.6012 - val_acc: 0.6801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 703us/step - loss: 0.5868 - acc: 0.7075 - val_loss: 0.5827 - val_acc: 0.7147\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 574us/step - loss: 0.6129 - acc: 0.6612 - val_loss: 0.6148 - val_acc: 0.6716\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 688us/step - loss: 0.6551 - acc: 0.6177 - val_loss: 0.6480 - val_acc: 0.6398\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 548us/step - loss: 0.5958 - acc: 0.6941 - val_loss: 0.5839 - val_acc: 0.7252\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 675us/step - loss: 0.6061 - acc: 0.6734 - val_loss: 0.5588 - val_acc: 0.7325\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 673us/step - loss: 0.6121 - acc: 0.6389 - val_loss: 0.5744 - val_acc: 0.7044\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 707us/step - loss: 0.6349 - acc: 0.6364 - val_loss: 0.6090 - val_acc: 0.6833\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 647us/step - loss: 0.5986 - acc: 0.6896 - val_loss: 0.5654 - val_acc: 0.7267\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 705us/step - loss: 0.5659 - acc: 0.7186 - val_loss: 0.5576 - val_acc: 0.7110\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 576us/step - loss: 0.5761 - acc: 0.7069 - val_loss: 0.5922 - val_acc: 0.6836\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 685us/step - loss: 0.5556 - acc: 0.7178 - val_loss: 0.5509 - val_acc: 0.7265\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 554us/step - loss: 0.6019 - acc: 0.6921 - val_loss: 0.5647 - val_acc: 0.7208\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 721us/step - loss: 0.6112 - acc: 0.6723 - val_loss: 0.5937 - val_acc: 0.7037\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 685us/step - loss: 0.5911 - acc: 0.6740 - val_loss: 0.5688 - val_acc: 0.7048\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 596us/step - loss: 0.6181 - acc: 0.6626 - val_loss: 0.5790 - val_acc: 0.7194\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.5358 - acc: 0.7441 - val_loss: 0.5748 - val_acc: 0.7002\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 619us/step - loss: 0.5863 - acc: 0.7085 - val_loss: 0.5749 - val_acc: 0.7253\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 675us/step - loss: 0.5654 - acc: 0.7231 - val_loss: 0.5738 - val_acc: 0.7058\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 757us/step - loss: 0.5532 - acc: 0.7308 - val_loss: 0.5741 - val_acc: 0.7201\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 605us/step - loss: 0.5492 - acc: 0.7386 - val_loss: 0.5753 - val_acc: 0.7080\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 741us/step - loss: 0.5522 - acc: 0.7339 - val_loss: 0.5948 - val_acc: 0.6758\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 625us/step - loss: 0.6032 - acc: 0.6731 - val_loss: 0.5866 - val_acc: 0.7018\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 603us/step - loss: 0.6022 - acc: 0.6740 - val_loss: 0.5809 - val_acc: 0.7105\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 699us/step - loss: 0.5921 - acc: 0.6572 - val_loss: 0.5845 - val_acc: 0.6910\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 647us/step - loss: 0.5996 - acc: 0.6957 - val_loss: 0.5862 - val_acc: 0.7224\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 581us/step - loss: 0.6635 - acc: 0.6205 - val_loss: 0.6130 - val_acc: 0.6889\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 719us/step - loss: 0.6026 - acc: 0.6857 - val_loss: 0.6026 - val_acc: 0.6964\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 667us/step - loss: 0.6023 - acc: 0.6883 - val_loss: 0.5714 - val_acc: 0.7140\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 668us/step - loss: 0.6078 - acc: 0.6609 - val_loss: 0.5899 - val_acc: 0.7046\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 641us/step - loss: 0.6697 - acc: 0.6104 - val_loss: 0.6249 - val_acc: 0.6702\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 659us/step - loss: 0.5852 - acc: 0.7000 - val_loss: 0.5398 - val_acc: 0.7556\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 676us/step - loss: 0.6224 - acc: 0.6739 - val_loss: 0.6312 - val_acc: 0.6849\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 592us/step - loss: 0.5842 - acc: 0.7225 - val_loss: 0.5840 - val_acc: 0.7210\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.5990 - acc: 0.6950 - val_loss: 0.5620 - val_acc: 0.7489\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 625us/step - loss: 0.5769 - acc: 0.7155 - val_loss: 0.5909 - val_acc: 0.7069\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 805us/step - loss: 0.5823 - acc: 0.6966 - val_loss: 0.5932 - val_acc: 0.6937\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 663us/step - loss: 0.6271 - acc: 0.6304 - val_loss: 0.6053 - val_acc: 0.6784\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 612us/step - loss: 0.6299 - acc: 0.6292 - val_loss: 0.5438 - val_acc: 0.7543\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 635us/step - loss: 0.6115 - acc: 0.6563 - val_loss: 0.5582 - val_acc: 0.7415\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 613us/step - loss: 0.6134 - acc: 0.6415 - val_loss: 0.5459 - val_acc: 0.7471\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 545us/step - loss: 0.6051 - acc: 0.6746 - val_loss: 0.5449 - val_acc: 0.7553\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 727us/step - loss: 0.5788 - acc: 0.6963 - val_loss: 0.5700 - val_acc: 0.7172\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 575us/step - loss: 0.6148 - acc: 0.6624 - val_loss: 0.5704 - val_acc: 0.7207\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 717us/step - loss: 0.5848 - acc: 0.6964 - val_loss: 0.5706 - val_acc: 0.7117\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 561us/step - loss: 0.5665 - acc: 0.7131 - val_loss: 0.5672 - val_acc: 0.7145\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 695us/step - loss: 0.5882 - acc: 0.6645 - val_loss: 0.5835 - val_acc: 0.7046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 725us/step - loss: 0.5915 - acc: 0.6816 - val_loss: 0.5963 - val_acc: 0.6829\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 761us/step - loss: 0.5543 - acc: 0.7212 - val_loss: 0.5224 - val_acc: 0.7836\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 689us/step - loss: 0.5709 - acc: 0.7046 - val_loss: 0.5873 - val_acc: 0.6895\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 557us/step - loss: 0.6164 - acc: 0.6622 - val_loss: 0.5836 - val_acc: 0.7047\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 569us/step - loss: 0.5693 - acc: 0.7063 - val_loss: 0.5478 - val_acc: 0.7490\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 859us/step - loss: 0.5820 - acc: 0.6995 - val_loss: 0.5541 - val_acc: 0.7210\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 755us/step - loss: 0.5564 - acc: 0.7276 - val_loss: 0.5418 - val_acc: 0.7405\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 751us/step - loss: 0.6217 - acc: 0.6511 - val_loss: 0.5768 - val_acc: 0.6978\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 737us/step - loss: 0.5398 - acc: 0.7606 - val_loss: 0.5168 - val_acc: 0.7716\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 760us/step - loss: 0.5998 - acc: 0.7198 - val_loss: 0.6411 - val_acc: 0.6648\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 754us/step - loss: 0.6423 - acc: 0.6562 - val_loss: 0.6211 - val_acc: 0.6674\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 679us/step - loss: 0.5910 - acc: 0.6837 - val_loss: 0.5962 - val_acc: 0.6938\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 608us/step - loss: 0.6149 - acc: 0.6806 - val_loss: 0.6118 - val_acc: 0.6845\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 760us/step - loss: 0.5915 - acc: 0.7095 - val_loss: 0.5721 - val_acc: 0.7325\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 618us/step - loss: 0.5899 - acc: 0.7003 - val_loss: 0.5807 - val_acc: 0.7160\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 717us/step - loss: 0.6068 - acc: 0.6652 - val_loss: 0.6195 - val_acc: 0.6550\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 649us/step - loss: 0.6312 - acc: 0.6305 - val_loss: 0.5979 - val_acc: 0.6862\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 605us/step - loss: 0.5974 - acc: 0.6868 - val_loss: 0.5778 - val_acc: 0.7091\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 725us/step - loss: 0.5888 - acc: 0.6908 - val_loss: 0.5915 - val_acc: 0.6963\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 553us/step - loss: 0.6060 - acc: 0.6856 - val_loss: 0.5929 - val_acc: 0.7080\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 798us/step - loss: 0.5766 - acc: 0.7264 - val_loss: 0.5821 - val_acc: 0.7189\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 579us/step - loss: 0.6135 - acc: 0.6796 - val_loss: 0.5873 - val_acc: 0.7082\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 604us/step - loss: 0.6180 - acc: 0.6720 - val_loss: 0.5986 - val_acc: 0.6850\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 718us/step - loss: 0.6094 - acc: 0.6807 - val_loss: 0.5910 - val_acc: 0.7205\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 744us/step - loss: 0.5740 - acc: 0.7291 - val_loss: 0.5970 - val_acc: 0.6971\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 696us/step - loss: 0.6001 - acc: 0.6960 - val_loss: 0.6145 - val_acc: 0.6716\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 635us/step - loss: 0.6216 - acc: 0.6623 - val_loss: 0.5588 - val_acc: 0.7532\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 674us/step - loss: 0.5995 - acc: 0.7044 - val_loss: 0.5986 - val_acc: 0.7060\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 831us/step - loss: 0.5980 - acc: 0.6947 - val_loss: 0.6021 - val_acc: 0.6883\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 676us/step - loss: 0.5955 - acc: 0.6913 - val_loss: 0.5971 - val_acc: 0.7015\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 691us/step - loss: 0.5338 - acc: 0.7679 - val_loss: 0.5459 - val_acc: 0.7566\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 696us/step - loss: 0.6086 - acc: 0.6817 - val_loss: 0.5756 - val_acc: 0.7238\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 676us/step - loss: 0.5520 - acc: 0.7340 - val_loss: 0.5408 - val_acc: 0.7437\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 704us/step - loss: 0.5917 - acc: 0.6956 - val_loss: 0.5640 - val_acc: 0.7220\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 559us/step - loss: 0.5708 - acc: 0.7064 - val_loss: 0.5757 - val_acc: 0.7055\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 666us/step - loss: 0.6260 - acc: 0.6447 - val_loss: 0.5987 - val_acc: 0.6886\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 618us/step - loss: 0.6026 - acc: 0.6893 - val_loss: 0.5716 - val_acc: 0.7294\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 635us/step - loss: 0.5998 - acc: 0.7005 - val_loss: 0.6021 - val_acc: 0.7122\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 618us/step - loss: 0.5398 - acc: 0.7513 - val_loss: 0.5453 - val_acc: 0.7310\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 591us/step - loss: 0.5875 - acc: 0.6952 - val_loss: 0.5482 - val_acc: 0.7505\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.5820 - acc: 0.7045 - val_loss: 0.5807 - val_acc: 0.7139\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 695us/step - loss: 0.5691 - acc: 0.7140 - val_loss: 0.5748 - val_acc: 0.6974\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 781us/step - loss: 0.5484 - acc: 0.7499 - val_loss: 0.5536 - val_acc: 0.7381\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 576us/step - loss: 0.5331 - acc: 0.7408 - val_loss: 0.5540 - val_acc: 0.7222\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 666us/step - loss: 0.6319 - acc: 0.6541 - val_loss: 0.5757 - val_acc: 0.7148\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 562us/step - loss: 0.5992 - acc: 0.7014 - val_loss: 0.5674 - val_acc: 0.7127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 677us/step - loss: 0.5738 - acc: 0.7017 - val_loss: 0.5808 - val_acc: 0.7195\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 711us/step - loss: 0.5723 - acc: 0.6977 - val_loss: 0.5723 - val_acc: 0.7258\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 598us/step - loss: 0.5806 - acc: 0.7066 - val_loss: 0.6059 - val_acc: 0.6888\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 716us/step - loss: 0.6255 - acc: 0.6539 - val_loss: 0.6245 - val_acc: 0.6790\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 879us/step - loss: 0.5583 - acc: 0.7263 - val_loss: 0.5638 - val_acc: 0.7254\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 589us/step - loss: 0.5802 - acc: 0.7114 - val_loss: 0.5746 - val_acc: 0.7068\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 766us/step - loss: 0.5878 - acc: 0.7050 - val_loss: 0.6100 - val_acc: 0.6781\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 661us/step - loss: 0.6195 - acc: 0.6752 - val_loss: 0.5977 - val_acc: 0.6816\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 625us/step - loss: 0.6050 - acc: 0.6800 - val_loss: 0.5911 - val_acc: 0.6898\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 710us/step - loss: 0.6149 - acc: 0.6598 - val_loss: 0.5514 - val_acc: 0.7256\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 697us/step - loss: 0.6319 - acc: 0.6498 - val_loss: 0.5882 - val_acc: 0.7070\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 767us/step - loss: 0.5620 - acc: 0.7263 - val_loss: 0.5669 - val_acc: 0.7298\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 591us/step - loss: 0.5816 - acc: 0.7014 - val_loss: 0.5638 - val_acc: 0.7337\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.6341 - acc: 0.6892 - val_loss: 0.6378 - val_acc: 0.6850\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 784us/step - loss: 0.5809 - acc: 0.7222 - val_loss: 0.5815 - val_acc: 0.7181\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 598us/step - loss: 0.5866 - acc: 0.6984 - val_loss: 0.5841 - val_acc: 0.7105\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 681us/step - loss: 0.5680 - acc: 0.7185 - val_loss: 0.5315 - val_acc: 0.7543\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 625us/step - loss: 0.5644 - acc: 0.7308 - val_loss: 0.5628 - val_acc: 0.7300\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 656us/step - loss: 0.5892 - acc: 0.6931 - val_loss: 0.5598 - val_acc: 0.7313\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 629us/step - loss: 0.5798 - acc: 0.7140 - val_loss: 0.5560 - val_acc: 0.7344\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 717us/step - loss: 0.5749 - acc: 0.7285 - val_loss: 0.5770 - val_acc: 0.7116\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 637us/step - loss: 0.5857 - acc: 0.7126 - val_loss: 0.5515 - val_acc: 0.7451\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.5588 - acc: 0.7242 - val_loss: 0.5365 - val_acc: 0.7407\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 550us/step - loss: 0.6296 - acc: 0.6582 - val_loss: 0.5621 - val_acc: 0.7207\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 799us/step - loss: 0.6132 - acc: 0.6729 - val_loss: 0.6474 - val_acc: 0.6383\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 585us/step - loss: 0.6374 - acc: 0.6445 - val_loss: 0.5997 - val_acc: 0.6733\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 620us/step - loss: 0.6019 - acc: 0.6738 - val_loss: 0.5925 - val_acc: 0.6848\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 608us/step - loss: 0.5885 - acc: 0.7005 - val_loss: 0.5885 - val_acc: 0.6924\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 729us/step - loss: 0.5809 - acc: 0.7035 - val_loss: 0.5685 - val_acc: 0.7195\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 560us/step - loss: 0.6112 - acc: 0.6664 - val_loss: 0.6097 - val_acc: 0.6785\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 704us/step - loss: 0.6340 - acc: 0.6396 - val_loss: 0.6233 - val_acc: 0.6563\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 566us/step - loss: 0.5763 - acc: 0.7099 - val_loss: 0.5686 - val_acc: 0.7300\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 658us/step - loss: 0.5899 - acc: 0.6957 - val_loss: 0.5408 - val_acc: 0.7490\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 659us/step - loss: 0.5926 - acc: 0.6624 - val_loss: 0.5574 - val_acc: 0.7277\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 722us/step - loss: 0.6165 - acc: 0.6673 - val_loss: 0.5962 - val_acc: 0.7035\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 633us/step - loss: 0.5723 - acc: 0.7192 - val_loss: 0.5455 - val_acc: 0.7430\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 683us/step - loss: 0.5463 - acc: 0.7368 - val_loss: 0.5334 - val_acc: 0.7464\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.5636 - acc: 0.7220 - val_loss: 0.5724 - val_acc: 0.7112\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 683us/step - loss: 0.5344 - acc: 0.7388 - val_loss: 0.5266 - val_acc: 0.7478\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 566us/step - loss: 0.5834 - acc: 0.7105 - val_loss: 0.5460 - val_acc: 0.7354\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 697us/step - loss: 0.5884 - acc: 0.7039 - val_loss: 0.5756 - val_acc: 0.7212\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 656us/step - loss: 0.5801 - acc: 0.6901 - val_loss: 0.5503 - val_acc: 0.7176\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 585us/step - loss: 0.6010 - acc: 0.6858 - val_loss: 0.5612 - val_acc: 0.7285\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.5213 - acc: 0.7619 - val_loss: 0.5648 - val_acc: 0.7130\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 603us/step - loss: 0.5692 - acc: 0.7236 - val_loss: 0.5555 - val_acc: 0.7343\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 657us/step - loss: 0.5444 - acc: 0.7355 - val_loss: 0.5542 - val_acc: 0.7239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 729us/step - loss: 0.5425 - acc: 0.7438 - val_loss: 0.5610 - val_acc: 0.7231\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 582us/step - loss: 0.5406 - acc: 0.7443 - val_loss: 0.5590 - val_acc: 0.7261\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 748us/step - loss: 0.5277 - acc: 0.7548 - val_loss: 0.5768 - val_acc: 0.6875\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 645us/step - loss: 0.5935 - acc: 0.6829 - val_loss: 0.5722 - val_acc: 0.7129\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 586us/step - loss: 0.5923 - acc: 0.6804 - val_loss: 0.5623 - val_acc: 0.7188\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 667us/step - loss: 0.5698 - acc: 0.6918 - val_loss: 0.5631 - val_acc: 0.7113\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 642us/step - loss: 0.5699 - acc: 0.7086 - val_loss: 0.5624 - val_acc: 0.7244\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 602us/step - loss: 0.6470 - acc: 0.6390 - val_loss: 0.5978 - val_acc: 0.6925\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 725us/step - loss: 0.5876 - acc: 0.6996 - val_loss: 0.5876 - val_acc: 0.7109\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 671us/step - loss: 0.5930 - acc: 0.6969 - val_loss: 0.5561 - val_acc: 0.7270\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 675us/step - loss: 0.5974 - acc: 0.6880 - val_loss: 0.5742 - val_acc: 0.7161\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 615us/step - loss: 0.6696 - acc: 0.6119 - val_loss: 0.6148 - val_acc: 0.6736\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 657us/step - loss: 0.5704 - acc: 0.7173 - val_loss: 0.5223 - val_acc: 0.7617\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 655us/step - loss: 0.6038 - acc: 0.6927 - val_loss: 0.6068 - val_acc: 0.7053\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 603us/step - loss: 0.5649 - acc: 0.7315 - val_loss: 0.5689 - val_acc: 0.7266\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.5801 - acc: 0.7184 - val_loss: 0.5441 - val_acc: 0.7556\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 616us/step - loss: 0.5629 - acc: 0.7248 - val_loss: 0.5814 - val_acc: 0.7096\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 719us/step - loss: 0.5725 - acc: 0.7090 - val_loss: 0.5766 - val_acc: 0.7075\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 648us/step - loss: 0.6062 - acc: 0.6622 - val_loss: 0.5905 - val_acc: 0.6944\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 633us/step - loss: 0.6127 - acc: 0.6586 - val_loss: 0.5285 - val_acc: 0.7633\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 658us/step - loss: 0.5921 - acc: 0.6817 - val_loss: 0.5408 - val_acc: 0.7544\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 625us/step - loss: 0.5984 - acc: 0.6550 - val_loss: 0.5379 - val_acc: 0.7488\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 545us/step - loss: 0.5885 - acc: 0.6987 - val_loss: 0.5275 - val_acc: 0.7676\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 726us/step - loss: 0.5584 - acc: 0.7204 - val_loss: 0.5460 - val_acc: 0.7350\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 561us/step - loss: 0.6043 - acc: 0.6723 - val_loss: 0.5547 - val_acc: 0.7345\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 717us/step - loss: 0.5689 - acc: 0.7098 - val_loss: 0.5550 - val_acc: 0.7224\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 565us/step - loss: 0.5537 - acc: 0.7320 - val_loss: 0.5554 - val_acc: 0.7239\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 719us/step - loss: 0.5863 - acc: 0.6892 - val_loss: 0.5679 - val_acc: 0.7127\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 651us/step - loss: 0.5819 - acc: 0.6896 - val_loss: 0.5845 - val_acc: 0.6887\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 806us/step - loss: 0.5398 - acc: 0.7313 - val_loss: 0.5064 - val_acc: 0.7969\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 707us/step - loss: 0.5586 - acc: 0.7253 - val_loss: 0.5708 - val_acc: 0.7045\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 575us/step - loss: 0.6031 - acc: 0.6697 - val_loss: 0.5643 - val_acc: 0.7144\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 572us/step - loss: 0.5564 - acc: 0.7208 - val_loss: 0.5324 - val_acc: 0.7578\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 892us/step - loss: 0.5770 - acc: 0.6981 - val_loss: 0.5409 - val_acc: 0.7310\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 760us/step - loss: 0.5404 - acc: 0.7377 - val_loss: 0.5186 - val_acc: 0.7590\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 741us/step - loss: 0.6053 - acc: 0.6671 - val_loss: 0.5594 - val_acc: 0.7136\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 665us/step - loss: 0.5241 - acc: 0.7672 - val_loss: 0.4984 - val_acc: 0.7860\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 697us/step - loss: 0.5880 - acc: 0.7330 - val_loss: 0.6098 - val_acc: 0.6979\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 693us/step - loss: 0.6219 - acc: 0.6677 - val_loss: 0.6100 - val_acc: 0.6773\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 626us/step - loss: 0.5716 - acc: 0.7165 - val_loss: 0.5772 - val_acc: 0.7230\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 548us/step - loss: 0.5991 - acc: 0.6962 - val_loss: 0.5992 - val_acc: 0.6954\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 721us/step - loss: 0.5761 - acc: 0.7229 - val_loss: 0.5500 - val_acc: 0.7565\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 578us/step - loss: 0.5745 - acc: 0.7113 - val_loss: 0.5666 - val_acc: 0.7236\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 728us/step - loss: 0.5970 - acc: 0.6797 - val_loss: 0.5998 - val_acc: 0.6787\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 571us/step - loss: 0.6196 - acc: 0.6456 - val_loss: 0.5800 - val_acc: 0.7078\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 581us/step - loss: 0.5828 - acc: 0.7032 - val_loss: 0.5599 - val_acc: 0.7245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 703us/step - loss: 0.5737 - acc: 0.7123 - val_loss: 0.5738 - val_acc: 0.7150\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 550us/step - loss: 0.5840 - acc: 0.7038 - val_loss: 0.5718 - val_acc: 0.7151\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 659us/step - loss: 0.5568 - acc: 0.7338 - val_loss: 0.5590 - val_acc: 0.7345\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 588us/step - loss: 0.6009 - acc: 0.6816 - val_loss: 0.5642 - val_acc: 0.7198\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 596us/step - loss: 0.6023 - acc: 0.6840 - val_loss: 0.5852 - val_acc: 0.6943\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 706us/step - loss: 0.6031 - acc: 0.6829 - val_loss: 0.5662 - val_acc: 0.7256\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 741us/step - loss: 0.5577 - acc: 0.7342 - val_loss: 0.5803 - val_acc: 0.7073\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 667us/step - loss: 0.5824 - acc: 0.7114 - val_loss: 0.5948 - val_acc: 0.6866\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 632us/step - loss: 0.6077 - acc: 0.6769 - val_loss: 0.5444 - val_acc: 0.7583\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 638us/step - loss: 0.5816 - acc: 0.7138 - val_loss: 0.5837 - val_acc: 0.7100\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 820us/step - loss: 0.5771 - acc: 0.7094 - val_loss: 0.5836 - val_acc: 0.7008\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 680us/step - loss: 0.5782 - acc: 0.7038 - val_loss: 0.5747 - val_acc: 0.7166\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 648us/step - loss: 0.5158 - acc: 0.7742 - val_loss: 0.5188 - val_acc: 0.7711\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 679us/step - loss: 0.5967 - acc: 0.6866 - val_loss: 0.5531 - val_acc: 0.7351\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 661us/step - loss: 0.5418 - acc: 0.7436 - val_loss: 0.5241 - val_acc: 0.7554\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 713us/step - loss: 0.5722 - acc: 0.7151 - val_loss: 0.5502 - val_acc: 0.7288\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 560us/step - loss: 0.5654 - acc: 0.7056 - val_loss: 0.5523 - val_acc: 0.7240\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 607us/step - loss: 0.6082 - acc: 0.6666 - val_loss: 0.5775 - val_acc: 0.7053\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 609us/step - loss: 0.5847 - acc: 0.6983 - val_loss: 0.5557 - val_acc: 0.7348\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 629us/step - loss: 0.5733 - acc: 0.7175 - val_loss: 0.5736 - val_acc: 0.7248\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 561us/step - loss: 0.5238 - acc: 0.7652 - val_loss: 0.5304 - val_acc: 0.7373\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 567us/step - loss: 0.5730 - acc: 0.7091 - val_loss: 0.5313 - val_acc: 0.7586\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 699us/step - loss: 0.5602 - acc: 0.7233 - val_loss: 0.5588 - val_acc: 0.7280\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 678us/step - loss: 0.5543 - acc: 0.7295 - val_loss: 0.5635 - val_acc: 0.7041\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 741us/step - loss: 0.5346 - acc: 0.7567 - val_loss: 0.5406 - val_acc: 0.7458\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 568us/step - loss: 0.5240 - acc: 0.7467 - val_loss: 0.5414 - val_acc: 0.7322\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 651us/step - loss: 0.6216 - acc: 0.6611 - val_loss: 0.5592 - val_acc: 0.7247\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 564us/step - loss: 0.5878 - acc: 0.7026 - val_loss: 0.5495 - val_acc: 0.7284\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 669us/step - loss: 0.5590 - acc: 0.7127 - val_loss: 0.5712 - val_acc: 0.7188\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 693us/step - loss: 0.5515 - acc: 0.7209 - val_loss: 0.5508 - val_acc: 0.7465\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 578us/step - loss: 0.5602 - acc: 0.7245 - val_loss: 0.5856 - val_acc: 0.7008\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 672us/step - loss: 0.6059 - acc: 0.6707 - val_loss: 0.6073 - val_acc: 0.6860\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 887us/step - loss: 0.5243 - acc: 0.7550 - val_loss: 0.5428 - val_acc: 0.7341\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 560us/step - loss: 0.5631 - acc: 0.7210 - val_loss: 0.5649 - val_acc: 0.7089\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 715us/step - loss: 0.5752 - acc: 0.7145 - val_loss: 0.5939 - val_acc: 0.6874\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 645us/step - loss: 0.5941 - acc: 0.6941 - val_loss: 0.5748 - val_acc: 0.7035\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 616us/step - loss: 0.5753 - acc: 0.7024 - val_loss: 0.5681 - val_acc: 0.7118\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 692us/step - loss: 0.5850 - acc: 0.6878 - val_loss: 0.5310 - val_acc: 0.7385\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 669us/step - loss: 0.6125 - acc: 0.6707 - val_loss: 0.5654 - val_acc: 0.7197\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 746us/step - loss: 0.5597 - acc: 0.7253 - val_loss: 0.5608 - val_acc: 0.7288\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 589us/step - loss: 0.5625 - acc: 0.7175 - val_loss: 0.5452 - val_acc: 0.7443\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.6123 - acc: 0.6952 - val_loss: 0.6106 - val_acc: 0.6868\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 680us/step - loss: 0.5783 - acc: 0.7249 - val_loss: 0.5700 - val_acc: 0.7172\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 589us/step - loss: 0.5736 - acc: 0.7026 - val_loss: 0.5680 - val_acc: 0.7152\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 666us/step - loss: 0.5488 - acc: 0.7287 - val_loss: 0.5092 - val_acc: 0.7660\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 568us/step - loss: 0.5398 - acc: 0.7443 - val_loss: 0.5402 - val_acc: 0.7388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 675us/step - loss: 0.5980 - acc: 0.6808 - val_loss: 0.5403 - val_acc: 0.7380\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 613us/step - loss: 0.5657 - acc: 0.7187 - val_loss: 0.5452 - val_acc: 0.7370\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 688us/step - loss: 0.5629 - acc: 0.7285 - val_loss: 0.5691 - val_acc: 0.7160\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 615us/step - loss: 0.5750 - acc: 0.7093 - val_loss: 0.5399 - val_acc: 0.7489\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.5452 - acc: 0.7292 - val_loss: 0.5212 - val_acc: 0.7461\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 524us/step - loss: 0.6066 - acc: 0.6785 - val_loss: 0.5589 - val_acc: 0.7233\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 841us/step - loss: 0.6022 - acc: 0.6885 - val_loss: 0.6415 - val_acc: 0.6458\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 575us/step - loss: 0.6454 - acc: 0.6399 - val_loss: 0.6028 - val_acc: 0.6742\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 611us/step - loss: 0.5894 - acc: 0.6813 - val_loss: 0.5844 - val_acc: 0.6929\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 594us/step - loss: 0.5877 - acc: 0.6969 - val_loss: 0.5754 - val_acc: 0.7050\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 716us/step - loss: 0.5678 - acc: 0.7120 - val_loss: 0.5538 - val_acc: 0.7240\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 567us/step - loss: 0.6064 - acc: 0.6755 - val_loss: 0.5971 - val_acc: 0.6793\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 703us/step - loss: 0.6136 - acc: 0.6635 - val_loss: 0.6050 - val_acc: 0.6724\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 609us/step - loss: 0.5657 - acc: 0.7135 - val_loss: 0.5510 - val_acc: 0.7322\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 721us/step - loss: 0.5737 - acc: 0.7145 - val_loss: 0.5245 - val_acc: 0.7660\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 670us/step - loss: 0.5834 - acc: 0.6755 - val_loss: 0.5500 - val_acc: 0.7349\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 690us/step - loss: 0.6072 - acc: 0.6787 - val_loss: 0.5918 - val_acc: 0.7115\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 729us/step - loss: 0.5612 - acc: 0.7284 - val_loss: 0.5338 - val_acc: 0.7458\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 695us/step - loss: 0.5376 - acc: 0.7402 - val_loss: 0.5192 - val_acc: 0.7600\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.5570 - acc: 0.7223 - val_loss: 0.5563 - val_acc: 0.7220\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 706us/step - loss: 0.5222 - acc: 0.7446 - val_loss: 0.5188 - val_acc: 0.7498\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 563us/step - loss: 0.5688 - acc: 0.7170 - val_loss: 0.5350 - val_acc: 0.7421\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 687us/step - loss: 0.5727 - acc: 0.7173 - val_loss: 0.5557 - val_acc: 0.7378\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 673us/step - loss: 0.5729 - acc: 0.6975 - val_loss: 0.5347 - val_acc: 0.7297\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 622us/step - loss: 0.5861 - acc: 0.7031 - val_loss: 0.5494 - val_acc: 0.7343\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.5187 - acc: 0.7595 - val_loss: 0.5537 - val_acc: 0.7212\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 621us/step - loss: 0.5490 - acc: 0.7391 - val_loss: 0.5392 - val_acc: 0.7413\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 685us/step - loss: 0.5315 - acc: 0.7476 - val_loss: 0.5367 - val_acc: 0.7376\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 745us/step - loss: 0.5375 - acc: 0.7437 - val_loss: 0.5517 - val_acc: 0.7253\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 596us/step - loss: 0.5345 - acc: 0.7537 - val_loss: 0.5451 - val_acc: 0.7347\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 810us/step - loss: 0.5145 - acc: 0.7614 - val_loss: 0.5631 - val_acc: 0.7003\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 618us/step - loss: 0.5917 - acc: 0.6892 - val_loss: 0.5566 - val_acc: 0.7208\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 592us/step - loss: 0.5788 - acc: 0.6934 - val_loss: 0.5471 - val_acc: 0.7272\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 659us/step - loss: 0.5509 - acc: 0.7058 - val_loss: 0.5436 - val_acc: 0.7313\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 666us/step - loss: 0.5502 - acc: 0.7291 - val_loss: 0.5369 - val_acc: 0.7343\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 582us/step - loss: 0.6382 - acc: 0.6401 - val_loss: 0.5894 - val_acc: 0.7001\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 758us/step - loss: 0.5776 - acc: 0.7074 - val_loss: 0.5748 - val_acc: 0.7176\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 674us/step - loss: 0.5856 - acc: 0.6926 - val_loss: 0.5354 - val_acc: 0.7376\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 691us/step - loss: 0.5693 - acc: 0.7143 - val_loss: 0.5504 - val_acc: 0.7330\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 617us/step - loss: 0.6546 - acc: 0.6278 - val_loss: 0.6027 - val_acc: 0.6854\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 679us/step - loss: 0.5405 - acc: 0.7417 - val_loss: 0.5101 - val_acc: 0.7686\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 672us/step - loss: 0.6028 - acc: 0.6936 - val_loss: 0.5920 - val_acc: 0.7140\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 638us/step - loss: 0.5513 - acc: 0.7351 - val_loss: 0.5574 - val_acc: 0.7291\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.5620 - acc: 0.7282 - val_loss: 0.5310 - val_acc: 0.7586\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 612us/step - loss: 0.5517 - acc: 0.7321 - val_loss: 0.5705 - val_acc: 0.7136\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 737us/step - loss: 0.5553 - acc: 0.7212 - val_loss: 0.5606 - val_acc: 0.7191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 682us/step - loss: 0.5976 - acc: 0.6724 - val_loss: 0.5863 - val_acc: 0.7005\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 617us/step - loss: 0.6031 - acc: 0.6710 - val_loss: 0.5172 - val_acc: 0.7611\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 637us/step - loss: 0.5760 - acc: 0.6996 - val_loss: 0.5341 - val_acc: 0.7538\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 630us/step - loss: 0.5841 - acc: 0.6689 - val_loss: 0.5252 - val_acc: 0.7538\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 554us/step - loss: 0.5707 - acc: 0.7159 - val_loss: 0.5159 - val_acc: 0.7682\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 758us/step - loss: 0.5362 - acc: 0.7392 - val_loss: 0.5279 - val_acc: 0.7474\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 570us/step - loss: 0.5893 - acc: 0.6845 - val_loss: 0.5391 - val_acc: 0.7430\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 724us/step - loss: 0.5522 - acc: 0.7235 - val_loss: 0.5339 - val_acc: 0.7349\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 626us/step - loss: 0.5437 - acc: 0.7375 - val_loss: 0.5437 - val_acc: 0.7313\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 876us/step - loss: 0.5749 - acc: 0.7045 - val_loss: 0.5492 - val_acc: 0.7194\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 662us/step - loss: 0.5633 - acc: 0.7058 - val_loss: 0.5661 - val_acc: 0.7000\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 761us/step - loss: 0.5243 - acc: 0.7496 - val_loss: 0.4897 - val_acc: 0.8053\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 717us/step - loss: 0.5430 - acc: 0.7287 - val_loss: 0.5513 - val_acc: 0.7156\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 560us/step - loss: 0.5748 - acc: 0.6954 - val_loss: 0.5419 - val_acc: 0.7306\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 574us/step - loss: 0.5332 - acc: 0.7409 - val_loss: 0.5139 - val_acc: 0.7688\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 907us/step - loss: 0.5582 - acc: 0.7119 - val_loss: 0.5273 - val_acc: 0.7431\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 762us/step - loss: 0.5316 - acc: 0.7349 - val_loss: 0.5010 - val_acc: 0.7729\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.5786 - acc: 0.6883 - val_loss: 0.5396 - val_acc: 0.7304\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 693us/step - loss: 0.5021 - acc: 0.7825 - val_loss: 0.4849 - val_acc: 0.7949\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 727us/step - loss: 0.5827 - acc: 0.7211 - val_loss: 0.6022 - val_acc: 0.6996\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 754us/step - loss: 0.6187 - acc: 0.6709 - val_loss: 0.6008 - val_acc: 0.6782\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 687us/step - loss: 0.5681 - acc: 0.7212 - val_loss: 0.5699 - val_acc: 0.7192\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 585us/step - loss: 0.5924 - acc: 0.7119 - val_loss: 0.5892 - val_acc: 0.7080\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 734us/step - loss: 0.5723 - acc: 0.7255 - val_loss: 0.5412 - val_acc: 0.7579\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 609us/step - loss: 0.5684 - acc: 0.7178 - val_loss: 0.5537 - val_acc: 0.7361\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 727us/step - loss: 0.5859 - acc: 0.6936 - val_loss: 0.5757 - val_acc: 0.7094\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 613us/step - loss: 0.5892 - acc: 0.6830 - val_loss: 0.5545 - val_acc: 0.7222\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 608us/step - loss: 0.5642 - acc: 0.7149 - val_loss: 0.5453 - val_acc: 0.7342\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 716us/step - loss: 0.5629 - acc: 0.7201 - val_loss: 0.5599 - val_acc: 0.7299\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 571us/step - loss: 0.5761 - acc: 0.7044 - val_loss: 0.5600 - val_acc: 0.7227\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 704us/step - loss: 0.5474 - acc: 0.7344 - val_loss: 0.5451 - val_acc: 0.7398\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 563us/step - loss: 0.5812 - acc: 0.6999 - val_loss: 0.5390 - val_acc: 0.7449\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 654us/step - loss: 0.5913 - acc: 0.6903 - val_loss: 0.5650 - val_acc: 0.7111\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 689us/step - loss: 0.5856 - acc: 0.6991 - val_loss: 0.5390 - val_acc: 0.7407\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 763us/step - loss: 0.5414 - acc: 0.7386 - val_loss: 0.5580 - val_acc: 0.7253\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 682us/step - loss: 0.5749 - acc: 0.7152 - val_loss: 0.5641 - val_acc: 0.7087\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 625us/step - loss: 0.6004 - acc: 0.6817 - val_loss: 0.5296 - val_acc: 0.7613\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 672us/step - loss: 0.5710 - acc: 0.7170 - val_loss: 0.5618 - val_acc: 0.7216\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 860us/step - loss: 0.5696 - acc: 0.7161 - val_loss: 0.5600 - val_acc: 0.7122\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 730us/step - loss: 0.5577 - acc: 0.7220 - val_loss: 0.5621 - val_acc: 0.7204\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 678us/step - loss: 0.4944 - acc: 0.7866 - val_loss: 0.4989 - val_acc: 0.7794\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 706us/step - loss: 0.5853 - acc: 0.6881 - val_loss: 0.5429 - val_acc: 0.7355\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 663us/step - loss: 0.5287 - acc: 0.7567 - val_loss: 0.5154 - val_acc: 0.7560\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 742us/step - loss: 0.5638 - acc: 0.7206 - val_loss: 0.5402 - val_acc: 0.7329\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 553us/step - loss: 0.5505 - acc: 0.7189 - val_loss: 0.5401 - val_acc: 0.7289\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 634us/step - loss: 0.5987 - acc: 0.6638 - val_loss: 0.5735 - val_acc: 0.7027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 619us/step - loss: 0.5730 - acc: 0.7047 - val_loss: 0.5473 - val_acc: 0.7333\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 626us/step - loss: 0.5557 - acc: 0.7314 - val_loss: 0.5546 - val_acc: 0.7394\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 571us/step - loss: 0.5101 - acc: 0.7739 - val_loss: 0.5141 - val_acc: 0.7525\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 586us/step - loss: 0.5511 - acc: 0.7318 - val_loss: 0.5206 - val_acc: 0.7608\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 693us/step - loss: 0.5498 - acc: 0.7346 - val_loss: 0.5374 - val_acc: 0.7398\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 653us/step - loss: 0.5412 - acc: 0.7419 - val_loss: 0.5531 - val_acc: 0.7152\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 766us/step - loss: 0.5257 - acc: 0.7554 - val_loss: 0.5248 - val_acc: 0.7524\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 587us/step - loss: 0.5116 - acc: 0.7535 - val_loss: 0.5316 - val_acc: 0.7368\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 728us/step - loss: 0.6033 - acc: 0.6764 - val_loss: 0.5410 - val_acc: 0.7360\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 582us/step - loss: 0.5713 - acc: 0.7105 - val_loss: 0.5351 - val_acc: 0.7416\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 701us/step - loss: 0.5539 - acc: 0.7191 - val_loss: 0.5565 - val_acc: 0.7212\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 710us/step - loss: 0.5425 - acc: 0.7254 - val_loss: 0.5334 - val_acc: 0.7542\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 577us/step - loss: 0.5404 - acc: 0.7366 - val_loss: 0.5647 - val_acc: 0.7111\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 721us/step - loss: 0.6017 - acc: 0.6814 - val_loss: 0.5868 - val_acc: 0.6928\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5192 - acc: 0.7616 - val_loss: 0.5288 - val_acc: 0.7393\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 587us/step - loss: 0.5591 - acc: 0.7224 - val_loss: 0.5580 - val_acc: 0.7161\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 728us/step - loss: 0.5698 - acc: 0.7195 - val_loss: 0.5856 - val_acc: 0.6940\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 723us/step - loss: 0.5901 - acc: 0.6874 - val_loss: 0.5690 - val_acc: 0.7037\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 629us/step - loss: 0.5784 - acc: 0.6973 - val_loss: 0.5555 - val_acc: 0.7161\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 712us/step - loss: 0.5791 - acc: 0.6923 - val_loss: 0.5294 - val_acc: 0.7415\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 685us/step - loss: 0.6071 - acc: 0.6744 - val_loss: 0.5511 - val_acc: 0.7234\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 732us/step - loss: 0.5497 - acc: 0.7225 - val_loss: 0.5480 - val_acc: 0.7289\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 586us/step - loss: 0.5563 - acc: 0.7211 - val_loss: 0.5333 - val_acc: 0.7506\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.6001 - acc: 0.6984 - val_loss: 0.6025 - val_acc: 0.6942\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 734us/step - loss: 0.5642 - acc: 0.7186 - val_loss: 0.5522 - val_acc: 0.7255\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 606us/step - loss: 0.5672 - acc: 0.7107 - val_loss: 0.5516 - val_acc: 0.7305\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 683us/step - loss: 0.5313 - acc: 0.7444 - val_loss: 0.4902 - val_acc: 0.7763\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 633us/step - loss: 0.5254 - acc: 0.7523 - val_loss: 0.5304 - val_acc: 0.7486\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 677us/step - loss: 0.5829 - acc: 0.6945 - val_loss: 0.5253 - val_acc: 0.7449\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 635us/step - loss: 0.5478 - acc: 0.7312 - val_loss: 0.5325 - val_acc: 0.7441\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 721us/step - loss: 0.5464 - acc: 0.7341 - val_loss: 0.5518 - val_acc: 0.7273\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 615us/step - loss: 0.5501 - acc: 0.7329 - val_loss: 0.5098 - val_acc: 0.7659\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.5319 - acc: 0.7392 - val_loss: 0.5045 - val_acc: 0.7576\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 544us/step - loss: 0.5827 - acc: 0.7024 - val_loss: 0.5312 - val_acc: 0.7480\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 801us/step - loss: 0.5777 - acc: 0.6983 - val_loss: 0.6080 - val_acc: 0.6663\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 565us/step - loss: 0.6177 - acc: 0.6546 - val_loss: 0.5718 - val_acc: 0.6906\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 608us/step - loss: 0.5598 - acc: 0.7125 - val_loss: 0.5502 - val_acc: 0.7194\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 583us/step - loss: 0.5611 - acc: 0.7166 - val_loss: 0.5489 - val_acc: 0.7249\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 756us/step - loss: 0.5355 - acc: 0.7300 - val_loss: 0.5343 - val_acc: 0.7386\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 561us/step - loss: 0.5861 - acc: 0.6944 - val_loss: 0.5676 - val_acc: 0.7001\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 721us/step - loss: 0.5898 - acc: 0.6912 - val_loss: 0.5795 - val_acc: 0.6903\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 557us/step - loss: 0.5477 - acc: 0.7242 - val_loss: 0.5284 - val_acc: 0.7473\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 665us/step - loss: 0.5650 - acc: 0.7176 - val_loss: 0.5101 - val_acc: 0.7755\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 685us/step - loss: 0.5737 - acc: 0.6879 - val_loss: 0.5462 - val_acc: 0.7408\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 680us/step - loss: 0.5954 - acc: 0.6879 - val_loss: 0.5822 - val_acc: 0.7143\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 651us/step - loss: 0.5487 - acc: 0.7303 - val_loss: 0.5210 - val_acc: 0.7529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 716us/step - loss: 0.5374 - acc: 0.7415 - val_loss: 0.5120 - val_acc: 0.7634\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.5579 - acc: 0.7186 - val_loss: 0.5464 - val_acc: 0.7283\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 669us/step - loss: 0.5210 - acc: 0.7396 - val_loss: 0.5134 - val_acc: 0.7524\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 566us/step - loss: 0.5628 - acc: 0.7193 - val_loss: 0.5241 - val_acc: 0.7501\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 681us/step - loss: 0.5573 - acc: 0.7260 - val_loss: 0.5447 - val_acc: 0.7444\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 671us/step - loss: 0.5588 - acc: 0.7058 - val_loss: 0.5215 - val_acc: 0.7384\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 590us/step - loss: 0.5744 - acc: 0.7116 - val_loss: 0.5447 - val_acc: 0.7385\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.5007 - acc: 0.7667 - val_loss: 0.5400 - val_acc: 0.7287\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 623us/step - loss: 0.5273 - acc: 0.7556 - val_loss: 0.5256 - val_acc: 0.7506\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 673us/step - loss: 0.5150 - acc: 0.7532 - val_loss: 0.5215 - val_acc: 0.7446\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 728us/step - loss: 0.5330 - acc: 0.7448 - val_loss: 0.5459 - val_acc: 0.7314\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 573us/step - loss: 0.5221 - acc: 0.7610 - val_loss: 0.5337 - val_acc: 0.7429\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 739us/step - loss: 0.5057 - acc: 0.7605 - val_loss: 0.5555 - val_acc: 0.7090\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 627us/step - loss: 0.5844 - acc: 0.6977 - val_loss: 0.5469 - val_acc: 0.7244\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 578us/step - loss: 0.5682 - acc: 0.7040 - val_loss: 0.5350 - val_acc: 0.7348\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 657us/step - loss: 0.5332 - acc: 0.7218 - val_loss: 0.5280 - val_acc: 0.7425\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 703us/step - loss: 0.5295 - acc: 0.7402 - val_loss: 0.5199 - val_acc: 0.7483\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 585us/step - loss: 0.6305 - acc: 0.6582 - val_loss: 0.5769 - val_acc: 0.7149\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 701us/step - loss: 0.5721 - acc: 0.7062 - val_loss: 0.5596 - val_acc: 0.7259\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 663us/step - loss: 0.5723 - acc: 0.7031 - val_loss: 0.5202 - val_acc: 0.7478\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 676us/step - loss: 0.5624 - acc: 0.7187 - val_loss: 0.5426 - val_acc: 0.7375\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 605us/step - loss: 0.6556 - acc: 0.6269 - val_loss: 0.5917 - val_acc: 0.6931\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 661us/step - loss: 0.5417 - acc: 0.7266 - val_loss: 0.4981 - val_acc: 0.7727\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 670us/step - loss: 0.5891 - acc: 0.7086 - val_loss: 0.5789 - val_acc: 0.7203\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.5358 - acc: 0.7454 - val_loss: 0.5490 - val_acc: 0.7330\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.5528 - acc: 0.7330 - val_loss: 0.5232 - val_acc: 0.7607\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 651us/step - loss: 0.5423 - acc: 0.7374 - val_loss: 0.5632 - val_acc: 0.7118\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 763us/step - loss: 0.5492 - acc: 0.7265 - val_loss: 0.5526 - val_acc: 0.7220\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 655us/step - loss: 0.5855 - acc: 0.6848 - val_loss: 0.5852 - val_acc: 0.6999\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 613us/step - loss: 0.5838 - acc: 0.6825 - val_loss: 0.5045 - val_acc: 0.7625\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 652us/step - loss: 0.5611 - acc: 0.7138 - val_loss: 0.5240 - val_acc: 0.7531\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 622us/step - loss: 0.5708 - acc: 0.6871 - val_loss: 0.5142 - val_acc: 0.7558\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 539us/step - loss: 0.5591 - acc: 0.7190 - val_loss: 0.5062 - val_acc: 0.7684\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 708us/step - loss: 0.5208 - acc: 0.7477 - val_loss: 0.5116 - val_acc: 0.7543\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 560us/step - loss: 0.5845 - acc: 0.6863 - val_loss: 0.5279 - val_acc: 0.7434\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 682us/step - loss: 0.5412 - acc: 0.7253 - val_loss: 0.5185 - val_acc: 0.7454\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 543us/step - loss: 0.5337 - acc: 0.7389 - val_loss: 0.5312 - val_acc: 0.7362\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 667us/step - loss: 0.5673 - acc: 0.7036 - val_loss: 0.5344 - val_acc: 0.7295\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 618us/step - loss: 0.5555 - acc: 0.7171 - val_loss: 0.5475 - val_acc: 0.7144\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 738us/step - loss: 0.5147 - acc: 0.7564 - val_loss: 0.4776 - val_acc: 0.8021\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 682us/step - loss: 0.5220 - acc: 0.7421 - val_loss: 0.5354 - val_acc: 0.7287\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 555us/step - loss: 0.5704 - acc: 0.7018 - val_loss: 0.5316 - val_acc: 0.7409\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 552us/step - loss: 0.5199 - acc: 0.7540 - val_loss: 0.5003 - val_acc: 0.7741\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 874us/step - loss: 0.5496 - acc: 0.7184 - val_loss: 0.5219 - val_acc: 0.7425\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 746us/step - loss: 0.5138 - acc: 0.7499 - val_loss: 0.4861 - val_acc: 0.7773\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 770us/step - loss: 0.5657 - acc: 0.7022 - val_loss: 0.5183 - val_acc: 0.7507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 683us/step - loss: 0.4944 - acc: 0.7855 - val_loss: 0.4784 - val_acc: 0.7925\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 734us/step - loss: 0.5736 - acc: 0.7287 - val_loss: 0.5844 - val_acc: 0.7110\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 727us/step - loss: 0.6018 - acc: 0.6865 - val_loss: 0.5875 - val_acc: 0.6933\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 628us/step - loss: 0.5503 - acc: 0.7276 - val_loss: 0.5453 - val_acc: 0.7380\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 548us/step - loss: 0.5854 - acc: 0.7073 - val_loss: 0.5799 - val_acc: 0.7113\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 730us/step - loss: 0.5600 - acc: 0.7367 - val_loss: 0.5229 - val_acc: 0.7686\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 596us/step - loss: 0.5540 - acc: 0.7275 - val_loss: 0.5381 - val_acc: 0.7424\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 691us/step - loss: 0.5797 - acc: 0.6984 - val_loss: 0.5793 - val_acc: 0.7003\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 602us/step - loss: 0.5901 - acc: 0.6761 - val_loss: 0.5522 - val_acc: 0.7222\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 608us/step - loss: 0.5560 - acc: 0.7258 - val_loss: 0.5405 - val_acc: 0.7351\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 729us/step - loss: 0.5558 - acc: 0.7241 - val_loss: 0.5596 - val_acc: 0.7294\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 572us/step - loss: 0.5641 - acc: 0.7147 - val_loss: 0.5536 - val_acc: 0.7283\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 675us/step - loss: 0.5424 - acc: 0.7340 - val_loss: 0.5402 - val_acc: 0.7372\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 538us/step - loss: 0.5740 - acc: 0.7112 - val_loss: 0.5344 - val_acc: 0.7448\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 572us/step - loss: 0.5878 - acc: 0.6965 - val_loss: 0.5577 - val_acc: 0.7152\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 702us/step - loss: 0.5780 - acc: 0.7039 - val_loss: 0.5262 - val_acc: 0.7473\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 745us/step - loss: 0.5348 - acc: 0.7380 - val_loss: 0.5517 - val_acc: 0.7293\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 648us/step - loss: 0.5669 - acc: 0.7217 - val_loss: 0.5587 - val_acc: 0.7138\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 610us/step - loss: 0.6031 - acc: 0.6770 - val_loss: 0.5255 - val_acc: 0.7613\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 654us/step - loss: 0.5672 - acc: 0.7148 - val_loss: 0.5561 - val_acc: 0.7183\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 828us/step - loss: 0.5612 - acc: 0.7227 - val_loss: 0.5477 - val_acc: 0.7233\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 659us/step - loss: 0.5633 - acc: 0.7088 - val_loss: 0.5531 - val_acc: 0.7269\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 659us/step - loss: 0.4951 - acc: 0.7784 - val_loss: 0.4911 - val_acc: 0.7753\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 707us/step - loss: 0.5801 - acc: 0.6941 - val_loss: 0.5335 - val_acc: 0.7327\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 647us/step - loss: 0.5310 - acc: 0.7442 - val_loss: 0.5120 - val_acc: 0.7526\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 700us/step - loss: 0.5559 - acc: 0.7221 - val_loss: 0.5290 - val_acc: 0.7421\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 565us/step - loss: 0.5446 - acc: 0.7220 - val_loss: 0.5241 - val_acc: 0.7383\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 621us/step - loss: 0.5897 - acc: 0.6773 - val_loss: 0.5549 - val_acc: 0.7173\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 618us/step - loss: 0.5577 - acc: 0.7161 - val_loss: 0.5334 - val_acc: 0.7419\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 616us/step - loss: 0.5431 - acc: 0.7345 - val_loss: 0.5401 - val_acc: 0.7454\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 585us/step - loss: 0.5005 - acc: 0.7745 - val_loss: 0.5043 - val_acc: 0.7589\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 615us/step - loss: 0.5493 - acc: 0.7306 - val_loss: 0.5175 - val_acc: 0.7592\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.5401 - acc: 0.7397 - val_loss: 0.5227 - val_acc: 0.7480\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 676us/step - loss: 0.5370 - acc: 0.7416 - val_loss: 0.5441 - val_acc: 0.7236\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 775us/step - loss: 0.5200 - acc: 0.7602 - val_loss: 0.5159 - val_acc: 0.7577\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 568us/step - loss: 0.5065 - acc: 0.7547 - val_loss: 0.5194 - val_acc: 0.7435\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 671us/step - loss: 0.5967 - acc: 0.6832 - val_loss: 0.5343 - val_acc: 0.7434\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 564us/step - loss: 0.5650 - acc: 0.7145 - val_loss: 0.5292 - val_acc: 0.7449\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 680us/step - loss: 0.5410 - acc: 0.7246 - val_loss: 0.5515 - val_acc: 0.7206\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 810us/step - loss: 0.5338 - acc: 0.7297 - val_loss: 0.5244 - val_acc: 0.7544\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 587us/step - loss: 0.5331 - acc: 0.7404 - val_loss: 0.5534 - val_acc: 0.7182\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 713us/step - loss: 0.5932 - acc: 0.6895 - val_loss: 0.5694 - val_acc: 0.7006\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 902us/step - loss: 0.5022 - acc: 0.7659 - val_loss: 0.5182 - val_acc: 0.7439\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 581us/step - loss: 0.5450 - acc: 0.7318 - val_loss: 0.5479 - val_acc: 0.7248\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 761us/step - loss: 0.5628 - acc: 0.7225 - val_loss: 0.5791 - val_acc: 0.7003\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 669us/step - loss: 0.5714 - acc: 0.7061 - val_loss: 0.5456 - val_acc: 0.7258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 607us/step - loss: 0.5452 - acc: 0.7307 - val_loss: 0.5416 - val_acc: 0.7327\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 764us/step - loss: 0.5577 - acc: 0.7087 - val_loss: 0.5117 - val_acc: 0.7546\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 691us/step - loss: 0.5836 - acc: 0.6905 - val_loss: 0.5407 - val_acc: 0.7380\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 759us/step - loss: 0.5382 - acc: 0.7356 - val_loss: 0.5337 - val_acc: 0.7383\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 622us/step - loss: 0.5410 - acc: 0.7335 - val_loss: 0.5227 - val_acc: 0.7548\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.5977 - acc: 0.7001 - val_loss: 0.5926 - val_acc: 0.6995\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 723us/step - loss: 0.5698 - acc: 0.7159 - val_loss: 0.5487 - val_acc: 0.7256\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 634us/step - loss: 0.5531 - acc: 0.7210 - val_loss: 0.5412 - val_acc: 0.7333\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 735us/step - loss: 0.5184 - acc: 0.7494 - val_loss: 0.4772 - val_acc: 0.7800\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 616us/step - loss: 0.5229 - acc: 0.7579 - val_loss: 0.5220 - val_acc: 0.7549\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 675us/step - loss: 0.5767 - acc: 0.6995 - val_loss: 0.5149 - val_acc: 0.7493\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 622us/step - loss: 0.5434 - acc: 0.7352 - val_loss: 0.5263 - val_acc: 0.7458\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 713us/step - loss: 0.5382 - acc: 0.7402 - val_loss: 0.5446 - val_acc: 0.7348\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 638us/step - loss: 0.5512 - acc: 0.7233 - val_loss: 0.5095 - val_acc: 0.7594\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 707us/step - loss: 0.5276 - acc: 0.7423 - val_loss: 0.4984 - val_acc: 0.7577\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 538us/step - loss: 0.5644 - acc: 0.7160 - val_loss: 0.5242 - val_acc: 0.7504\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 805us/step - loss: 0.5704 - acc: 0.7074 - val_loss: 0.6105 - val_acc: 0.6654\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 567us/step - loss: 0.6014 - acc: 0.6723 - val_loss: 0.5706 - val_acc: 0.6928\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 580us/step - loss: 0.5538 - acc: 0.7097 - val_loss: 0.5395 - val_acc: 0.7273\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 577us/step - loss: 0.5511 - acc: 0.7203 - val_loss: 0.5395 - val_acc: 0.7262\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 685us/step - loss: 0.5310 - acc: 0.7347 - val_loss: 0.5265 - val_acc: 0.7402\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 560us/step - loss: 0.5713 - acc: 0.6988 - val_loss: 0.5489 - val_acc: 0.7130\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 673us/step - loss: 0.5797 - acc: 0.6990 - val_loss: 0.5659 - val_acc: 0.7008\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 539us/step - loss: 0.5459 - acc: 0.7208 - val_loss: 0.5200 - val_acc: 0.7502\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 650us/step - loss: 0.5467 - acc: 0.7298 - val_loss: 0.4970 - val_acc: 0.7772\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 684us/step - loss: 0.5654 - acc: 0.6996 - val_loss: 0.5318 - val_acc: 0.7476\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 673us/step - loss: 0.5784 - acc: 0.7042 - val_loss: 0.5679 - val_acc: 0.7268\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 639us/step - loss: 0.5343 - acc: 0.7424 - val_loss: 0.5105 - val_acc: 0.7600\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 804us/step - loss: 0.5263 - acc: 0.7525 - val_loss: 0.4992 - val_acc: 0.7693\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.5495 - acc: 0.7272 - val_loss: 0.5336 - val_acc: 0.7347\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 713us/step - loss: 0.5093 - acc: 0.7473 - val_loss: 0.5015 - val_acc: 0.7647\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 576us/step - loss: 0.5533 - acc: 0.7267 - val_loss: 0.5146 - val_acc: 0.7573\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 664us/step - loss: 0.5450 - acc: 0.7288 - val_loss: 0.5311 - val_acc: 0.7497\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 672us/step - loss: 0.5546 - acc: 0.7067 - val_loss: 0.5127 - val_acc: 0.7435\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 587us/step - loss: 0.5591 - acc: 0.7220 - val_loss: 0.5362 - val_acc: 0.7413\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.4947 - acc: 0.7708 - val_loss: 0.5319 - val_acc: 0.7374\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 633us/step - loss: 0.5262 - acc: 0.7493 - val_loss: 0.5133 - val_acc: 0.7572\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 685us/step - loss: 0.5095 - acc: 0.7532 - val_loss: 0.5084 - val_acc: 0.7518\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 737us/step - loss: 0.5260 - acc: 0.7503 - val_loss: 0.5440 - val_acc: 0.7281\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 587us/step - loss: 0.5128 - acc: 0.7638 - val_loss: 0.5266 - val_acc: 0.7439\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 746us/step - loss: 0.4984 - acc: 0.7650 - val_loss: 0.5504 - val_acc: 0.7091\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 645us/step - loss: 0.5826 - acc: 0.7015 - val_loss: 0.5317 - val_acc: 0.7350\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 597us/step - loss: 0.5566 - acc: 0.7121 - val_loss: 0.5298 - val_acc: 0.7361\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 642us/step - loss: 0.5225 - acc: 0.7354 - val_loss: 0.5184 - val_acc: 0.7402\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 657us/step - loss: 0.5208 - acc: 0.7509 - val_loss: 0.5169 - val_acc: 0.7471\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 582us/step - loss: 0.6307 - acc: 0.6603 - val_loss: 0.5774 - val_acc: 0.7178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 764us/step - loss: 0.5651 - acc: 0.7125 - val_loss: 0.5606 - val_acc: 0.7236\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 704us/step - loss: 0.5586 - acc: 0.7150 - val_loss: 0.5075 - val_acc: 0.7563\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 689us/step - loss: 0.5446 - acc: 0.7330 - val_loss: 0.5300 - val_acc: 0.7417\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 616us/step - loss: 0.6550 - acc: 0.6347 - val_loss: 0.5877 - val_acc: 0.6972\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 662us/step - loss: 0.5263 - acc: 0.7469 - val_loss: 0.4888 - val_acc: 0.7774\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 644us/step - loss: 0.5907 - acc: 0.7113 - val_loss: 0.5747 - val_acc: 0.7227\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.5329 - acc: 0.7451 - val_loss: 0.5440 - val_acc: 0.7349\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.5409 - acc: 0.7393 - val_loss: 0.5134 - val_acc: 0.7609\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 639us/step - loss: 0.5374 - acc: 0.7397 - val_loss: 0.5564 - val_acc: 0.7147\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 751us/step - loss: 0.5423 - acc: 0.7301 - val_loss: 0.5384 - val_acc: 0.7328\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 654us/step - loss: 0.5793 - acc: 0.6929 - val_loss: 0.5720 - val_acc: 0.7135\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 593us/step - loss: 0.5676 - acc: 0.7018 - val_loss: 0.4932 - val_acc: 0.7667\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 625us/step - loss: 0.5556 - acc: 0.7158 - val_loss: 0.5130 - val_acc: 0.7603\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 622us/step - loss: 0.5676 - acc: 0.6866 - val_loss: 0.5115 - val_acc: 0.7519\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 545us/step - loss: 0.5570 - acc: 0.7222 - val_loss: 0.4977 - val_acc: 0.7665\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 716us/step - loss: 0.5066 - acc: 0.7580 - val_loss: 0.5031 - val_acc: 0.7564\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 575us/step - loss: 0.5777 - acc: 0.6918 - val_loss: 0.5207 - val_acc: 0.7459\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 719us/step - loss: 0.5256 - acc: 0.7383 - val_loss: 0.5102 - val_acc: 0.7500\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 562us/step - loss: 0.5258 - acc: 0.7376 - val_loss: 0.5258 - val_acc: 0.7372\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 697us/step - loss: 0.5486 - acc: 0.7324 - val_loss: 0.5230 - val_acc: 0.7406\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 672us/step - loss: 0.5468 - acc: 0.7175 - val_loss: 0.5407 - val_acc: 0.7180\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 754us/step - loss: 0.5066 - acc: 0.7666 - val_loss: 0.4701 - val_acc: 0.8013\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 715us/step - loss: 0.5155 - acc: 0.7458 - val_loss: 0.5298 - val_acc: 0.7307\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 554us/step - loss: 0.5534 - acc: 0.7137 - val_loss: 0.5223 - val_acc: 0.7477\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 550us/step - loss: 0.5089 - acc: 0.7553 - val_loss: 0.4919 - val_acc: 0.7795\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 909us/step - loss: 0.5500 - acc: 0.7164 - val_loss: 0.5161 - val_acc: 0.7426\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 741us/step - loss: 0.5070 - acc: 0.7543 - val_loss: 0.4781 - val_acc: 0.7781\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 771us/step - loss: 0.5600 - acc: 0.7102 - val_loss: 0.5131 - val_acc: 0.7536\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 666us/step - loss: 0.4749 - acc: 0.7950 - val_loss: 0.4648 - val_acc: 0.7956\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 746us/step - loss: 0.5703 - acc: 0.7295 - val_loss: 0.5767 - val_acc: 0.7138\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 755us/step - loss: 0.5950 - acc: 0.6954 - val_loss: 0.5783 - val_acc: 0.7000\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 663us/step - loss: 0.5468 - acc: 0.7263 - val_loss: 0.5513 - val_acc: 0.7317\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 559us/step - loss: 0.5753 - acc: 0.7228 - val_loss: 0.5713 - val_acc: 0.7209\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 740us/step - loss: 0.5615 - acc: 0.7297 - val_loss: 0.5167 - val_acc: 0.7705\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 645us/step - loss: 0.5421 - acc: 0.7313 - val_loss: 0.5303 - val_acc: 0.7477\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 705us/step - loss: 0.5712 - acc: 0.7055 - val_loss: 0.5789 - val_acc: 0.6989\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 576us/step - loss: 0.5884 - acc: 0.6892 - val_loss: 0.5488 - val_acc: 0.7243\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 593us/step - loss: 0.5566 - acc: 0.7178 - val_loss: 0.5400 - val_acc: 0.7360\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 825us/step - loss: 0.5459 - acc: 0.7290 - val_loss: 0.5484 - val_acc: 0.7369\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 546us/step - loss: 0.5592 - acc: 0.7194 - val_loss: 0.5370 - val_acc: 0.7412\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 673us/step - loss: 0.5352 - acc: 0.7377 - val_loss: 0.5275 - val_acc: 0.7451\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 568us/step - loss: 0.5649 - acc: 0.7186 - val_loss: 0.5240 - val_acc: 0.7550\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 589us/step - loss: 0.5756 - acc: 0.7045 - val_loss: 0.5483 - val_acc: 0.7249\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 722us/step - loss: 0.5706 - acc: 0.7072 - val_loss: 0.5158 - val_acc: 0.7566\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 749us/step - loss: 0.5282 - acc: 0.7469 - val_loss: 0.5434 - val_acc: 0.7377\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 661us/step - loss: 0.5580 - acc: 0.7282 - val_loss: 0.5419 - val_acc: 0.7286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 609us/step - loss: 0.5854 - acc: 0.6903 - val_loss: 0.5156 - val_acc: 0.7662\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 659us/step - loss: 0.5567 - acc: 0.7270 - val_loss: 0.5435 - val_acc: 0.7335\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 836us/step - loss: 0.5569 - acc: 0.7233 - val_loss: 0.5371 - val_acc: 0.7321\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 683us/step - loss: 0.5449 - acc: 0.7234 - val_loss: 0.5425 - val_acc: 0.7330\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 684us/step - loss: 0.4835 - acc: 0.7813 - val_loss: 0.4738 - val_acc: 0.7885\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 735us/step - loss: 0.5815 - acc: 0.6959 - val_loss: 0.5206 - val_acc: 0.7439\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 710us/step - loss: 0.5170 - acc: 0.7583 - val_loss: 0.5011 - val_acc: 0.7586\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 746us/step - loss: 0.5456 - acc: 0.7300 - val_loss: 0.5260 - val_acc: 0.7421\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 556us/step - loss: 0.5449 - acc: 0.7174 - val_loss: 0.5174 - val_acc: 0.7451\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 636us/step - loss: 0.5828 - acc: 0.6910 - val_loss: 0.5542 - val_acc: 0.7127\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 640us/step - loss: 0.5521 - acc: 0.7228 - val_loss: 0.5274 - val_acc: 0.7433\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 625us/step - loss: 0.5359 - acc: 0.7420 - val_loss: 0.5279 - val_acc: 0.7539\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 587us/step - loss: 0.4980 - acc: 0.7735 - val_loss: 0.4987 - val_acc: 0.7647\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 573us/step - loss: 0.5406 - acc: 0.7359 - val_loss: 0.5087 - val_acc: 0.7647\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.5347 - acc: 0.7436 - val_loss: 0.5137 - val_acc: 0.7525\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 683us/step - loss: 0.5313 - acc: 0.7444 - val_loss: 0.5367 - val_acc: 0.7307\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 762us/step - loss: 0.5108 - acc: 0.7689 - val_loss: 0.5119 - val_acc: 0.7595\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 589us/step - loss: 0.5058 - acc: 0.7508 - val_loss: 0.5136 - val_acc: 0.7461\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 724us/step - loss: 0.5888 - acc: 0.6877 - val_loss: 0.5275 - val_acc: 0.7474\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 585us/step - loss: 0.5557 - acc: 0.7216 - val_loss: 0.5210 - val_acc: 0.7505\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 713us/step - loss: 0.5420 - acc: 0.7169 - val_loss: 0.5491 - val_acc: 0.7219\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 740us/step - loss: 0.5265 - acc: 0.7375 - val_loss: 0.5130 - val_acc: 0.7613\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 604us/step - loss: 0.5343 - acc: 0.7412 - val_loss: 0.5487 - val_acc: 0.7209\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 702us/step - loss: 0.5967 - acc: 0.6924 - val_loss: 0.5671 - val_acc: 0.7003\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 890us/step - loss: 0.4986 - acc: 0.7690 - val_loss: 0.5105 - val_acc: 0.7488\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 578us/step - loss: 0.5430 - acc: 0.7324 - val_loss: 0.5391 - val_acc: 0.7299\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 742us/step - loss: 0.5476 - acc: 0.7323 - val_loss: 0.5712 - val_acc: 0.7063\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 663us/step - loss: 0.5720 - acc: 0.7037 - val_loss: 0.5420 - val_acc: 0.7273\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 638us/step - loss: 0.5465 - acc: 0.7275 - val_loss: 0.5332 - val_acc: 0.7351\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 718us/step - loss: 0.5537 - acc: 0.7105 - val_loss: 0.5047 - val_acc: 0.7565\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 694us/step - loss: 0.5896 - acc: 0.6895 - val_loss: 0.5355 - val_acc: 0.7380\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 722us/step - loss: 0.5329 - acc: 0.7384 - val_loss: 0.5242 - val_acc: 0.7453\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 601us/step - loss: 0.5366 - acc: 0.7382 - val_loss: 0.5159 - val_acc: 0.7586\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.5920 - acc: 0.7049 - val_loss: 0.5917 - val_acc: 0.7008\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 687us/step - loss: 0.5592 - acc: 0.7247 - val_loss: 0.5408 - val_acc: 0.7316\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 596us/step - loss: 0.5445 - acc: 0.7293 - val_loss: 0.5307 - val_acc: 0.7414\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 673us/step - loss: 0.5098 - acc: 0.7518 - val_loss: 0.4715 - val_acc: 0.7814\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 558us/step - loss: 0.5108 - acc: 0.7636 - val_loss: 0.5162 - val_acc: 0.7578\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 697us/step - loss: 0.5675 - acc: 0.7085 - val_loss: 0.5081 - val_acc: 0.7540\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 596us/step - loss: 0.5380 - acc: 0.7375 - val_loss: 0.5214 - val_acc: 0.7486\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 726us/step - loss: 0.5316 - acc: 0.7456 - val_loss: 0.5330 - val_acc: 0.7447\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 628us/step - loss: 0.5416 - acc: 0.7267 - val_loss: 0.4963 - val_acc: 0.7703\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 806us/step - loss: 0.5101 - acc: 0.7572 - val_loss: 0.4896 - val_acc: 0.7613\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 607us/step - loss: 0.5643 - acc: 0.7081 - val_loss: 0.5206 - val_acc: 0.7518\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 768us/step - loss: 0.5547 - acc: 0.7247 - val_loss: 0.6026 - val_acc: 0.6722\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 565us/step - loss: 0.5975 - acc: 0.6718 - val_loss: 0.5658 - val_acc: 0.6976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 595us/step - loss: 0.5466 - acc: 0.7158 - val_loss: 0.5287 - val_acc: 0.7375\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 579us/step - loss: 0.5456 - acc: 0.7241 - val_loss: 0.5325 - val_acc: 0.7314\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 701us/step - loss: 0.5251 - acc: 0.7361 - val_loss: 0.5172 - val_acc: 0.7472\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 555us/step - loss: 0.5716 - acc: 0.7017 - val_loss: 0.5429 - val_acc: 0.7182\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 677us/step - loss: 0.5691 - acc: 0.7065 - val_loss: 0.5623 - val_acc: 0.7059\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 540us/step - loss: 0.5338 - acc: 0.7357 - val_loss: 0.5158 - val_acc: 0.7552\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 643us/step - loss: 0.5392 - acc: 0.7409 - val_loss: 0.4937 - val_acc: 0.7838\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 636us/step - loss: 0.5637 - acc: 0.7045 - val_loss: 0.5337 - val_acc: 0.7482\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 673us/step - loss: 0.5762 - acc: 0.7051 - val_loss: 0.5671 - val_acc: 0.7340\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 628us/step - loss: 0.5348 - acc: 0.7376 - val_loss: 0.5099 - val_acc: 0.7583\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 722us/step - loss: 0.5242 - acc: 0.7474 - val_loss: 0.4965 - val_acc: 0.7702\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.5491 - acc: 0.7263 - val_loss: 0.5285 - val_acc: 0.7398\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 776us/step - loss: 0.5097 - acc: 0.7461 - val_loss: 0.4978 - val_acc: 0.7668\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 550us/step - loss: 0.5558 - acc: 0.7281 - val_loss: 0.5175 - val_acc: 0.7557\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 753us/step - loss: 0.5424 - acc: 0.7369 - val_loss: 0.5236 - val_acc: 0.7563\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 696us/step - loss: 0.5515 - acc: 0.7137 - val_loss: 0.5095 - val_acc: 0.7464\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 670us/step - loss: 0.5625 - acc: 0.7234 - val_loss: 0.5297 - val_acc: 0.7464\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4905 - acc: 0.7691 - val_loss: 0.5288 - val_acc: 0.7400\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 625us/step - loss: 0.5214 - acc: 0.7535 - val_loss: 0.5069 - val_acc: 0.7624\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 688us/step - loss: 0.4960 - acc: 0.7623 - val_loss: 0.5015 - val_acc: 0.7552\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 740us/step - loss: 0.5142 - acc: 0.7566 - val_loss: 0.5346 - val_acc: 0.7376\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 589us/step - loss: 0.5101 - acc: 0.7644 - val_loss: 0.5226 - val_acc: 0.7462\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 759us/step - loss: 0.4835 - acc: 0.7770 - val_loss: 0.5441 - val_acc: 0.7148\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 609us/step - loss: 0.5791 - acc: 0.7040 - val_loss: 0.5342 - val_acc: 0.7318\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 575us/step - loss: 0.5542 - acc: 0.7104 - val_loss: 0.5301 - val_acc: 0.7359\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 646us/step - loss: 0.5229 - acc: 0.7307 - val_loss: 0.5207 - val_acc: 0.7388\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 664us/step - loss: 0.5300 - acc: 0.7391 - val_loss: 0.5210 - val_acc: 0.7418\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 565us/step - loss: 0.6257 - acc: 0.6639 - val_loss: 0.5802 - val_acc: 0.7138\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 709us/step - loss: 0.5648 - acc: 0.7127 - val_loss: 0.5600 - val_acc: 0.7219\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 673us/step - loss: 0.5531 - acc: 0.7178 - val_loss: 0.5036 - val_acc: 0.7591\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 666us/step - loss: 0.5386 - acc: 0.7356 - val_loss: 0.5249 - val_acc: 0.7420\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 611us/step - loss: 0.6487 - acc: 0.6408 - val_loss: 0.5833 - val_acc: 0.7007\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 660us/step - loss: 0.5214 - acc: 0.7459 - val_loss: 0.4829 - val_acc: 0.7814\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 649us/step - loss: 0.5827 - acc: 0.7149 - val_loss: 0.5642 - val_acc: 0.7276\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 555us/step - loss: 0.5237 - acc: 0.7573 - val_loss: 0.5394 - val_acc: 0.7364\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 688us/step - loss: 0.5450 - acc: 0.7339 - val_loss: 0.5093 - val_acc: 0.7599\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 586us/step - loss: 0.5340 - acc: 0.7384 - val_loss: 0.5514 - val_acc: 0.7187\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 695us/step - loss: 0.5340 - acc: 0.7373 - val_loss: 0.5339 - val_acc: 0.7369\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 611us/step - loss: 0.5787 - acc: 0.6989 - val_loss: 0.5811 - val_acc: 0.7031\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 584us/step - loss: 0.5720 - acc: 0.6965 - val_loss: 0.4938 - val_acc: 0.7629\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 601us/step - loss: 0.5461 - acc: 0.7224 - val_loss: 0.5134 - val_acc: 0.7596\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 581us/step - loss: 0.5610 - acc: 0.6949 - val_loss: 0.5075 - val_acc: 0.7551\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 541us/step - loss: 0.5462 - acc: 0.7309 - val_loss: 0.4925 - val_acc: 0.7699\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 747us/step - loss: 0.4981 - acc: 0.7656 - val_loss: 0.4993 - val_acc: 0.7565\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 616us/step - loss: 0.5733 - acc: 0.6882 - val_loss: 0.5170 - val_acc: 0.7467\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 668us/step - loss: 0.5261 - acc: 0.7357 - val_loss: 0.5057 - val_acc: 0.7542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 549us/step - loss: 0.5216 - acc: 0.7409 - val_loss: 0.5211 - val_acc: 0.7418\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 632us/step - loss: 0.5613 - acc: 0.7136 - val_loss: 0.5147 - val_acc: 0.7464\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 621us/step - loss: 0.5455 - acc: 0.7192 - val_loss: 0.5358 - val_acc: 0.7245\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 749us/step - loss: 0.4991 - acc: 0.7701 - val_loss: 0.4656 - val_acc: 0.8023\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 699us/step - loss: 0.5129 - acc: 0.7492 - val_loss: 0.5193 - val_acc: 0.7389\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 566us/step - loss: 0.5494 - acc: 0.7211 - val_loss: 0.5126 - val_acc: 0.7542\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 567us/step - loss: 0.5071 - acc: 0.7554 - val_loss: 0.4849 - val_acc: 0.7837\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 847us/step - loss: 0.5417 - acc: 0.7223 - val_loss: 0.5074 - val_acc: 0.7502\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 726us/step - loss: 0.5010 - acc: 0.7536 - val_loss: 0.4691 - val_acc: 0.7832\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 752us/step - loss: 0.5437 - acc: 0.7201 - val_loss: 0.5011 - val_acc: 0.7585\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 681us/step - loss: 0.4764 - acc: 0.7981 - val_loss: 0.4694 - val_acc: 0.7945\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 713us/step - loss: 0.5517 - acc: 0.7410 - val_loss: 0.5651 - val_acc: 0.7238\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 715us/step - loss: 0.5899 - acc: 0.7034 - val_loss: 0.5809 - val_acc: 0.7002\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 684us/step - loss: 0.5441 - acc: 0.7300 - val_loss: 0.5451 - val_acc: 0.7368\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 537us/step - loss: 0.5858 - acc: 0.7112 - val_loss: 0.5710 - val_acc: 0.7227\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 695us/step - loss: 0.5487 - acc: 0.7417 - val_loss: 0.5117 - val_acc: 0.7720\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 586us/step - loss: 0.5439 - acc: 0.7281 - val_loss: 0.5227 - val_acc: 0.7521\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 683us/step - loss: 0.5706 - acc: 0.7065 - val_loss: 0.5726 - val_acc: 0.7038\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 567us/step - loss: 0.5908 - acc: 0.6828 - val_loss: 0.5462 - val_acc: 0.7258\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 570us/step - loss: 0.5436 - acc: 0.7289 - val_loss: 0.5324 - val_acc: 0.7407\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 684us/step - loss: 0.5415 - acc: 0.7335 - val_loss: 0.5477 - val_acc: 0.7360\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 552us/step - loss: 0.5593 - acc: 0.7162 - val_loss: 0.5399 - val_acc: 0.7367\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 657us/step - loss: 0.5357 - acc: 0.7371 - val_loss: 0.5310 - val_acc: 0.7394\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 565us/step - loss: 0.5672 - acc: 0.7176 - val_loss: 0.5227 - val_acc: 0.7531\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 573us/step - loss: 0.5672 - acc: 0.7104 - val_loss: 0.5453 - val_acc: 0.7269\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 737us/step - loss: 0.5634 - acc: 0.7144 - val_loss: 0.5092 - val_acc: 0.7608\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 747us/step - loss: 0.5272 - acc: 0.7455 - val_loss: 0.5428 - val_acc: 0.7370\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 692us/step - loss: 0.5615 - acc: 0.7267 - val_loss: 0.5418 - val_acc: 0.7327\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 630us/step - loss: 0.5806 - acc: 0.7002 - val_loss: 0.5080 - val_acc: 0.7715\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 698us/step - loss: 0.5531 - acc: 0.7324 - val_loss: 0.5385 - val_acc: 0.7281\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 809us/step - loss: 0.5503 - acc: 0.7291 - val_loss: 0.5353 - val_acc: 0.7316\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 672us/step - loss: 0.5413 - acc: 0.7298 - val_loss: 0.5395 - val_acc: 0.7325\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 687us/step - loss: 0.4821 - acc: 0.7858 - val_loss: 0.4694 - val_acc: 0.7898\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 675us/step - loss: 0.5662 - acc: 0.7124 - val_loss: 0.5146 - val_acc: 0.7455\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 753us/step - loss: 0.5187 - acc: 0.7499 - val_loss: 0.4968 - val_acc: 0.7617\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 771us/step - loss: 0.5432 - acc: 0.7285 - val_loss: 0.5207 - val_acc: 0.7470\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 555us/step - loss: 0.5381 - acc: 0.7245 - val_loss: 0.5116 - val_acc: 0.7515\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 652us/step - loss: 0.5884 - acc: 0.6826 - val_loss: 0.5550 - val_acc: 0.7118\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 626us/step - loss: 0.5516 - acc: 0.7171 - val_loss: 0.5261 - val_acc: 0.7430\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 640us/step - loss: 0.5418 - acc: 0.7320 - val_loss: 0.5254 - val_acc: 0.7565\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 619us/step - loss: 0.4915 - acc: 0.7761 - val_loss: 0.4935 - val_acc: 0.7700\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 627us/step - loss: 0.5355 - acc: 0.7406 - val_loss: 0.5040 - val_acc: 0.7686\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 696us/step - loss: 0.5277 - acc: 0.7434 - val_loss: 0.5072 - val_acc: 0.7578\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 688us/step - loss: 0.5242 - acc: 0.7446 - val_loss: 0.5331 - val_acc: 0.7334\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 811us/step - loss: 0.5006 - acc: 0.7716 - val_loss: 0.5070 - val_acc: 0.7627\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 584us/step - loss: 0.4961 - acc: 0.7603 - val_loss: 0.5101 - val_acc: 0.7502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 687us/step - loss: 0.5881 - acc: 0.6913 - val_loss: 0.5198 - val_acc: 0.7535\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 582us/step - loss: 0.5485 - acc: 0.7286 - val_loss: 0.5149 - val_acc: 0.7550\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 650us/step - loss: 0.5349 - acc: 0.7268 - val_loss: 0.5438 - val_acc: 0.7262\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 777us/step - loss: 0.5270 - acc: 0.7297 - val_loss: 0.5073 - val_acc: 0.7652\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 624us/step - loss: 0.5305 - acc: 0.7422 - val_loss: 0.5433 - val_acc: 0.7245\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 715us/step - loss: 0.5841 - acc: 0.6998 - val_loss: 0.5574 - val_acc: 0.7072\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 913us/step - loss: 0.4945 - acc: 0.7666 - val_loss: 0.5044 - val_acc: 0.7549\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 587us/step - loss: 0.5388 - acc: 0.7344 - val_loss: 0.5401 - val_acc: 0.7287\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 758us/step - loss: 0.5492 - acc: 0.7316 - val_loss: 0.5689 - val_acc: 0.7085\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 655us/step - loss: 0.5553 - acc: 0.7165 - val_loss: 0.5361 - val_acc: 0.7283\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 610us/step - loss: 0.5357 - acc: 0.7359 - val_loss: 0.5270 - val_acc: 0.7379\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 706us/step - loss: 0.5436 - acc: 0.7218 - val_loss: 0.4999 - val_acc: 0.7626\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 678us/step - loss: 0.5842 - acc: 0.6970 - val_loss: 0.5317 - val_acc: 0.7388\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 733us/step - loss: 0.5261 - acc: 0.7404 - val_loss: 0.5200 - val_acc: 0.7457\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 585us/step - loss: 0.5351 - acc: 0.7430 - val_loss: 0.5124 - val_acc: 0.7585\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.5681 - acc: 0.7214 - val_loss: 0.5721 - val_acc: 0.7159\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 648us/step - loss: 0.5647 - acc: 0.7209 - val_loss: 0.5389 - val_acc: 0.7342\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 567us/step - loss: 0.5432 - acc: 0.7229 - val_loss: 0.5294 - val_acc: 0.7418\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 629us/step - loss: 0.5116 - acc: 0.7525 - val_loss: 0.4687 - val_acc: 0.7823\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 553us/step - loss: 0.5093 - acc: 0.7628 - val_loss: 0.5168 - val_acc: 0.7569\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 734us/step - loss: 0.5674 - acc: 0.7060 - val_loss: 0.5055 - val_acc: 0.7558\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 623us/step - loss: 0.5344 - acc: 0.7386 - val_loss: 0.5192 - val_acc: 0.7500\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 691us/step - loss: 0.5238 - acc: 0.7546 - val_loss: 0.5309 - val_acc: 0.7459\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 614us/step - loss: 0.5329 - acc: 0.7337 - val_loss: 0.4944 - val_acc: 0.7696\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 702us/step - loss: 0.5058 - acc: 0.7614 - val_loss: 0.4884 - val_acc: 0.7624\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 577us/step - loss: 0.5528 - acc: 0.7237 - val_loss: 0.5118 - val_acc: 0.7567\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 949us/step - loss: 0.5451 - acc: 0.7267 - val_loss: 0.5882 - val_acc: 0.6843\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 696us/step - loss: 0.5895 - acc: 0.6746 - val_loss: 0.5531 - val_acc: 0.7102\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 577us/step - loss: 0.5333 - acc: 0.7298 - val_loss: 0.5172 - val_acc: 0.7468\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 576us/step - loss: 0.5405 - acc: 0.7298 - val_loss: 0.5260 - val_acc: 0.7351\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 682us/step - loss: 0.5145 - acc: 0.7431 - val_loss: 0.5106 - val_acc: 0.7516\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 553us/step - loss: 0.5545 - acc: 0.7208 - val_loss: 0.5334 - val_acc: 0.7264\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 663us/step - loss: 0.5596 - acc: 0.7150 - val_loss: 0.5467 - val_acc: 0.7197\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 558us/step - loss: 0.5227 - acc: 0.7412 - val_loss: 0.5053 - val_acc: 0.7604\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 643us/step - loss: 0.5255 - acc: 0.7456 - val_loss: 0.4822 - val_acc: 0.7870\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 640us/step - loss: 0.5554 - acc: 0.7082 - val_loss: 0.5095 - val_acc: 0.7626\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 679us/step - loss: 0.5559 - acc: 0.7214 - val_loss: 0.5507 - val_acc: 0.7367\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 631us/step - loss: 0.5224 - acc: 0.7448 - val_loss: 0.4989 - val_acc: 0.7646\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 704us/step - loss: 0.5178 - acc: 0.7554 - val_loss: 0.4857 - val_acc: 0.7769\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 567us/step - loss: 0.5357 - acc: 0.7368 - val_loss: 0.5233 - val_acc: 0.7431\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 671us/step - loss: 0.5013 - acc: 0.7509 - val_loss: 0.4963 - val_acc: 0.7654\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 544us/step - loss: 0.5376 - acc: 0.7414 - val_loss: 0.5071 - val_acc: 0.7618\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 657us/step - loss: 0.5333 - acc: 0.7349 - val_loss: 0.5105 - val_acc: 0.7642\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 671us/step - loss: 0.5345 - acc: 0.7219 - val_loss: 0.5007 - val_acc: 0.7570\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 747us/step - loss: 0.5626 - acc: 0.7206 - val_loss: 0.5262 - val_acc: 0.7476\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4825 - acc: 0.7787 - val_loss: 0.5226 - val_acc: 0.7455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 600us/step - loss: 0.5125 - acc: 0.7601 - val_loss: 0.5020 - val_acc: 0.7652\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 638us/step - loss: 0.4975 - acc: 0.7578 - val_loss: 0.4980 - val_acc: 0.7572\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 710us/step - loss: 0.5215 - acc: 0.7512 - val_loss: 0.5325 - val_acc: 0.7363\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 585us/step - loss: 0.5108 - acc: 0.7669 - val_loss: 0.5223 - val_acc: 0.7462\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 725us/step - loss: 0.4840 - acc: 0.7712 - val_loss: 0.5370 - val_acc: 0.7194\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 600us/step - loss: 0.5676 - acc: 0.7099 - val_loss: 0.5230 - val_acc: 0.7373\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 604us/step - loss: 0.5530 - acc: 0.7115 - val_loss: 0.5252 - val_acc: 0.7397\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 655us/step - loss: 0.5187 - acc: 0.7295 - val_loss: 0.5125 - val_acc: 0.7432\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 630us/step - loss: 0.5208 - acc: 0.7481 - val_loss: 0.5141 - val_acc: 0.7462\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 604us/step - loss: 0.6142 - acc: 0.6742 - val_loss: 0.5697 - val_acc: 0.7242\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 714us/step - loss: 0.5640 - acc: 0.7131 - val_loss: 0.5603 - val_acc: 0.7167\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 643us/step - loss: 0.5517 - acc: 0.7177 - val_loss: 0.4977 - val_acc: 0.7642\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 678us/step - loss: 0.5389 - acc: 0.7332 - val_loss: 0.5208 - val_acc: 0.7445\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 601us/step - loss: 0.6503 - acc: 0.6422 - val_loss: 0.5783 - val_acc: 0.7048\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 752us/step - loss: 0.5189 - acc: 0.7468 - val_loss: 0.4777 - val_acc: 0.7835\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 675us/step - loss: 0.5863 - acc: 0.7125 - val_loss: 0.5611 - val_acc: 0.7272\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 554us/step - loss: 0.5220 - acc: 0.7536 - val_loss: 0.5353 - val_acc: 0.7403\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.5317 - acc: 0.7435 - val_loss: 0.5027 - val_acc: 0.7635\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 584us/step - loss: 0.5316 - acc: 0.7379 - val_loss: 0.5481 - val_acc: 0.7191\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 707us/step - loss: 0.5300 - acc: 0.7400 - val_loss: 0.5284 - val_acc: 0.7389\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 629us/step - loss: 0.5697 - acc: 0.7044 - val_loss: 0.5675 - val_acc: 0.7148\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 644us/step - loss: 0.5688 - acc: 0.6997 - val_loss: 0.4876 - val_acc: 0.7659\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 670us/step - loss: 0.5455 - acc: 0.7199 - val_loss: 0.5071 - val_acc: 0.7622\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 596us/step - loss: 0.5570 - acc: 0.6949 - val_loss: 0.4998 - val_acc: 0.7607\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 556us/step - loss: 0.5418 - acc: 0.7296 - val_loss: 0.4894 - val_acc: 0.7657\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 813us/step - loss: 0.4884 - acc: 0.7729 - val_loss: 0.4944 - val_acc: 0.7591\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 563us/step - loss: 0.5686 - acc: 0.6982 - val_loss: 0.5104 - val_acc: 0.7503\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 736us/step - loss: 0.5177 - acc: 0.7370 - val_loss: 0.5007 - val_acc: 0.7579\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 579us/step - loss: 0.5192 - acc: 0.7437 - val_loss: 0.5160 - val_acc: 0.7444\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 708us/step - loss: 0.5612 - acc: 0.7158 - val_loss: 0.5093 - val_acc: 0.7487\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 692us/step - loss: 0.5318 - acc: 0.7274 - val_loss: 0.5310 - val_acc: 0.7316\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 745us/step - loss: 0.5005 - acc: 0.7675 - val_loss: 0.4603 - val_acc: 0.8026\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 821us/step - loss: 0.5034 - acc: 0.7591 - val_loss: 0.5133 - val_acc: 0.7436\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 581us/step - loss: 0.5399 - acc: 0.7328 - val_loss: 0.5055 - val_acc: 0.7586\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 554us/step - loss: 0.5018 - acc: 0.7612 - val_loss: 0.4779 - val_acc: 0.7890\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 881us/step - loss: 0.5289 - acc: 0.7338 - val_loss: 0.5009 - val_acc: 0.7543\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 761us/step - loss: 0.4991 - acc: 0.7551 - val_loss: 0.4626 - val_acc: 0.7870\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 760us/step - loss: 0.5426 - acc: 0.7210 - val_loss: 0.4982 - val_acc: 0.7605\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 696us/step - loss: 0.4667 - acc: 0.7992 - val_loss: 0.4589 - val_acc: 0.7988\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 727us/step - loss: 0.5488 - acc: 0.7437 - val_loss: 0.5589 - val_acc: 0.7300\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 726us/step - loss: 0.5912 - acc: 0.7068 - val_loss: 0.5723 - val_acc: 0.7082\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 674us/step - loss: 0.5425 - acc: 0.7356 - val_loss: 0.5389 - val_acc: 0.7424\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 561us/step - loss: 0.5773 - acc: 0.7230 - val_loss: 0.5673 - val_acc: 0.7260\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 758us/step - loss: 0.5476 - acc: 0.7412 - val_loss: 0.5099 - val_acc: 0.7722\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 601us/step - loss: 0.5337 - acc: 0.7419 - val_loss: 0.5150 - val_acc: 0.7606\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 700us/step - loss: 0.5569 - acc: 0.7185 - val_loss: 0.5536 - val_acc: 0.7206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 637us/step - loss: 0.5670 - acc: 0.7025 - val_loss: 0.5366 - val_acc: 0.7304\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 611us/step - loss: 0.5373 - acc: 0.7390 - val_loss: 0.5293 - val_acc: 0.7442\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 695us/step - loss: 0.5504 - acc: 0.7268 - val_loss: 0.5500 - val_acc: 0.7340\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 559us/step - loss: 0.5492 - acc: 0.7225 - val_loss: 0.5326 - val_acc: 0.7408\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 674us/step - loss: 0.5238 - acc: 0.7446 - val_loss: 0.5245 - val_acc: 0.7472\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 573us/step - loss: 0.5497 - acc: 0.7265 - val_loss: 0.5122 - val_acc: 0.7617\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 555us/step - loss: 0.5752 - acc: 0.7087 - val_loss: 0.5406 - val_acc: 0.7310\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 713us/step - loss: 0.5630 - acc: 0.7138 - val_loss: 0.5029 - val_acc: 0.7618\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 745us/step - loss: 0.5257 - acc: 0.7422 - val_loss: 0.5365 - val_acc: 0.7413\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 670us/step - loss: 0.5565 - acc: 0.7271 - val_loss: 0.5386 - val_acc: 0.7339\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 649us/step - loss: 0.5798 - acc: 0.7040 - val_loss: 0.5028 - val_acc: 0.7739\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 709us/step - loss: 0.5479 - acc: 0.7286 - val_loss: 0.5332 - val_acc: 0.7336\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 828us/step - loss: 0.5420 - acc: 0.7352 - val_loss: 0.5305 - val_acc: 0.7370\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 659us/step - loss: 0.5337 - acc: 0.7377 - val_loss: 0.5296 - val_acc: 0.7399\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 653us/step - loss: 0.4794 - acc: 0.7856 - val_loss: 0.4610 - val_acc: 0.7946\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 659us/step - loss: 0.5676 - acc: 0.7067 - val_loss: 0.5113 - val_acc: 0.7478\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 645us/step - loss: 0.5072 - acc: 0.7559 - val_loss: 0.4962 - val_acc: 0.7634\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 743us/step - loss: 0.5337 - acc: 0.7394 - val_loss: 0.5157 - val_acc: 0.7508\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 541us/step - loss: 0.5259 - acc: 0.7331 - val_loss: 0.5094 - val_acc: 0.7514\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 637us/step - loss: 0.5814 - acc: 0.6945 - val_loss: 0.5629 - val_acc: 0.7045\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 596us/step - loss: 0.5558 - acc: 0.7126 - val_loss: 0.5299 - val_acc: 0.7380\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 660us/step - loss: 0.5398 - acc: 0.7369 - val_loss: 0.5227 - val_acc: 0.7596\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 566us/step - loss: 0.4940 - acc: 0.7725 - val_loss: 0.4899 - val_acc: 0.7742\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 586us/step - loss: 0.5308 - acc: 0.7408 - val_loss: 0.5014 - val_acc: 0.7696\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 690us/step - loss: 0.5222 - acc: 0.7528 - val_loss: 0.5027 - val_acc: 0.7616\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 674us/step - loss: 0.5242 - acc: 0.7470 - val_loss: 0.5312 - val_acc: 0.7340\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 726us/step - loss: 0.5027 - acc: 0.7680 - val_loss: 0.5053 - val_acc: 0.7612\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 561us/step - loss: 0.4982 - acc: 0.7586 - val_loss: 0.5093 - val_acc: 0.7513\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 671us/step - loss: 0.5865 - acc: 0.6981 - val_loss: 0.5150 - val_acc: 0.7546\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 542us/step - loss: 0.5484 - acc: 0.7246 - val_loss: 0.5073 - val_acc: 0.7565\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 653us/step - loss: 0.5393 - acc: 0.7164 - val_loss: 0.5376 - val_acc: 0.7320\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 723us/step - loss: 0.5175 - acc: 0.7376 - val_loss: 0.4988 - val_acc: 0.7715\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 588us/step - loss: 0.5253 - acc: 0.7476 - val_loss: 0.5354 - val_acc: 0.7292\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 697us/step - loss: 0.5807 - acc: 0.7037 - val_loss: 0.5537 - val_acc: 0.7100\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 913us/step - loss: 0.4946 - acc: 0.7701 - val_loss: 0.5033 - val_acc: 0.7564\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 572us/step - loss: 0.5300 - acc: 0.7414 - val_loss: 0.5349 - val_acc: 0.7333\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 726us/step - loss: 0.5514 - acc: 0.7330 - val_loss: 0.5649 - val_acc: 0.7112\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 654us/step - loss: 0.5542 - acc: 0.7219 - val_loss: 0.5304 - val_acc: 0.7326\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 611us/step - loss: 0.5404 - acc: 0.7355 - val_loss: 0.5240 - val_acc: 0.7386\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 704us/step - loss: 0.5377 - acc: 0.7290 - val_loss: 0.4980 - val_acc: 0.7619\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 681us/step - loss: 0.5814 - acc: 0.6968 - val_loss: 0.5275 - val_acc: 0.7425\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 741us/step - loss: 0.5202 - acc: 0.7470 - val_loss: 0.5154 - val_acc: 0.7500\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 600us/step - loss: 0.5295 - acc: 0.7461 - val_loss: 0.5086 - val_acc: 0.7631\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5743 - acc: 0.7171 - val_loss: 0.5757 - val_acc: 0.7171\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 655us/step - loss: 0.5535 - acc: 0.7306 - val_loss: 0.5322 - val_acc: 0.7422\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 577us/step - loss: 0.5355 - acc: 0.7297 - val_loss: 0.5211 - val_acc: 0.7486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 662us/step - loss: 0.5059 - acc: 0.7553 - val_loss: 0.4646 - val_acc: 0.7836\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 593us/step - loss: 0.5068 - acc: 0.7641 - val_loss: 0.5140 - val_acc: 0.7578\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 631us/step - loss: 0.5583 - acc: 0.7163 - val_loss: 0.4989 - val_acc: 0.7617\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 602us/step - loss: 0.5318 - acc: 0.7404 - val_loss: 0.5127 - val_acc: 0.7525\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 696us/step - loss: 0.5179 - acc: 0.7580 - val_loss: 0.5268 - val_acc: 0.7481\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 596us/step - loss: 0.5318 - acc: 0.7356 - val_loss: 0.4861 - val_acc: 0.7735\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 696us/step - loss: 0.5019 - acc: 0.7638 - val_loss: 0.4843 - val_acc: 0.7628\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 555us/step - loss: 0.5423 - acc: 0.7337 - val_loss: 0.5150 - val_acc: 0.7559\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 784us/step - loss: 0.5424 - acc: 0.7299 - val_loss: 0.5905 - val_acc: 0.6849\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 556us/step - loss: 0.5901 - acc: 0.6812 - val_loss: 0.5545 - val_acc: 0.7087\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 597us/step - loss: 0.5292 - acc: 0.7364 - val_loss: 0.5119 - val_acc: 0.7521\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 586us/step - loss: 0.5385 - acc: 0.7308 - val_loss: 0.5230 - val_acc: 0.7388\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 729us/step - loss: 0.5128 - acc: 0.7492 - val_loss: 0.5072 - val_acc: 0.7530\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 578us/step - loss: 0.5575 - acc: 0.7219 - val_loss: 0.5308 - val_acc: 0.7292\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 737us/step - loss: 0.5557 - acc: 0.7206 - val_loss: 0.5405 - val_acc: 0.7218\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 560us/step - loss: 0.5195 - acc: 0.7425 - val_loss: 0.5020 - val_acc: 0.7621\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 644us/step - loss: 0.5303 - acc: 0.7433 - val_loss: 0.4809 - val_acc: 0.7861\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 675us/step - loss: 0.5531 - acc: 0.7073 - val_loss: 0.5121 - val_acc: 0.7603\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 656us/step - loss: 0.5511 - acc: 0.7264 - val_loss: 0.5475 - val_acc: 0.7400\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 618us/step - loss: 0.5231 - acc: 0.7442 - val_loss: 0.4979 - val_acc: 0.7675\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 692us/step - loss: 0.5139 - acc: 0.7558 - val_loss: 0.4868 - val_acc: 0.7764\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 661us/step - loss: 0.5343 - acc: 0.7350 - val_loss: 0.5191 - val_acc: 0.7468\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 669us/step - loss: 0.5014 - acc: 0.7482 - val_loss: 0.4940 - val_acc: 0.7694\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 551us/step - loss: 0.5354 - acc: 0.7423 - val_loss: 0.5032 - val_acc: 0.7656\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 638us/step - loss: 0.5298 - acc: 0.7384 - val_loss: 0.5027 - val_acc: 0.7674\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 666us/step - loss: 0.5394 - acc: 0.7189 - val_loss: 0.4981 - val_acc: 0.7559\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 641us/step - loss: 0.5535 - acc: 0.7251 - val_loss: 0.5193 - val_acc: 0.7503\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 938us/step - loss: 0.4881 - acc: 0.7712 - val_loss: 0.5206 - val_acc: 0.7488\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 628us/step - loss: 0.5017 - acc: 0.7708 - val_loss: 0.4977 - val_acc: 0.7683\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 671us/step - loss: 0.4989 - acc: 0.7569 - val_loss: 0.4919 - val_acc: 0.7631\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 781us/step - loss: 0.5121 - acc: 0.7557 - val_loss: 0.5280 - val_acc: 0.7361\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 565us/step - loss: 0.5036 - acc: 0.7673 - val_loss: 0.5163 - val_acc: 0.7515\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 742us/step - loss: 0.4837 - acc: 0.7740 - val_loss: 0.5364 - val_acc: 0.7187\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 618us/step - loss: 0.5673 - acc: 0.7111 - val_loss: 0.5145 - val_acc: 0.7441\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 597us/step - loss: 0.5446 - acc: 0.7200 - val_loss: 0.5134 - val_acc: 0.7485\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 655us/step - loss: 0.5138 - acc: 0.7402 - val_loss: 0.5036 - val_acc: 0.7499\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 687us/step - loss: 0.5017 - acc: 0.7622 - val_loss: 0.4997 - val_acc: 0.7583\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 559us/step - loss: 0.6083 - acc: 0.6784 - val_loss: 0.5627 - val_acc: 0.7275\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 704us/step - loss: 0.5570 - acc: 0.7209 - val_loss: 0.5559 - val_acc: 0.7216\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 663us/step - loss: 0.5555 - acc: 0.7171 - val_loss: 0.4964 - val_acc: 0.7644\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 662us/step - loss: 0.5287 - acc: 0.7428 - val_loss: 0.5184 - val_acc: 0.7466\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 590us/step - loss: 0.6483 - acc: 0.6437 - val_loss: 0.5767 - val_acc: 0.7048\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 638us/step - loss: 0.5084 - acc: 0.7554 - val_loss: 0.4740 - val_acc: 0.7848\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 646us/step - loss: 0.5754 - acc: 0.7176 - val_loss: 0.5586 - val_acc: 0.7245\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 571us/step - loss: 0.5189 - acc: 0.7533 - val_loss: 0.5302 - val_acc: 0.7413\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 691us/step - loss: 0.5273 - acc: 0.7453 - val_loss: 0.5032 - val_acc: 0.7606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 574us/step - loss: 0.5305 - acc: 0.7397 - val_loss: 0.5448 - val_acc: 0.7225\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 705us/step - loss: 0.5240 - acc: 0.7410 - val_loss: 0.5245 - val_acc: 0.7434\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 618us/step - loss: 0.5701 - acc: 0.7044 - val_loss: 0.5674 - val_acc: 0.7141\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 568us/step - loss: 0.5650 - acc: 0.7008 - val_loss: 0.4848 - val_acc: 0.7670\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 603us/step - loss: 0.5391 - acc: 0.7285 - val_loss: 0.5046 - val_acc: 0.7657\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 573us/step - loss: 0.5566 - acc: 0.6984 - val_loss: 0.4988 - val_acc: 0.7596\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 533us/step - loss: 0.5376 - acc: 0.7330 - val_loss: 0.4878 - val_acc: 0.7659\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 712us/step - loss: 0.4903 - acc: 0.7701 - val_loss: 0.4913 - val_acc: 0.7618\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 555us/step - loss: 0.5701 - acc: 0.6984 - val_loss: 0.5087 - val_acc: 0.7527\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 685us/step - loss: 0.5158 - acc: 0.7403 - val_loss: 0.4990 - val_acc: 0.7589\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 551us/step - loss: 0.5198 - acc: 0.7419 - val_loss: 0.5154 - val_acc: 0.7419\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 736us/step - loss: 0.5422 - acc: 0.7234 - val_loss: 0.5011 - val_acc: 0.7582\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 668us/step - loss: 0.5331 - acc: 0.7288 - val_loss: 0.5290 - val_acc: 0.7316\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 724us/step - loss: 0.4889 - acc: 0.7775 - val_loss: 0.4566 - val_acc: 0.8036\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 696us/step - loss: 0.5038 - acc: 0.7565 - val_loss: 0.5093 - val_acc: 0.7457\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 596us/step - loss: 0.5339 - acc: 0.7330 - val_loss: 0.5029 - val_acc: 0.7610\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 552us/step - loss: 0.4988 - acc: 0.7639 - val_loss: 0.4737 - val_acc: 0.7917\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 834us/step - loss: 0.5281 - acc: 0.7376 - val_loss: 0.4978 - val_acc: 0.7583\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 739us/step - loss: 0.4969 - acc: 0.7548 - val_loss: 0.4574 - val_acc: 0.7897\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 725us/step - loss: 0.5376 - acc: 0.7249 - val_loss: 0.4935 - val_acc: 0.7653\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 674us/step - loss: 0.4678 - acc: 0.7983 - val_loss: 0.4554 - val_acc: 0.8000\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 710us/step - loss: 0.5499 - acc: 0.7477 - val_loss: 0.5578 - val_acc: 0.7323\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 713us/step - loss: 0.5880 - acc: 0.7019 - val_loss: 0.5666 - val_acc: 0.7123\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 674us/step - loss: 0.5327 - acc: 0.7394 - val_loss: 0.5315 - val_acc: 0.7468\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 552us/step - loss: 0.5706 - acc: 0.7225 - val_loss: 0.5563 - val_acc: 0.7323\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 740us/step - loss: 0.5458 - acc: 0.7365 - val_loss: 0.5058 - val_acc: 0.7736\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 587us/step - loss: 0.5326 - acc: 0.7393 - val_loss: 0.5164 - val_acc: 0.7555\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 678us/step - loss: 0.5637 - acc: 0.7159 - val_loss: 0.5630 - val_acc: 0.7098\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 575us/step - loss: 0.5753 - acc: 0.6944 - val_loss: 0.5445 - val_acc: 0.7242\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 570us/step - loss: 0.5410 - acc: 0.7321 - val_loss: 0.5288 - val_acc: 0.7407\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 674us/step - loss: 0.5432 - acc: 0.7323 - val_loss: 0.5438 - val_acc: 0.7382\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 536us/step - loss: 0.5483 - acc: 0.7241 - val_loss: 0.5307 - val_acc: 0.7428\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 659us/step - loss: 0.5168 - acc: 0.7491 - val_loss: 0.5195 - val_acc: 0.7515\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 582us/step - loss: 0.5514 - acc: 0.7295 - val_loss: 0.5134 - val_acc: 0.7574\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 561us/step - loss: 0.5618 - acc: 0.7119 - val_loss: 0.5361 - val_acc: 0.7345\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 703us/step - loss: 0.5573 - acc: 0.7175 - val_loss: 0.4994 - val_acc: 0.7675\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 758us/step - loss: 0.5259 - acc: 0.7448 - val_loss: 0.5341 - val_acc: 0.7420\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 666us/step - loss: 0.5529 - acc: 0.7288 - val_loss: 0.5317 - val_acc: 0.7380\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 618us/step - loss: 0.5769 - acc: 0.7029 - val_loss: 0.4974 - val_acc: 0.7754\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 650us/step - loss: 0.5407 - acc: 0.7347 - val_loss: 0.5295 - val_acc: 0.7327\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 832us/step - loss: 0.5395 - acc: 0.7291 - val_loss: 0.5243 - val_acc: 0.7416\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 658us/step - loss: 0.5385 - acc: 0.7299 - val_loss: 0.5235 - val_acc: 0.7438\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 651us/step - loss: 0.4724 - acc: 0.7851 - val_loss: 0.4576 - val_acc: 0.7956\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 648us/step - loss: 0.5560 - acc: 0.7242 - val_loss: 0.5082 - val_acc: 0.7471\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 608us/step - loss: 0.5111 - acc: 0.7547 - val_loss: 0.4887 - val_acc: 0.7681\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 700us/step - loss: 0.5381 - acc: 0.7328 - val_loss: 0.5176 - val_acc: 0.7476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 580us/step - loss: 0.5302 - acc: 0.7273 - val_loss: 0.5028 - val_acc: 0.7578\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 635us/step - loss: 0.5842 - acc: 0.6929 - val_loss: 0.5566 - val_acc: 0.7091\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 595us/step - loss: 0.5464 - acc: 0.7225 - val_loss: 0.5242 - val_acc: 0.7425\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 607us/step - loss: 0.5337 - acc: 0.7414 - val_loss: 0.5180 - val_acc: 0.7614\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 540us/step - loss: 0.4864 - acc: 0.7783 - val_loss: 0.4855 - val_acc: 0.7771\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 560us/step - loss: 0.5300 - acc: 0.7431 - val_loss: 0.4933 - val_acc: 0.7709\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 701us/step - loss: 0.5202 - acc: 0.7511 - val_loss: 0.4986 - val_acc: 0.7613\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 695us/step - loss: 0.5164 - acc: 0.7527 - val_loss: 0.5251 - val_acc: 0.7400\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 798us/step - loss: 0.4990 - acc: 0.7728 - val_loss: 0.4995 - val_acc: 0.7642\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 596us/step - loss: 0.4923 - acc: 0.7593 - val_loss: 0.5040 - val_acc: 0.7553\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 676us/step - loss: 0.5801 - acc: 0.7000 - val_loss: 0.5093 - val_acc: 0.7597\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 569us/step - loss: 0.5496 - acc: 0.7264 - val_loss: 0.5044 - val_acc: 0.7598\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 648us/step - loss: 0.5311 - acc: 0.7303 - val_loss: 0.5331 - val_acc: 0.7367\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 695us/step - loss: 0.5163 - acc: 0.7416 - val_loss: 0.4946 - val_acc: 0.7716\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 595us/step - loss: 0.5192 - acc: 0.7561 - val_loss: 0.5342 - val_acc: 0.7298\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 705us/step - loss: 0.5769 - acc: 0.7050 - val_loss: 0.5507 - val_acc: 0.7149\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 887us/step - loss: 0.4818 - acc: 0.7764 - val_loss: 0.4962 - val_acc: 0.7632\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 566us/step - loss: 0.5309 - acc: 0.7405 - val_loss: 0.5357 - val_acc: 0.7312\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 733us/step - loss: 0.5479 - acc: 0.7306 - val_loss: 0.5633 - val_acc: 0.7119\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 643us/step - loss: 0.5545 - acc: 0.7215 - val_loss: 0.5259 - val_acc: 0.7358\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 582us/step - loss: 0.5327 - acc: 0.7348 - val_loss: 0.5172 - val_acc: 0.7425\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 678us/step - loss: 0.5328 - acc: 0.7306 - val_loss: 0.4958 - val_acc: 0.7623\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 667us/step - loss: 0.5790 - acc: 0.7010 - val_loss: 0.5215 - val_acc: 0.7455\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 732us/step - loss: 0.5106 - acc: 0.7571 - val_loss: 0.5085 - val_acc: 0.7543\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 590us/step - loss: 0.5293 - acc: 0.7448 - val_loss: 0.5013 - val_acc: 0.7666\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.5638 - acc: 0.7236 - val_loss: 0.5680 - val_acc: 0.7226\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 679us/step - loss: 0.5581 - acc: 0.7263 - val_loss: 0.5292 - val_acc: 0.7424\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 601us/step - loss: 0.5305 - acc: 0.7400 - val_loss: 0.5162 - val_acc: 0.7511\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 662us/step - loss: 0.5012 - acc: 0.7573 - val_loss: 0.4581 - val_acc: 0.7897\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 569us/step - loss: 0.5024 - acc: 0.7659 - val_loss: 0.5132 - val_acc: 0.7557\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 657us/step - loss: 0.5592 - acc: 0.7144 - val_loss: 0.4961 - val_acc: 0.7639\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 640us/step - loss: 0.5269 - acc: 0.7460 - val_loss: 0.5109 - val_acc: 0.7548\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 712us/step - loss: 0.5247 - acc: 0.7514 - val_loss: 0.5232 - val_acc: 0.7521\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 645us/step - loss: 0.5261 - acc: 0.7398 - val_loss: 0.4791 - val_acc: 0.7793\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 705us/step - loss: 0.5003 - acc: 0.7637 - val_loss: 0.4800 - val_acc: 0.7655\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 542us/step - loss: 0.5486 - acc: 0.7290 - val_loss: 0.5124 - val_acc: 0.7563\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 755us/step - loss: 0.5417 - acc: 0.7340 - val_loss: 0.5866 - val_acc: 0.6904\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 544us/step - loss: 0.5832 - acc: 0.6876 - val_loss: 0.5521 - val_acc: 0.7096\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 568us/step - loss: 0.5272 - acc: 0.7348 - val_loss: 0.5083 - val_acc: 0.7523\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 568us/step - loss: 0.5383 - acc: 0.7324 - val_loss: 0.5220 - val_acc: 0.7381\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 704us/step - loss: 0.5117 - acc: 0.7488 - val_loss: 0.5032 - val_acc: 0.7559\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 554us/step - loss: 0.5552 - acc: 0.7182 - val_loss: 0.5277 - val_acc: 0.7326\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 671us/step - loss: 0.5544 - acc: 0.7192 - val_loss: 0.5414 - val_acc: 0.7201\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 547us/step - loss: 0.5165 - acc: 0.7466 - val_loss: 0.5000 - val_acc: 0.7633\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 645us/step - loss: 0.5338 - acc: 0.7379 - val_loss: 0.4752 - val_acc: 0.7912\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 647us/step - loss: 0.5517 - acc: 0.7089 - val_loss: 0.5009 - val_acc: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 646us/step - loss: 0.5435 - acc: 0.7349 - val_loss: 0.5428 - val_acc: 0.7442\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 635us/step - loss: 0.5127 - acc: 0.7572 - val_loss: 0.4928 - val_acc: 0.7678\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 670us/step - loss: 0.5044 - acc: 0.7632 - val_loss: 0.4809 - val_acc: 0.7796\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 600us/step - loss: 0.5376 - acc: 0.7346 - val_loss: 0.5179 - val_acc: 0.7482\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 663us/step - loss: 0.4972 - acc: 0.7534 - val_loss: 0.4928 - val_acc: 0.7700\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 569us/step - loss: 0.5392 - acc: 0.7378 - val_loss: 0.5036 - val_acc: 0.7632\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 689us/step - loss: 0.5248 - acc: 0.7443 - val_loss: 0.5038 - val_acc: 0.7690\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 664us/step - loss: 0.5296 - acc: 0.7281 - val_loss: 0.4958 - val_acc: 0.7579\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 602us/step - loss: 0.5536 - acc: 0.7291 - val_loss: 0.5192 - val_acc: 0.7510\n"
     ]
    }
   ],
   "source": [
    "Max_RNN=5\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(GRU(Max_RNN, return_sequences=True), input_shape=(Max_RNN,513)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(GRU(Max_RNN, return_sequences=True)))\n",
    "# model.add(GRU(output_dim = 513, input_length = 5, input_dim = 513, return_sequences=True))\n",
    "\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(TimeDistributed(Dense(513, activation='sigmoid')))\n",
    "model.add(Dense(513, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "for e in range(10):\n",
    "    for (b_x,b_y), (v_x,v_y) in zip(next_batch(data_train_x, data_train_M), next_batch(data_val_x, data_val_M)):\n",
    "        model.fit(b_x, b_y, validation_data=(v_x,v_y), shuffle=True, batch_size=100)\n",
    "\n",
    "#     model.fit( , epochs=20, steps_per_epoch=700, validation_data=next_batch_mb(DATA_val_x, DATA_val_x,10), validation_steps=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  75.0041942597735\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for v_x,v_y in next_batch(data_val_x, data_val_M):\n",
    "    scores.append( model.evaluate(v_x, v_y,verbose=0)[1] )\n",
    "scores=np.mean(scores)\n",
    "print(\"Accuracy: \",  scores*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_s = 0.0\n",
    "sum_s_diff = 0.0\n",
    "\n",
    "for v_s,v_x,v_x_cmplx,v_s_cmplx in next_batchXSCmplx(data_val_s,data_val_x,val_complx_X,val_complx_S):\n",
    "    \n",
    "#     print(v_s.shape)\n",
    "#     print(v_x.shape)\n",
    "#     print(v_x_cmplx.shape)\n",
    "#     print('v_s_cmplx',v_s_cmplx.shape)\n",
    "    \n",
    "    mask = model.predict(v_x)\n",
    "    S_hat = (mask) * v_x_cmplx\n",
    "    S_hat = S_hat.reshape(-1,513).T\n",
    "    S = v_s_cmplx.T\n",
    "#     S=S.reshape(-1,513)\n",
    "    \n",
    "#     print('S.shape',S.shape)\n",
    "#     print('S_hat.shape',S_hat.shape)\n",
    "\n",
    "    S_org = librosa.istft(S, hop_length=512)\n",
    "    S_pred = librosa.istft(S_hat, hop_length=512)\n",
    "\n",
    "    sum_s += np.sum(S_org*S_org)\n",
    "    sum_s_diff += np.sum((S_org-S_pred)*(S_org-S_pred))\n",
    "    \n",
    "acc = sum_s/ sum_s_diff\n",
    "print(acc)\n",
    "\n",
    "10*np.log10(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write into audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_audio(file_name):\n",
    "    for i in range(len(file_name)):\n",
    "        audio_fname=file_name[i].replace(\"/opt/e533/timit-homework/te/\", \"\").replace(\".wav\",\"\")\n",
    "        print(audio_fname)\n",
    "        sn, sr=librosa.load(file_name[i], sr=None)\n",
    "        Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "        print(mag_Sn.shape)\n",
    "#         mag_Sn=mag_Sn.reshape(-1, 5, 513)\n",
    "        Stest_hat=model.predict(mag_Sn.reshape(-1, 5, 513))\n",
    "        Stest_hat=Stest_hat.reshape(-1,513)\n",
    "        S_hat=(Sn/mag_Sn)*Stest_hat.T\n",
    "\n",
    "        S_time=librosa.istft(S_hat, hop_length=512)\n",
    "        audio_fname=audio_fname + \"_recons.wav\"\n",
    "        print(audio_fname)\n",
    "        librosa.output.write_wav(audio_fname, S_time, sr)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_audio():\n",
    "    mags = None\n",
    "    cmplxs = None\n",
    "    \n",
    "    for e, file_x in enumerate(fname_test[:10]):\n",
    "        print(e)\n",
    "        sn, sr = librosa.load(file_x, sr=None)\n",
    "        Sn = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "        \n",
    "        mags = np.array(mag_Sn.T) if mags is None else np.concatenate( (mags,mag_Sn.T), axis=0)\n",
    "        cmplxs = np.array(Sn.T) if cmplxs is None else np.concatenate( (cmplxs,Sn.T), axis=0)\n",
    "        \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp, mags = mags, None\n",
    "            \n",
    "            temp = temp.reshape((-1,Max_RNN,513))\n",
    "            mask = model.predict(temp)\n",
    "            \n",
    "            mask=mask.reshape(-1,513)\n",
    "            S_hat = (mask) * cmplxs\n",
    "            S_hat = S_hat.T\n",
    "            \n",
    "            lenght_w = S_hat.shape[1]//10\n",
    "            for clip in range(10):\n",
    "                start_w = clip*lenght_w\n",
    "                end_w = (clip+1)*lenght_w\n",
    "                \n",
    "                wav = S_hat[:,start_w:end_w].T\n",
    "                S_time=librosa.istft(wav, hop_length=512)\n",
    "#                 fname = PATH_directory+PATH_denoise+ e + \"_redoise.wav\"\n",
    "#                 audio_fname=file_x.replace(\"/opt/e533/timit-homework/te/\", \"\").replace(\".wav\",\"\")\n",
    "                audio_fname=str(clip) + \"_recons.wav\"\n",
    "                print(audio_fname)\n",
    "                librosa.output.write_wav(audio_fname, S_time, sr)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0_recons.wav\n",
      "1_recons.wav\n",
      "2_recons.wav\n",
      "3_recons.wav\n",
      "4_recons.wav\n",
      "5_recons.wav\n",
      "6_recons.wav\n",
      "7_recons.wav\n",
      "8_recons.wav\n",
      "9_recons.wav\n"
     ]
    }
   ],
   "source": [
    "write_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 65)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "sn, sr=librosa.load(fname_trn[0], sr=None)\n",
    "Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "trn_arr=np.abs(Sn)\n",
    "print(trn_arr.shape)\n",
    "sx, sr=librosa.load(fname_trx[0], sr=None)\n",
    "Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "trx_arr=np.abs(Sx)\n",
    "\n",
    "ss, sr=librosa.load(fname_trs[0], sr=None)\n",
    "Ss=librosa.stft(ss, n_fft=1024, hop_length=512)\n",
    "trs_arr=np.abs(Ss)\n",
    "for i in range(1,1200):\n",
    "\n",
    "    sn, sr=librosa.load(fname_trn[i], sr=None)\n",
    "    Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    mag_Sn=np.abs(Sn)\n",
    "    trn_arr=np.concatenate((trn_arr, mag_Sn), axis=1)\n",
    "#     print(Sn.shape)\n",
    "\n",
    "    sx, sr=librosa.load(fname_trx[i], sr=None)\n",
    "    Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "    mag_Sx=np.abs(Sx)\n",
    "    trx_arr=np.concatenate((trx_arr, mag_Sx), axis=1)\n",
    "    \n",
    "    ss, sr=librosa.load(fname_trs[i], sr=None)\n",
    "    Ss=librosa.stft(ss, n_fft=1024, hop_length=512)\n",
    "    mag_Ss=np.abs(Ss)\n",
    "    trs_arr=np.concatenate((trs_arr, mag_Ss), axis=1)\n",
    "# print(Sn.shape)\n",
    "\n",
    "# sn, sr=librosa.load(fname_trn[129], sr=None)\n",
    "# Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "\n",
    "# print(Sn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 118550)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_train_M = 1*(trs_arr>trn_arr)\n",
    "DATA_train_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((513, 10, 11855), (513, 10, 11855), (513, 10, 11855), (513, 10, 11855))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_arr = trn_arr.reshape( (513,10,-1))\n",
    "trx_arr = trx_arr.reshape( (513,10,-1))\n",
    "trs_arr = trs_arr.reshape( (513,10,-1))\n",
    "DATA_train_M = DATA_train_M.reshape( (513,10,-1))\n",
    "\n",
    "trn_arr.shape, trx_arr.shape, trs_arr.shape, DATA_train_M.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "sn, sr=librosa.load(fname_val_n[0], sr=None)\n",
    "Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "val_n_arr=np.abs(Sn)\n",
    "\n",
    "# print(trn_arr.shape)\n",
    "sx, sr=librosa.load(fname_val_x[0], sr=None)\n",
    "Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "val_x_arr=np.abs(Sx)\n",
    "\n",
    "ss, sr=librosa.load(fname_val_s[0], sr=None)\n",
    "Ss=librosa.stft(ss, n_fft=1024, hop_length=512)\n",
    "val_s_arr=np.abs(Ss)\n",
    "for i in range(1,len(fname_val_n)):\n",
    "\n",
    "    sn, sr=librosa.load(fname_val_n[i], sr=None)\n",
    "    Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    mag_Sn=np.abs(Sn)\n",
    "    val_n_arr=np.concatenate((val_n_arr, mag_Sn), axis=1)\n",
    "#     print(Sn.shape)\n",
    "\n",
    "    sx, sr=librosa.load(fname_val_x[i], sr=None)\n",
    "    Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "    mag_Sx=np.abs(Sx)\n",
    "    val_x_arr=np.concatenate((val_x_arr, mag_Sx), axis=1)\n",
    "    \n",
    "    ss, sr=librosa.load(fname_val_s[i], sr=None)\n",
    "    Ss=librosa.stft(ss, n_fft=1024, hop_length=512)\n",
    "    mag_Ss=np.abs(Ss)\n",
    "    val_s_arr=np.concatenate((val_s_arr, mag_Ss), axis=1)\n",
    "# print(Sn.shape)\n",
    "\n",
    "# sn, sr=librosa.load(fname_trn[129], sr=None)\n",
    "# Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "\n",
    "# print(Sn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 118550)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_val_M = 1*(val_s_arr>val_n_arr)\n",
    "DATA_val_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((513, 10, 11855), (513, 10, 11855), (513, 10, 11855), (513, 10, 11855))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_n_arr = val_n_arr.reshape( (513,10,-1))\n",
    "val_x_arr = val_x_arr.reshape( (513,10,-1))\n",
    "val_s_arr = val_s_arr.reshape( (513,10,-1))\n",
    "DATA_val_M = DATA_val_M.reshape( (513,10,-1))\n",
    "\n",
    "val_n_arr.shape, val_x_arr.shape, val_s_arr.shape, DATA_val_M.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn, sr=librosa.load(fname_test[0], sr=None)\n",
    "Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "test_arr=np.abs(Sn)\n",
    "\n",
    "# print(trn_arr.shape)\n",
    "# sx, sr=librosa.load(fname_val_x[0], sr=None)\n",
    "# Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "# val_x_arr=np.abs(Sx)\n",
    "\n",
    "# ss, sr=librosa.load(fname_val_s[0], sr=None)\n",
    "# Ss=librosa.stft(ss, n_fft=1024, hop_length=512)\n",
    "# val_s_arr=np.abs(Ss)\n",
    "for i in range(1,len(fname_test)):\n",
    "\n",
    "    sn, sr=librosa.load(fname_test[i], sr=None)\n",
    "    Sn=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    mag_Sn=np.abs(Sn)\n",
    "    test_arr=np.concatenate((test_arr, mag_Sn), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 10, 4415)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr.shape\n",
    "test_arr = test_arr.reshape( (513,10,-1))\n",
    "test_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('DATA_train_s.npy', trs_arr)\n",
    "np.save('DATA_train_n.npy', trn_arr)\n",
    "np.save('DATA_train_x.npy', trx_arr)\n",
    "np.save('DATA_train_M.npy', DATA_train_M)\n",
    "\n",
    "np.save('DATA_val_s.npy', val_s_arr)\n",
    "np.save('DATA_val_n.npy', val_n_arr)\n",
    "np.save('DATA_val_x.npy', val_x_arr)\n",
    "np.save('DATA_val_M.npy', DATA_val_M)\n",
    "\n",
    "np.save('DATA_test_x.npy', test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_train_s_f = np.load('DATA_train_s.npy')\n",
    "DATA_train_n_f = np.load('DATA_train_n.npy')\n",
    "DATA_train_x_f = np.load('DATA_train_x.npy')\n",
    "DATA_train_M_f = np.load('DATA_train_M.npy')\n",
    "\n",
    "DATA_val_s_f = np.load('DATA_val_s.npy')\n",
    "DATA_val_n_f = np.load('DATA_val_n.npy')\n",
    "DATA_val_x_f = np.load('DATA_val_x.npy')\n",
    "DATA_val_M_f = np.load('DATA_val_M.npy')\n",
    "\n",
    "DATA_test_x_f = np.load('DATA_test_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_val_M_f[:10, :3, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11855, 10, 513, 2)\n",
      "(11855, 10, 513, 2)\n"
     ]
    }
   ],
   "source": [
    "tr_categorical_labels = to_categorical(DATA_train_M_f.T, num_classes=2)\n",
    "print(tr_categorical_labels.shape)\n",
    "\n",
    "v_categorical_labels = to_categorical(DATA_val_M_f.T, num_classes=2)\n",
    "print(v_categorical_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 10, 10)            20960     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 10)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10, 513)           5643      \n",
      "=================================================================\n",
      "Total params: 26,603\n",
      "Trainable params: 26,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11855 samples, validate on 11855 samples\n",
      "Epoch 1/25\n",
      "11855/11855 [==============================] - 20s 2ms/step - loss: 0.2133 - acc: 0.0017 - val_loss: 0.1920 - val_acc: 0.0018\n",
      "Epoch 2/25\n",
      "11855/11855 [==============================] - 20s 2ms/step - loss: 0.1944 - acc: 0.0026 - val_loss: 0.1836 - val_acc: 0.0022\n",
      "Epoch 3/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1891 - acc: 0.0033 - val_loss: 0.1782 - val_acc: 0.0022\n",
      "Epoch 4/25\n",
      "11855/11855 [==============================] - 20s 2ms/step - loss: 0.1859 - acc: 0.0049 - val_loss: 0.1751 - val_acc: 0.0035\n",
      "Epoch 5/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1838 - acc: 0.0076 - val_loss: 0.1735 - val_acc: 0.0071\n",
      "Epoch 6/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1824 - acc: 0.0124 - val_loss: 0.1718 - val_acc: 0.0091\n",
      "Epoch 7/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1812 - acc: 0.0162 - val_loss: 0.1712 - val_acc: 0.0165\n",
      "Epoch 8/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1803 - acc: 0.0190 - val_loss: 0.1704 - val_acc: 0.0194\n",
      "Epoch 9/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1796 - acc: 0.0208 - val_loss: 0.1697 - val_acc: 0.0236\n",
      "Epoch 10/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1790 - acc: 0.0223 - val_loss: 0.1690 - val_acc: 0.0182\n",
      "Epoch 11/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1782 - acc: 0.0229 - val_loss: 0.1679 - val_acc: 0.0211\n",
      "Epoch 12/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1779 - acc: 0.0235 - val_loss: 0.1677 - val_acc: 0.0211\n",
      "Epoch 13/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1775 - acc: 0.0231 - val_loss: 0.1679 - val_acc: 0.0221\n",
      "Epoch 14/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1771 - acc: 0.0236 - val_loss: 0.1678 - val_acc: 0.0223\n",
      "Epoch 15/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1768 - acc: 0.0252 - val_loss: 0.1677 - val_acc: 0.0235\n",
      "Epoch 16/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1763 - acc: 0.0242 - val_loss: 0.1674 - val_acc: 0.0237\n",
      "Epoch 17/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1761 - acc: 0.0249 - val_loss: 0.1668 - val_acc: 0.0276\n",
      "Epoch 18/25\n",
      "11855/11855 [==============================] - 19s 2ms/step - loss: 0.1761 - acc: 0.0245 - val_loss: 0.1669 - val_acc: 0.0220\n",
      "Epoch 19/25\n",
      "11855/11855 [==============================] - 25s 2ms/step - loss: 0.1755 - acc: 0.0248 - val_loss: 0.1661 - val_acc: 0.0241\n",
      "Epoch 20/25\n",
      "11855/11855 [==============================] - 26s 2ms/step - loss: 0.1753 - acc: 0.0241 - val_loss: 0.1657 - val_acc: 0.0220\n",
      "Epoch 21/25\n",
      "11855/11855 [==============================] - 24s 2ms/step - loss: 0.1752 - acc: 0.0244 - val_loss: 0.1653 - val_acc: 0.0241\n",
      "Epoch 22/25\n",
      "11855/11855 [==============================] - 24s 2ms/step - loss: 0.1751 - acc: 0.0244 - val_loss: 0.1659 - val_acc: 0.0257\n",
      "Epoch 23/25\n",
      "11855/11855 [==============================] - 25s 2ms/step - loss: 0.1747 - acc: 0.0247 - val_loss: 0.1653 - val_acc: 0.0217\n",
      "Epoch 24/25\n",
      "11855/11855 [==============================] - 25s 2ms/step - loss: 0.1744 - acc: 0.0237 - val_loss: 0.1660 - val_acc: 0.0235\n",
      "Epoch 25/25\n",
      "11855/11855 [==============================] - 24s 2ms/step - loss: 0.1744 - acc: 0.0237 - val_loss: 0.1658 - val_acc: 0.0265\n",
      "Accuracy: 2.65%\n"
     ]
    }
   ],
   "source": [
    "Max_RNN = 10\n",
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(Max_RNN, return_sequences=True, input_shape=(Max_RNN,513)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(513, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# model.fit(DATA_train_x_f.T, tr_categorical_labels, validation_data=(DATA_val_x_f.T,v_categorical_labels), shuffle=True, nb_epoch=100, batch_size=10)\n",
    "# # Final evaluation of the model\n",
    "# scores = model.evaluate(DATA_val_x_f.T, v_categorical_labels, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(DATA_train_x_f.T, DATA_train_M_f.T, validation_data=(DATA_val_x_f.T,DATA_val_M_f.T), shuffle=True, nb_epoch=25, batch_size=10)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(DATA_val_x_f.T, DATA_val_M_f.T, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "sx, sr=librosa.load(fname_trx[0], sr=None)\n",
    "Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "X_tr=Sx\n",
    "\n",
    "for i in range(1,len(fname_trx)):\n",
    "\n",
    "    sx, sr=librosa.load(fname_trx[i], sr=None)\n",
    "    Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "#     mag_Sx=np.abs(Sx)\n",
    "    X_tr=np.concatenate((X_tr, Sx), axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "sx, sr=librosa.load(fname_val_x[0], sr=None)\n",
    "Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "X_val=Sx\n",
    "\n",
    "for i in range(1,len(fname_val_x)):\n",
    "\n",
    "    sx, sr=librosa.load(fname_val_x[i], sr=None)\n",
    "    Sx=librosa.stft(sx, n_fft=1024, hop_length=512)\n",
    "#     mag_Sx=np.abs(Sx)\n",
    "    X_val=np.concatenate((X_val, Sx), axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11855, 10, 513)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = model.predict(DATA_val_x_f.T)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_hat = (labels.T) * DATA_val_x_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_org = (DATA_val_s_f).flatten()\n",
    "S_pred = S_hat.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.074747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.101006865501404"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.sum(S_org*S_org)/ np.sum((S_org-S_pred)*(S_org-S_pred))\n",
    "print(acc)\n",
    "\n",
    "10*np.log10(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
