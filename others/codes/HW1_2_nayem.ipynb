{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR-E 533: Deep Learning Systems\n",
    "## Homework 1\n",
    "\n",
    "### Khandokar Md. Nayem (knayem@iu.edu)\n",
    "### Mar 9, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary files and set environment parameters\n",
    "My assigned Node is `r-006` and GPU `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy -> Input Data\n",
    "sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "X_mag = np.abs(X)\n",
    "\n",
    "# Clean -> Label\n",
    "s, sr=librosa.load('train_clean_male.wav', sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "S_mag = np.abs(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X,Y, batch_size):\n",
    "    num_samples, _ = X.shape\n",
    "    \n",
    "    selected_indics = np.random.randint(num_samples-batch_size)\n",
    "#     print(selected_indics)\n",
    "    return X[selected_indics:selected_indics+batch_size], Y[selected_indics:selected_indics+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATION = 1000\n",
    "BATCH_SIZE = X_mag.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier Initialization of Weights\n",
    "These are the weight initialization function used in defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable (shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = np.sqrt(2.0/sum(shape)) )\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable (shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = np.sqrt(1.0/sum(shape)) )\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the fully connected model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 513]) \n",
    "\n",
    "W_1 = weight_variable([513, 1024])\n",
    "b_1 = bias_variable([1024])\n",
    "\n",
    "W_2 = weight_variable([1024, 1024])\n",
    "b_2 = bias_variable([1024])\n",
    "\n",
    "W_3 = weight_variable([1024, 1024])\n",
    "b_3 = bias_variable([1024])\n",
    "\n",
    "W_4 = weight_variable([1024, 1024])\n",
    "b_4 = bias_variable([1024])\n",
    "\n",
    "W_5 = weight_variable([1024, 513])\n",
    "b_5 = bias_variable([513])\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 513]) # original\n",
    "\n",
    "\n",
    "# Layer connections and Activation functions\n",
    "y_1 = tf.nn.relu(tf.matmul(x, W_1) + b_1)\n",
    "y_2 = tf.nn.relu(tf.matmul(y_1, W_2) + b_2)\n",
    "y_3 = tf.nn.relu(tf.matmul(y_2, W_3) + b_3)\n",
    "y_4 = tf.nn.relu(tf.matmul(y_3, W_4) + b_4)\n",
    "y =  tf.nn.relu(tf.matmul(y_2, W_5) + b_5) # predicted\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "mse = tf.reduce_sum( tf.losses.mean_squared_error(labels=y_, predictions=y) )\n",
    "train_step = tf.train.AdamOptimizer().minimize(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "We try different batch sizes, but for whole input dimension batch size gives better result and it removes the need of batch normalization. Since the input dimension is not very large, we can do this. For larger input dimensions, we have to adopt mini batch techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration to control GPU use\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.33\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "# Train Model\n",
    "for _ in range(NUM_ITERATION):\n",
    "    for _ in range(((X_mag.T).shape[0]//BATCH_SIZE)):\n",
    "        batch_xs, batch_ys = next_batch(X_mag.T,S_mag.T, BATCH_SIZE)\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 142)\n"
     ]
    }
   ],
   "source": [
    "# Load Test data-1\n",
    "sn, sr=librosa.load('test_x_01.wav', sr=None)\n",
    "X_test_01=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "X_mag_test_01 = np.abs(X_test_01)\n",
    "\n",
    "# Load Test data-2\n",
    "sn, sr=librosa.load('test_x_02.wav', sr=None)\n",
    "X_test_02=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "X_mag_test_02 = np.abs(X_test_02)\n",
    "\n",
    "print(X_mag_test_01.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Test Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model-1\n",
    "S_hat_mag_test_01=sess.run(y, feed_dict={x: X_mag_test_01.T})\n",
    "S_hat_test_01=(X_test_01/X_mag_test_01)*S_hat_mag_test_01.T\n",
    "S_hat_01=librosa.istft(S_hat_test_01, hop_length=512)\n",
    "librosa.output.write_wav('test_s_01_recons.wav', S_hat_01, sr)\n",
    "\n",
    "# Test model-2\n",
    "S_hat_mag_test_02=sess.run(y, feed_dict={x: X_mag_test_02.T})\n",
    "S_hat_test_02=(X_test_02/X_mag_test_02)*S_hat_mag_test_02.T\n",
    "S_hat_02=librosa.istft(S_hat_test_02, hop_length=512)\n",
    "librosa.output.write_wav('test_s_02_recons.wav', S_hat_02, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
