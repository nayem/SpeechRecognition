{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR-E 533: Deep Learning Systems\n",
    "## Homework 2\n",
    "\n",
    "### Khandokar Md. Nayem (knayem@iu.edu)\n",
    "### Apr 3, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary files and set environment parameters\n",
    "My assigned Node is `r-005` and GPU `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "\n",
    "Directory names, file formates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_directory = '/N/u/knayem/data/timit-homework/'\n",
    "\n",
    "PATH_train = 'tr/'\n",
    "PATH_val = 'v/'\n",
    "PATH_test = 'te/'\n",
    "PATH_denoise = 'dn/'\n",
    "\n",
    "CLEAN_format_train = 'trs*.wav'\n",
    "NOISE_format_train = 'trn*.wav'\n",
    "MIX_format_train = 'trx*.wav'\n",
    "\n",
    "CLEAN_format_val = 'vs*.wav'\n",
    "NOISE_format_val = 'vn*.wav'\n",
    "MIX_format_val = 'vx*.wav'\n",
    "\n",
    "MIX_format_test = 'tex*.wav'\n",
    "\n",
    "Max_RNN = 5 # Number of Time Stamps in a RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Names\n",
    "\n",
    "Since there are huge number of files for both training, validation and testing, for convinience we write them in files. These are the name of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_S = 'TRAIN_S.txt'\n",
    "TRAIN_N = 'TRAIN_N.txt'\n",
    "TRAIN_X_cmplx = 'TRAIN_X_cmplx.txt'\n",
    "TRAIN_X = 'TRAIN_X.txt'\n",
    "\n",
    "VAL_S = 'VAL_S.txt'\n",
    "VAL_S_cmplx = 'VAL_S_cmplx.txt'\n",
    "VAL_N = 'VAL_N.txt'\n",
    "VAL_X_cmplx = 'VAL_X_cmplx.txt'\n",
    "VAL_X = 'VAL_X.txt'\n",
    "\n",
    "\n",
    "TEST_S = 'TEST_S.txt'\n",
    "TEST_N = 'TEST_N.txt'\n",
    "TEST_X_cmplx = 'TEST_X_cmplx.txt'\n",
    "TEST_X = 'TEST_X.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a .wav file\n",
    "A function to get the Complex and Magnitude Spectum of a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprossed_data(file_name):\n",
    "    \n",
    "    sn, sr=librosa.load(file_name, sr=None)\n",
    "    X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    X_mag = np.abs(X)\n",
    "#     print('X_mag',X_mag.shape)\n",
    "    return X, X_mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Train Data  \n",
    "\n",
    "Here we open the files, and read the Train Dataset. We need to run this portion for the first time only. This file reading needs lots fo time. After saving in file once, we can load data from files unless you want complex version of Noisy Speech. Complex numbers are hard to retrive from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ...\n",
      "2 ...\n",
      "3 ...\n",
      "4 ...\n",
      "5 ...\n",
      "6 ...\n",
      "7 ...\n",
      "8 ...\n",
      "9 ...\n",
      "10 ...\n",
      "11 ...\n",
      "12 ...\n",
      "13 ...\n",
      "14 ...\n",
      "15 ...\n",
      "16 ...\n",
      "17 ...\n",
      "18 ...\n",
      "19 ...\n",
      "20 ...\n",
      "21 ...\n",
      "22 ...\n",
      "23 ...\n",
      "24 ...\n",
      "25 ...\n",
      "26 ...\n",
      "27 ...\n",
      "28 ...\n",
      "29 ...\n",
      "30 ...\n",
      "31 ...\n",
      "32 ...\n",
      "33 ...\n",
      "34 ...\n",
      "35 ...\n",
      "36 ...\n",
      "37 ...\n",
      "38 ...\n",
      "39 ...\n",
      "40 ...\n",
      "41 ...\n",
      "42 ...\n",
      "43 ...\n",
      "44 ...\n",
      "45 ...\n",
      "46 ...\n",
      "47 ...\n",
      "48 ...\n",
      "49 ...\n",
      "50 ...\n",
      "51 ...\n",
      "52 ...\n",
      "53 ...\n",
      "54 ...\n",
      "55 ...\n",
      "56 ...\n",
      "57 ...\n",
      "58 ...\n",
      "59 ...\n",
      "60 ...\n",
      "61 ...\n",
      "62 ...\n",
      "63 ...\n",
      "64 ...\n",
      "65 ...\n",
      "66 ...\n",
      "67 ...\n",
      "68 ...\n",
      "69 ...\n",
      "70 ...\n",
      "71 ...\n",
      "72 ...\n",
      "73 ...\n",
      "74 ...\n",
      "75 ...\n",
      "76 ...\n",
      "77 ...\n",
      "78 ...\n",
      "79 ...\n",
      "80 ...\n",
      "81 ...\n",
      "82 ...\n",
      "83 ...\n",
      "84 ...\n",
      "85 ...\n",
      "86 ...\n",
      "87 ...\n",
      "88 ...\n",
      "89 ...\n",
      "90 ...\n",
      "91 ...\n",
      "92 ...\n",
      "93 ...\n",
      "94 ...\n",
      "95 ...\n",
      "96 ...\n",
      "97 ...\n",
      "98 ...\n",
      "99 ...\n",
      "100 ...\n",
      "101 ...\n",
      "102 ...\n",
      "103 ...\n",
      "104 ...\n",
      "105 ...\n",
      "106 ...\n",
      "107 ...\n",
      "108 ...\n",
      "109 ...\n",
      "110 ...\n",
      "111 ...\n",
      "112 ...\n",
      "113 ...\n",
      "114 ...\n",
      "115 ...\n",
      "116 ...\n",
      "117 ...\n",
      "118 ...\n",
      "119 ...\n",
      "120 ...\n",
      "121 ...\n",
      "122 ...\n",
      "123 ...\n",
      "124 ...\n",
      "125 ...\n",
      "126 ...\n",
      "127 ...\n",
      "128 ...\n",
      "129 ...\n",
      "130 ...\n",
      "131 ...\n",
      "132 ...\n",
      "133 ...\n",
      "134 ...\n",
      "135 ...\n",
      "136 ...\n",
      "137 ...\n",
      "138 ...\n",
      "139 ...\n",
      "140 ...\n",
      "141 ...\n",
      "142 ...\n",
      "143 ...\n",
      "144 ...\n",
      "145 ...\n",
      "146 ...\n",
      "147 ...\n",
      "148 ...\n",
      "149 ...\n",
      "150 ...\n",
      "151 ...\n",
      "152 ...\n",
      "153 ...\n",
      "154 ...\n",
      "155 ...\n",
      "156 ...\n",
      "157 ...\n",
      "158 ...\n",
      "159 ...\n",
      "160 ...\n",
      "161 ...\n",
      "162 ...\n",
      "163 ...\n",
      "164 ...\n",
      "165 ...\n",
      "166 ...\n",
      "167 ...\n",
      "168 ...\n",
      "169 ...\n",
      "170 ...\n",
      "171 ...\n",
      "172 ...\n",
      "173 ...\n",
      "174 ...\n",
      "175 ...\n",
      "176 ...\n",
      "177 ...\n",
      "178 ...\n",
      "179 ...\n",
      "180 ...\n",
      "181 ...\n",
      "182 ...\n",
      "183 ...\n",
      "184 ...\n",
      "185 ...\n",
      "186 ...\n",
      "187 ...\n",
      "188 ...\n",
      "189 ...\n",
      "190 ...\n",
      "191 ...\n",
      "192 ...\n",
      "193 ...\n",
      "194 ...\n",
      "195 ...\n",
      "196 ...\n",
      "197 ...\n",
      "198 ...\n",
      "199 ...\n",
      "200 ...\n",
      "201 ...\n",
      "202 ...\n",
      "203 ...\n",
      "204 ...\n",
      "205 ...\n",
      "206 ...\n",
      "207 ...\n",
      "208 ...\n",
      "209 ...\n",
      "210 ...\n",
      "211 ...\n",
      "212 ...\n",
      "213 ...\n",
      "214 ...\n",
      "215 ...\n",
      "216 ...\n",
      "217 ...\n",
      "218 ...\n",
      "219 ...\n",
      "220 ...\n",
      "221 ...\n",
      "222 ...\n",
      "223 ...\n",
      "224 ...\n",
      "225 ...\n",
      "226 ...\n",
      "227 ...\n",
      "228 ...\n",
      "229 ...\n",
      "230 ...\n",
      "231 ...\n",
      "232 ...\n",
      "233 ...\n",
      "234 ...\n",
      "235 ...\n",
      "236 ...\n",
      "237 ...\n",
      "238 ...\n",
      "239 ...\n",
      "240 ...\n",
      "241 ...\n",
      "242 ...\n",
      "243 ...\n",
      "244 ...\n",
      "245 ...\n",
      "246 ...\n",
      "247 ...\n",
      "248 ...\n",
      "249 ...\n",
      "250 ...\n",
      "251 ...\n",
      "252 ...\n",
      "253 ...\n",
      "254 ...\n",
      "255 ...\n",
      "256 ...\n",
      "257 ...\n",
      "258 ...\n",
      "259 ...\n",
      "260 ...\n",
      "261 ...\n",
      "262 ...\n",
      "263 ...\n",
      "264 ...\n",
      "265 ...\n",
      "266 ...\n",
      "267 ...\n",
      "268 ...\n",
      "269 ...\n",
      "270 ...\n",
      "271 ...\n",
      "272 ...\n",
      "273 ...\n",
      "274 ...\n",
      "275 ...\n",
      "276 ...\n",
      "277 ...\n",
      "278 ...\n",
      "279 ...\n",
      "280 ...\n",
      "281 ...\n",
      "282 ...\n",
      "283 ...\n",
      "284 ...\n",
      "285 ...\n",
      "286 ...\n",
      "287 ...\n",
      "288 ...\n",
      "289 ...\n",
      "290 ...\n",
      "291 ...\n",
      "292 ...\n",
      "293 ...\n",
      "294 ...\n",
      "295 ...\n",
      "296 ...\n",
      "297 ...\n",
      "298 ...\n",
      "299 ...\n",
      "300 ...\n",
      "301 ...\n",
      "302 ...\n",
      "303 ...\n",
      "304 ...\n",
      "305 ...\n",
      "306 ...\n",
      "307 ...\n",
      "308 ...\n",
      "309 ...\n",
      "310 ...\n",
      "311 ...\n",
      "312 ...\n",
      "313 ...\n",
      "314 ...\n",
      "315 ...\n",
      "316 ...\n",
      "317 ...\n",
      "318 ...\n",
      "319 ...\n",
      "320 ...\n",
      "321 ...\n",
      "322 ...\n",
      "323 ...\n",
      "324 ...\n",
      "325 ...\n",
      "326 ...\n",
      "327 ...\n",
      "328 ...\n",
      "329 ...\n",
      "330 ...\n",
      "331 ...\n",
      "332 ...\n",
      "333 ...\n",
      "334 ...\n",
      "335 ...\n",
      "336 ...\n",
      "337 ...\n",
      "338 ...\n",
      "339 ...\n",
      "340 ...\n",
      "341 ...\n",
      "342 ...\n",
      "343 ...\n",
      "344 ...\n",
      "345 ...\n",
      "346 ...\n",
      "347 ...\n",
      "348 ...\n",
      "349 ...\n",
      "350 ...\n",
      "351 ...\n",
      "352 ...\n",
      "353 ...\n",
      "354 ...\n",
      "355 ...\n",
      "356 ...\n",
      "357 ...\n",
      "358 ...\n",
      "359 ...\n",
      "360 ...\n",
      "361 ...\n",
      "362 ...\n",
      "363 ...\n",
      "364 ...\n",
      "365 ...\n",
      "366 ...\n",
      "367 ...\n",
      "368 ...\n",
      "369 ...\n",
      "370 ...\n",
      "371 ...\n",
      "372 ...\n",
      "373 ...\n",
      "374 ...\n",
      "375 ...\n",
      "376 ...\n",
      "377 ...\n",
      "378 ...\n",
      "379 ...\n",
      "380 ...\n",
      "381 ...\n",
      "382 ...\n",
      "383 ...\n",
      "384 ...\n",
      "385 ...\n",
      "386 ...\n",
      "387 ...\n",
      "388 ...\n",
      "389 ...\n",
      "390 ...\n",
      "391 ...\n",
      "392 ...\n",
      "393 ...\n",
      "394 ...\n",
      "395 ...\n",
      "396 ...\n",
      "397 ...\n",
      "398 ...\n",
      "399 ...\n",
      "400 ...\n",
      "401 ...\n",
      "402 ...\n",
      "403 ...\n",
      "404 ...\n",
      "405 ...\n",
      "406 ...\n",
      "407 ...\n",
      "408 ...\n",
      "409 ...\n",
      "410 ...\n",
      "411 ...\n",
      "412 ...\n",
      "413 ...\n",
      "414 ...\n",
      "415 ...\n",
      "416 ...\n",
      "417 ...\n",
      "418 ...\n",
      "419 ...\n",
      "420 ...\n",
      "421 ...\n",
      "422 ...\n",
      "423 ...\n",
      "424 ...\n",
      "425 ...\n",
      "426 ...\n",
      "427 ...\n",
      "428 ...\n",
      "429 ...\n",
      "430 ...\n",
      "431 ...\n",
      "432 ...\n",
      "433 ...\n",
      "434 ...\n",
      "435 ...\n",
      "436 ...\n",
      "437 ...\n",
      "438 ...\n",
      "439 ...\n",
      "440 ...\n",
      "441 ...\n",
      "442 ...\n",
      "443 ...\n",
      "444 ...\n",
      "445 ...\n",
      "446 ...\n",
      "447 ...\n",
      "448 ...\n",
      "449 ...\n",
      "450 ...\n",
      "451 ...\n",
      "452 ...\n",
      "453 ...\n",
      "454 ...\n",
      "455 ...\n",
      "456 ...\n",
      "457 ...\n",
      "458 ...\n",
      "459 ...\n",
      "460 ...\n",
      "461 ...\n",
      "462 ...\n",
      "463 ...\n",
      "464 ...\n",
      "465 ...\n",
      "466 ...\n",
      "467 ...\n",
      "468 ...\n",
      "469 ...\n",
      "470 ...\n",
      "471 ...\n",
      "472 ...\n",
      "473 ...\n",
      "474 ...\n",
      "475 ...\n",
      "476 ...\n",
      "477 ...\n",
      "478 ...\n",
      "479 ...\n",
      "480 ...\n",
      "481 ...\n",
      "482 ...\n",
      "483 ...\n",
      "484 ...\n",
      "485 ...\n",
      "486 ...\n",
      "487 ...\n",
      "488 ...\n",
      "489 ...\n",
      "490 ...\n",
      "491 ...\n",
      "492 ...\n",
      "493 ...\n",
      "494 ...\n",
      "495 ...\n",
      "496 ...\n",
      "497 ...\n",
      "498 ...\n",
      "499 ...\n",
      "500 ...\n",
      "501 ...\n",
      "502 ...\n",
      "503 ...\n",
      "504 ...\n",
      "505 ...\n",
      "506 ...\n",
      "507 ...\n",
      "508 ...\n",
      "509 ...\n",
      "510 ...\n",
      "511 ...\n",
      "512 ...\n",
      "513 ...\n",
      "514 ...\n",
      "515 ...\n",
      "516 ...\n",
      "517 ...\n",
      "518 ...\n",
      "519 ...\n",
      "520 ...\n",
      "521 ...\n",
      "522 ...\n",
      "523 ...\n",
      "524 ...\n",
      "525 ...\n",
      "526 ...\n",
      "527 ...\n",
      "528 ...\n",
      "529 ...\n",
      "530 ...\n",
      "531 ...\n",
      "532 ...\n",
      "533 ...\n",
      "534 ...\n",
      "535 ...\n",
      "536 ...\n",
      "537 ...\n",
      "538 ...\n",
      "539 ...\n",
      "540 ...\n",
      "541 ...\n",
      "542 ...\n",
      "543 ...\n",
      "544 ...\n",
      "545 ...\n",
      "546 ...\n",
      "547 ...\n",
      "548 ...\n",
      "549 ...\n",
      "550 ...\n",
      "551 ...\n",
      "552 ...\n",
      "553 ...\n",
      "554 ...\n",
      "555 ...\n",
      "556 ...\n",
      "557 ...\n",
      "558 ...\n",
      "559 ...\n",
      "560 ...\n",
      "561 ...\n",
      "562 ...\n",
      "563 ...\n",
      "564 ...\n",
      "565 ...\n",
      "566 ...\n",
      "567 ...\n",
      "568 ...\n",
      "569 ...\n",
      "570 ...\n",
      "571 ...\n",
      "572 ...\n",
      "573 ...\n",
      "574 ...\n",
      "575 ...\n",
      "576 ...\n",
      "577 ...\n",
      "578 ...\n",
      "579 ...\n",
      "580 ...\n",
      "581 ...\n",
      "582 ...\n",
      "583 ...\n",
      "584 ...\n",
      "585 ...\n",
      "586 ...\n",
      "587 ...\n",
      "588 ...\n",
      "589 ...\n",
      "590 ...\n",
      "591 ...\n",
      "592 ...\n",
      "593 ...\n",
      "594 ...\n",
      "595 ...\n",
      "596 ...\n",
      "597 ...\n",
      "598 ...\n",
      "599 ...\n",
      "600 ...\n",
      "601 ...\n",
      "602 ...\n",
      "603 ...\n",
      "604 ...\n",
      "605 ...\n",
      "606 ...\n",
      "607 ...\n",
      "608 ...\n",
      "609 ...\n",
      "610 ...\n",
      "611 ...\n",
      "612 ...\n",
      "613 ...\n",
      "614 ...\n",
      "615 ...\n",
      "616 ...\n",
      "617 ...\n",
      "618 ...\n",
      "619 ...\n",
      "620 ...\n",
      "621 ...\n",
      "622 ...\n",
      "623 ...\n",
      "624 ...\n",
      "625 ...\n",
      "626 ...\n",
      "627 ...\n",
      "628 ...\n",
      "629 ...\n",
      "630 ...\n",
      "631 ...\n",
      "632 ...\n",
      "633 ...\n",
      "634 ...\n",
      "635 ...\n",
      "636 ...\n",
      "637 ...\n",
      "638 ...\n",
      "639 ...\n",
      "640 ...\n",
      "641 ...\n",
      "642 ...\n",
      "643 ...\n",
      "644 ...\n",
      "645 ...\n",
      "646 ...\n",
      "647 ...\n",
      "648 ...\n",
      "649 ...\n",
      "650 ...\n",
      "651 ...\n",
      "652 ...\n",
      "653 ...\n",
      "654 ...\n",
      "655 ...\n",
      "656 ...\n",
      "657 ...\n",
      "658 ...\n",
      "659 ...\n",
      "660 ...\n",
      "661 ...\n",
      "662 ...\n",
      "663 ...\n",
      "664 ...\n",
      "665 ...\n",
      "666 ...\n",
      "667 ...\n",
      "668 ...\n",
      "669 ...\n",
      "670 ...\n",
      "671 ...\n",
      "672 ...\n",
      "673 ...\n",
      "674 ...\n",
      "675 ...\n",
      "676 ...\n",
      "677 ...\n",
      "678 ...\n",
      "679 ...\n",
      "680 ...\n",
      "681 ...\n",
      "682 ...\n",
      "683 ...\n",
      "684 ...\n",
      "685 ...\n",
      "686 ...\n",
      "687 ...\n",
      "688 ...\n",
      "689 ...\n",
      "690 ...\n",
      "691 ...\n",
      "692 ...\n",
      "693 ...\n",
      "694 ...\n",
      "695 ...\n",
      "696 ...\n",
      "697 ...\n",
      "698 ...\n",
      "699 ...\n",
      "700 ...\n",
      "701 ...\n",
      "702 ...\n",
      "703 ...\n",
      "704 ...\n",
      "705 ...\n",
      "706 ...\n",
      "707 ...\n",
      "708 ...\n",
      "709 ...\n",
      "710 ...\n",
      "711 ...\n",
      "712 ...\n",
      "713 ...\n",
      "714 ...\n",
      "715 ...\n",
      "716 ...\n",
      "717 ...\n",
      "718 ...\n",
      "719 ...\n",
      "720 ...\n",
      "721 ...\n",
      "722 ...\n",
      "723 ...\n",
      "724 ...\n",
      "725 ...\n",
      "726 ...\n",
      "727 ...\n",
      "728 ...\n",
      "729 ...\n",
      "730 ...\n",
      "731 ...\n",
      "732 ...\n",
      "733 ...\n",
      "734 ...\n",
      "735 ...\n",
      "736 ...\n",
      "737 ...\n",
      "738 ...\n",
      "739 ...\n",
      "740 ...\n",
      "741 ...\n",
      "742 ...\n",
      "743 ...\n",
      "744 ...\n",
      "745 ...\n",
      "746 ...\n",
      "747 ...\n",
      "748 ...\n",
      "749 ...\n",
      "750 ...\n",
      "751 ...\n",
      "752 ...\n",
      "753 ...\n",
      "754 ...\n",
      "755 ...\n",
      "756 ...\n",
      "757 ...\n",
      "758 ...\n",
      "759 ...\n",
      "760 ...\n",
      "761 ...\n",
      "762 ...\n",
      "763 ...\n",
      "764 ...\n",
      "765 ...\n",
      "766 ...\n",
      "767 ...\n",
      "768 ...\n",
      "769 ...\n",
      "770 ...\n",
      "771 ...\n",
      "772 ...\n",
      "773 ...\n",
      "774 ...\n",
      "775 ...\n",
      "776 ...\n",
      "777 ...\n",
      "778 ...\n",
      "779 ...\n",
      "780 ...\n",
      "781 ...\n",
      "782 ...\n",
      "783 ...\n",
      "784 ...\n",
      "785 ...\n",
      "786 ...\n",
      "787 ...\n",
      "788 ...\n",
      "789 ...\n",
      "790 ...\n",
      "791 ...\n",
      "792 ...\n",
      "793 ...\n",
      "794 ...\n",
      "795 ...\n",
      "796 ...\n",
      "797 ...\n",
      "798 ...\n",
      "799 ...\n",
      "800 ...\n",
      "801 ...\n",
      "802 ...\n",
      "803 ...\n",
      "804 ...\n",
      "805 ...\n",
      "806 ...\n",
      "807 ...\n",
      "808 ...\n",
      "809 ...\n",
      "810 ...\n",
      "811 ...\n",
      "812 ...\n",
      "813 ...\n",
      "814 ...\n",
      "815 ...\n",
      "816 ...\n",
      "817 ...\n",
      "818 ...\n",
      "819 ...\n",
      "820 ...\n",
      "821 ...\n",
      "822 ...\n",
      "823 ...\n",
      "824 ...\n",
      "825 ...\n",
      "826 ...\n",
      "827 ...\n",
      "828 ...\n",
      "829 ...\n",
      "830 ...\n",
      "831 ...\n",
      "832 ...\n",
      "833 ...\n",
      "834 ...\n",
      "835 ...\n",
      "836 ...\n",
      "837 ...\n",
      "838 ...\n",
      "839 ...\n",
      "840 ...\n",
      "841 ...\n",
      "842 ...\n",
      "843 ...\n",
      "844 ...\n",
      "845 ...\n",
      "846 ...\n",
      "847 ...\n",
      "848 ...\n",
      "849 ...\n",
      "850 ...\n",
      "851 ...\n",
      "852 ...\n",
      "853 ...\n",
      "854 ...\n",
      "855 ...\n",
      "856 ...\n",
      "857 ...\n",
      "858 ...\n",
      "859 ...\n",
      "860 ...\n",
      "861 ...\n",
      "862 ...\n",
      "863 ...\n",
      "864 ...\n",
      "865 ...\n",
      "866 ...\n",
      "867 ...\n",
      "868 ...\n",
      "869 ...\n",
      "870 ...\n",
      "871 ...\n",
      "872 ...\n",
      "873 ...\n",
      "874 ...\n",
      "875 ...\n",
      "876 ...\n",
      "877 ...\n",
      "878 ...\n",
      "879 ...\n",
      "880 ...\n",
      "881 ...\n",
      "882 ...\n",
      "883 ...\n",
      "884 ...\n",
      "885 ...\n",
      "886 ...\n",
      "887 ...\n",
      "888 ...\n",
      "889 ...\n",
      "890 ...\n",
      "891 ...\n",
      "892 ...\n",
      "893 ...\n",
      "894 ...\n",
      "895 ...\n",
      "896 ...\n",
      "897 ...\n",
      "898 ...\n",
      "899 ...\n",
      "900 ...\n",
      "901 ...\n",
      "902 ...\n",
      "903 ...\n",
      "904 ...\n",
      "905 ...\n",
      "906 ...\n",
      "907 ...\n",
      "908 ...\n",
      "909 ...\n",
      "910 ...\n",
      "911 ...\n",
      "912 ...\n",
      "913 ...\n",
      "914 ...\n",
      "915 ...\n",
      "916 ...\n",
      "917 ...\n",
      "918 ...\n",
      "919 ...\n",
      "920 ...\n",
      "921 ...\n",
      "922 ...\n",
      "923 ...\n",
      "924 ...\n",
      "925 ...\n",
      "926 ...\n",
      "927 ...\n",
      "928 ...\n",
      "929 ...\n",
      "930 ...\n",
      "931 ...\n",
      "932 ...\n",
      "933 ...\n",
      "934 ...\n",
      "935 ...\n",
      "936 ...\n",
      "937 ...\n",
      "938 ...\n",
      "939 ...\n",
      "940 ...\n",
      "941 ...\n",
      "942 ...\n",
      "943 ...\n",
      "944 ...\n",
      "945 ...\n",
      "946 ...\n",
      "947 ...\n",
      "948 ...\n",
      "949 ...\n",
      "950 ...\n",
      "951 ...\n",
      "952 ...\n",
      "953 ...\n",
      "954 ...\n",
      "955 ...\n",
      "956 ...\n",
      "957 ...\n",
      "958 ...\n",
      "959 ...\n",
      "960 ...\n",
      "961 ...\n",
      "962 ...\n",
      "963 ...\n",
      "964 ...\n",
      "965 ...\n",
      "966 ...\n",
      "967 ...\n",
      "968 ...\n",
      "969 ...\n",
      "970 ...\n",
      "971 ...\n",
      "972 ...\n",
      "973 ...\n",
      "974 ...\n",
      "975 ...\n",
      "976 ...\n",
      "977 ...\n",
      "978 ...\n",
      "979 ...\n",
      "980 ...\n",
      "981 ...\n",
      "982 ...\n",
      "983 ...\n",
      "984 ...\n",
      "985 ...\n",
      "986 ...\n",
      "987 ...\n",
      "988 ...\n",
      "989 ...\n",
      "990 ...\n",
      "991 ...\n",
      "992 ...\n",
      "993 ...\n",
      "994 ...\n",
      "995 ...\n",
      "996 ...\n",
      "997 ...\n",
      "998 ...\n",
      "999 ...\n",
      "1000 ...\n",
      "1001 ...\n",
      "1002 ...\n",
      "1003 ...\n",
      "1004 ...\n",
      "1005 ...\n",
      "1006 ...\n",
      "1007 ...\n",
      "1008 ...\n",
      "1009 ...\n",
      "1010 ...\n",
      "1011 ...\n",
      "1012 ...\n",
      "1013 ...\n",
      "1014 ...\n",
      "1015 ...\n",
      "1016 ...\n",
      "1017 ...\n",
      "1018 ...\n",
      "1019 ...\n",
      "1020 ...\n",
      "1021 ...\n",
      "1022 ...\n",
      "1023 ...\n",
      "1024 ...\n",
      "1025 ...\n",
      "1026 ...\n",
      "1027 ...\n",
      "1028 ...\n",
      "1029 ...\n",
      "1030 ...\n",
      "1031 ...\n",
      "1032 ...\n",
      "1033 ...\n",
      "1034 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035 ...\n",
      "1036 ...\n",
      "1037 ...\n",
      "1038 ...\n",
      "1039 ...\n",
      "1040 ...\n",
      "1041 ...\n",
      "1042 ...\n",
      "1043 ...\n",
      "1044 ...\n",
      "1045 ...\n",
      "1046 ...\n",
      "1047 ...\n",
      "1048 ...\n",
      "1049 ...\n",
      "1050 ...\n",
      "1051 ...\n",
      "1052 ...\n",
      "1053 ...\n",
      "1054 ...\n",
      "1055 ...\n",
      "1056 ...\n",
      "1057 ...\n",
      "1058 ...\n",
      "1059 ...\n",
      "1060 ...\n",
      "1061 ...\n",
      "1062 ...\n",
      "1063 ...\n",
      "1064 ...\n",
      "1065 ...\n",
      "1066 ...\n",
      "1067 ...\n",
      "1068 ...\n",
      "1069 ...\n",
      "1070 ...\n",
      "1071 ...\n",
      "1072 ...\n",
      "1073 ...\n",
      "1074 ...\n",
      "1075 ...\n",
      "1076 ...\n",
      "1077 ...\n",
      "1078 ...\n",
      "1079 ...\n",
      "1080 ...\n",
      "1081 ...\n",
      "1082 ...\n",
      "1083 ...\n",
      "1084 ...\n",
      "1085 ...\n",
      "1086 ...\n",
      "1087 ...\n",
      "1088 ...\n",
      "1089 ...\n",
      "1090 ...\n",
      "1091 ...\n",
      "1092 ...\n",
      "1093 ...\n",
      "1094 ...\n",
      "1095 ...\n",
      "1096 ...\n",
      "1097 ...\n",
      "1098 ...\n",
      "1099 ...\n",
      "1100 ...\n",
      "1101 ...\n",
      "1102 ...\n",
      "1103 ...\n",
      "1104 ...\n",
      "1105 ...\n",
      "1106 ...\n",
      "1107 ...\n",
      "1108 ...\n",
      "1109 ...\n",
      "1110 ...\n",
      "1111 ...\n",
      "1112 ...\n",
      "1113 ...\n",
      "1114 ...\n",
      "1115 ...\n",
      "1116 ...\n",
      "1117 ...\n",
      "1118 ...\n",
      "1119 ...\n",
      "1120 ...\n",
      "1121 ...\n",
      "1122 ...\n",
      "1123 ...\n",
      "1124 ...\n",
      "1125 ...\n",
      "1126 ...\n",
      "1127 ...\n",
      "1128 ...\n",
      "1129 ...\n",
      "1130 ...\n",
      "1131 ...\n",
      "1132 ...\n",
      "1133 ...\n",
      "1134 ...\n",
      "1135 ...\n",
      "1136 ...\n",
      "1137 ...\n",
      "1138 ...\n",
      "1139 ...\n",
      "1140 ...\n",
      "1141 ...\n",
      "1142 ...\n",
      "1143 ...\n",
      "1144 ...\n",
      "1145 ...\n",
      "1146 ...\n",
      "1147 ...\n",
      "1148 ...\n",
      "1149 ...\n",
      "1150 ...\n",
      "1151 ...\n",
      "1152 ...\n",
      "1153 ...\n",
      "1154 ...\n",
      "1155 ...\n",
      "1156 ...\n",
      "1157 ...\n",
      "1158 ...\n",
      "1159 ...\n",
      "1160 ...\n",
      "1161 ...\n",
      "1162 ...\n",
      "1163 ...\n",
      "1164 ...\n",
      "1165 ...\n",
      "1166 ...\n",
      "1167 ...\n",
      "1168 ...\n",
      "1169 ...\n",
      "1170 ...\n",
      "1171 ...\n",
      "1172 ...\n",
      "1173 ...\n",
      "1174 ...\n",
      "1175 ...\n",
      "1176 ...\n",
      "1177 ...\n",
      "1178 ...\n",
      "1179 ...\n",
      "1180 ...\n",
      "1181 ...\n",
      "1182 ...\n",
      "1183 ...\n",
      "1184 ...\n",
      "1185 ...\n",
      "1186 ...\n",
      "1187 ...\n",
      "1188 ...\n",
      "1189 ...\n",
      "1190 ...\n",
      "1191 ...\n",
      "1192 ...\n",
      "1193 ...\n",
      "1194 ...\n",
      "1195 ...\n",
      "1196 ...\n",
      "1197 ...\n",
      "1198 ...\n",
      "1199 ...\n",
      "1200 ...\n"
     ]
    }
   ],
   "source": [
    "DATA_train_s = []\n",
    "DATA_train_n = []\n",
    "DATA_train_x = []\n",
    "DATA_train_x_cmplx = []\n",
    "\n",
    "with open(TRAIN_S,'wb') as fs, open(TRAIN_N,'wb') as fn, open(TRAIN_X_cmplx,'wb') as fx_cmplx, open(TRAIN_X,'wb') as fx: \n",
    "    count = 1\n",
    "    for file_s, file_n, file_x in zip(sorted(glob.glob(PATH_directory+PATH_train+CLEAN_format_train)),sorted(glob.glob(PATH_directory+PATH_train+NOISE_format_train)),sorted(glob.glob(PATH_directory+PATH_train+MIX_format_train))):\n",
    "        _,s = preprossed_data(file_s)\n",
    "        DATA_train_s.append(np.array(s))\n",
    "        np.savetxt(fs, s, fmt='%.5f')\n",
    "        fs.write(b'\\n')\n",
    "        \n",
    "        _,n = preprossed_data(file_n)\n",
    "        DATA_train_n.append(np.array(n))\n",
    "        np.savetxt(fn, n, fmt='%.5f')\n",
    "        fn.write(b'\\n')\n",
    "        \n",
    "        x_cmplx,x = preprossed_data(file_x)\n",
    "        DATA_train_x.append(np.array(x))\n",
    "        np.savetxt(fx, x, fmt='%.5f')\n",
    "        fx.write(b'\\n')\n",
    "        \n",
    "        DATA_train_x_cmplx.append(np.array(x_cmplx))\n",
    "        np.savetxt(fx_cmplx, x_cmplx, fmt='%.5f')\n",
    "        fx_cmplx.write(b'\\n')\n",
    "        \n",
    "        print(count, '...')\n",
    "        count += 1\n",
    "        \n",
    "fs.close()\n",
    "fn.close()\n",
    "fx_cmplx.close()\n",
    "fx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Validate Data\n",
    "\n",
    "Here we open the files, and read the Validation Dataset. To evaluate SNR of validation data, we need to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ...\n",
      "2 ...\n",
      "3 ...\n",
      "4 ...\n",
      "5 ...\n",
      "6 ...\n",
      "7 ...\n",
      "8 ...\n",
      "9 ...\n",
      "10 ...\n",
      "11 ...\n",
      "12 ...\n",
      "13 ...\n",
      "14 ...\n",
      "15 ...\n",
      "16 ...\n",
      "17 ...\n",
      "18 ...\n",
      "19 ...\n",
      "20 ...\n",
      "21 ...\n",
      "22 ...\n",
      "23 ...\n",
      "24 ...\n",
      "25 ...\n",
      "26 ...\n",
      "27 ...\n",
      "28 ...\n",
      "29 ...\n",
      "30 ...\n",
      "31 ...\n",
      "32 ...\n",
      "33 ...\n",
      "34 ...\n",
      "35 ...\n",
      "36 ...\n",
      "37 ...\n",
      "38 ...\n",
      "39 ...\n",
      "40 ...\n",
      "41 ...\n",
      "42 ...\n",
      "43 ...\n",
      "44 ...\n",
      "45 ...\n",
      "46 ...\n",
      "47 ...\n",
      "48 ...\n",
      "49 ...\n",
      "50 ...\n",
      "51 ...\n",
      "52 ...\n",
      "53 ...\n",
      "54 ...\n",
      "55 ...\n",
      "56 ...\n",
      "57 ...\n",
      "58 ...\n",
      "59 ...\n",
      "60 ...\n",
      "61 ...\n",
      "62 ...\n",
      "63 ...\n",
      "64 ...\n",
      "65 ...\n",
      "66 ...\n",
      "67 ...\n",
      "68 ...\n",
      "69 ...\n",
      "70 ...\n",
      "71 ...\n",
      "72 ...\n",
      "73 ...\n",
      "74 ...\n",
      "75 ...\n",
      "76 ...\n",
      "77 ...\n",
      "78 ...\n",
      "79 ...\n",
      "80 ...\n",
      "81 ...\n",
      "82 ...\n",
      "83 ...\n",
      "84 ...\n",
      "85 ...\n",
      "86 ...\n",
      "87 ...\n",
      "88 ...\n",
      "89 ...\n",
      "90 ...\n",
      "91 ...\n",
      "92 ...\n",
      "93 ...\n",
      "94 ...\n",
      "95 ...\n",
      "96 ...\n",
      "97 ...\n",
      "98 ...\n",
      "99 ...\n",
      "100 ...\n",
      "101 ...\n",
      "102 ...\n",
      "103 ...\n",
      "104 ...\n",
      "105 ...\n",
      "106 ...\n",
      "107 ...\n",
      "108 ...\n",
      "109 ...\n",
      "110 ...\n",
      "111 ...\n",
      "112 ...\n",
      "113 ...\n",
      "114 ...\n",
      "115 ...\n",
      "116 ...\n",
      "117 ...\n",
      "118 ...\n",
      "119 ...\n",
      "120 ...\n",
      "121 ...\n",
      "122 ...\n",
      "123 ...\n",
      "124 ...\n",
      "125 ...\n",
      "126 ...\n",
      "127 ...\n",
      "128 ...\n",
      "129 ...\n",
      "130 ...\n",
      "131 ...\n",
      "132 ...\n",
      "133 ...\n",
      "134 ...\n",
      "135 ...\n",
      "136 ...\n",
      "137 ...\n",
      "138 ...\n",
      "139 ...\n",
      "140 ...\n",
      "141 ...\n",
      "142 ...\n",
      "143 ...\n",
      "144 ...\n",
      "145 ...\n",
      "146 ...\n",
      "147 ...\n",
      "148 ...\n",
      "149 ...\n",
      "150 ...\n",
      "151 ...\n",
      "152 ...\n",
      "153 ...\n",
      "154 ...\n",
      "155 ...\n",
      "156 ...\n",
      "157 ...\n",
      "158 ...\n",
      "159 ...\n",
      "160 ...\n",
      "161 ...\n",
      "162 ...\n",
      "163 ...\n",
      "164 ...\n",
      "165 ...\n",
      "166 ...\n",
      "167 ...\n",
      "168 ...\n",
      "169 ...\n",
      "170 ...\n",
      "171 ...\n",
      "172 ...\n",
      "173 ...\n",
      "174 ...\n",
      "175 ...\n",
      "176 ...\n",
      "177 ...\n",
      "178 ...\n",
      "179 ...\n",
      "180 ...\n",
      "181 ...\n",
      "182 ...\n",
      "183 ...\n",
      "184 ...\n",
      "185 ...\n",
      "186 ...\n",
      "187 ...\n",
      "188 ...\n",
      "189 ...\n",
      "190 ...\n",
      "191 ...\n",
      "192 ...\n",
      "193 ...\n",
      "194 ...\n",
      "195 ...\n",
      "196 ...\n",
      "197 ...\n",
      "198 ...\n",
      "199 ...\n",
      "200 ...\n",
      "201 ...\n",
      "202 ...\n",
      "203 ...\n",
      "204 ...\n",
      "205 ...\n",
      "206 ...\n",
      "207 ...\n",
      "208 ...\n",
      "209 ...\n",
      "210 ...\n",
      "211 ...\n",
      "212 ...\n",
      "213 ...\n",
      "214 ...\n",
      "215 ...\n",
      "216 ...\n",
      "217 ...\n",
      "218 ...\n",
      "219 ...\n",
      "220 ...\n",
      "221 ...\n",
      "222 ...\n",
      "223 ...\n",
      "224 ...\n",
      "225 ...\n",
      "226 ...\n",
      "227 ...\n",
      "228 ...\n",
      "229 ...\n",
      "230 ...\n",
      "231 ...\n",
      "232 ...\n",
      "233 ...\n",
      "234 ...\n",
      "235 ...\n",
      "236 ...\n",
      "237 ...\n",
      "238 ...\n",
      "239 ...\n",
      "240 ...\n",
      "241 ...\n",
      "242 ...\n",
      "243 ...\n",
      "244 ...\n",
      "245 ...\n",
      "246 ...\n",
      "247 ...\n",
      "248 ...\n",
      "249 ...\n",
      "250 ...\n",
      "251 ...\n",
      "252 ...\n",
      "253 ...\n",
      "254 ...\n",
      "255 ...\n",
      "256 ...\n",
      "257 ...\n",
      "258 ...\n",
      "259 ...\n",
      "260 ...\n",
      "261 ...\n",
      "262 ...\n",
      "263 ...\n",
      "264 ...\n",
      "265 ...\n",
      "266 ...\n",
      "267 ...\n",
      "268 ...\n",
      "269 ...\n",
      "270 ...\n",
      "271 ...\n",
      "272 ...\n",
      "273 ...\n",
      "274 ...\n",
      "275 ...\n",
      "276 ...\n",
      "277 ...\n",
      "278 ...\n",
      "279 ...\n",
      "280 ...\n",
      "281 ...\n",
      "282 ...\n",
      "283 ...\n",
      "284 ...\n",
      "285 ...\n",
      "286 ...\n",
      "287 ...\n",
      "288 ...\n",
      "289 ...\n",
      "290 ...\n",
      "291 ...\n",
      "292 ...\n",
      "293 ...\n",
      "294 ...\n",
      "295 ...\n",
      "296 ...\n",
      "297 ...\n",
      "298 ...\n",
      "299 ...\n",
      "300 ...\n",
      "301 ...\n",
      "302 ...\n",
      "303 ...\n",
      "304 ...\n",
      "305 ...\n",
      "306 ...\n",
      "307 ...\n",
      "308 ...\n",
      "309 ...\n",
      "310 ...\n",
      "311 ...\n",
      "312 ...\n",
      "313 ...\n",
      "314 ...\n",
      "315 ...\n",
      "316 ...\n",
      "317 ...\n",
      "318 ...\n",
      "319 ...\n",
      "320 ...\n",
      "321 ...\n",
      "322 ...\n",
      "323 ...\n",
      "324 ...\n",
      "325 ...\n",
      "326 ...\n",
      "327 ...\n",
      "328 ...\n",
      "329 ...\n",
      "330 ...\n",
      "331 ...\n",
      "332 ...\n",
      "333 ...\n",
      "334 ...\n",
      "335 ...\n",
      "336 ...\n",
      "337 ...\n",
      "338 ...\n",
      "339 ...\n",
      "340 ...\n",
      "341 ...\n",
      "342 ...\n",
      "343 ...\n",
      "344 ...\n",
      "345 ...\n",
      "346 ...\n",
      "347 ...\n",
      "348 ...\n",
      "349 ...\n",
      "350 ...\n",
      "351 ...\n",
      "352 ...\n",
      "353 ...\n",
      "354 ...\n",
      "355 ...\n",
      "356 ...\n",
      "357 ...\n",
      "358 ...\n",
      "359 ...\n",
      "360 ...\n",
      "361 ...\n",
      "362 ...\n",
      "363 ...\n",
      "364 ...\n",
      "365 ...\n",
      "366 ...\n",
      "367 ...\n",
      "368 ...\n",
      "369 ...\n",
      "370 ...\n",
      "371 ...\n",
      "372 ...\n",
      "373 ...\n",
      "374 ...\n",
      "375 ...\n",
      "376 ...\n",
      "377 ...\n",
      "378 ...\n",
      "379 ...\n",
      "380 ...\n",
      "381 ...\n",
      "382 ...\n",
      "383 ...\n",
      "384 ...\n",
      "385 ...\n",
      "386 ...\n",
      "387 ...\n",
      "388 ...\n",
      "389 ...\n",
      "390 ...\n",
      "391 ...\n",
      "392 ...\n",
      "393 ...\n",
      "394 ...\n",
      "395 ...\n",
      "396 ...\n",
      "397 ...\n",
      "398 ...\n",
      "399 ...\n",
      "400 ...\n",
      "401 ...\n",
      "402 ...\n",
      "403 ...\n",
      "404 ...\n",
      "405 ...\n",
      "406 ...\n",
      "407 ...\n",
      "408 ...\n",
      "409 ...\n",
      "410 ...\n",
      "411 ...\n",
      "412 ...\n",
      "413 ...\n",
      "414 ...\n",
      "415 ...\n",
      "416 ...\n",
      "417 ...\n",
      "418 ...\n",
      "419 ...\n",
      "420 ...\n",
      "421 ...\n",
      "422 ...\n",
      "423 ...\n",
      "424 ...\n",
      "425 ...\n",
      "426 ...\n",
      "427 ...\n",
      "428 ...\n",
      "429 ...\n",
      "430 ...\n",
      "431 ...\n",
      "432 ...\n",
      "433 ...\n",
      "434 ...\n",
      "435 ...\n",
      "436 ...\n",
      "437 ...\n",
      "438 ...\n",
      "439 ...\n",
      "440 ...\n",
      "441 ...\n",
      "442 ...\n",
      "443 ...\n",
      "444 ...\n",
      "445 ...\n",
      "446 ...\n",
      "447 ...\n",
      "448 ...\n",
      "449 ...\n",
      "450 ...\n",
      "451 ...\n",
      "452 ...\n",
      "453 ...\n",
      "454 ...\n",
      "455 ...\n",
      "456 ...\n",
      "457 ...\n",
      "458 ...\n",
      "459 ...\n",
      "460 ...\n",
      "461 ...\n",
      "462 ...\n",
      "463 ...\n",
      "464 ...\n",
      "465 ...\n",
      "466 ...\n",
      "467 ...\n",
      "468 ...\n",
      "469 ...\n",
      "470 ...\n",
      "471 ...\n",
      "472 ...\n",
      "473 ...\n",
      "474 ...\n",
      "475 ...\n",
      "476 ...\n",
      "477 ...\n",
      "478 ...\n",
      "479 ...\n",
      "480 ...\n",
      "481 ...\n",
      "482 ...\n",
      "483 ...\n",
      "484 ...\n",
      "485 ...\n",
      "486 ...\n",
      "487 ...\n",
      "488 ...\n",
      "489 ...\n",
      "490 ...\n",
      "491 ...\n",
      "492 ...\n",
      "493 ...\n",
      "494 ...\n",
      "495 ...\n",
      "496 ...\n",
      "497 ...\n",
      "498 ...\n",
      "499 ...\n",
      "500 ...\n",
      "501 ...\n",
      "502 ...\n",
      "503 ...\n",
      "504 ...\n",
      "505 ...\n",
      "506 ...\n",
      "507 ...\n",
      "508 ...\n",
      "509 ...\n",
      "510 ...\n",
      "511 ...\n",
      "512 ...\n",
      "513 ...\n",
      "514 ...\n",
      "515 ...\n",
      "516 ...\n",
      "517 ...\n",
      "518 ...\n",
      "519 ...\n",
      "520 ...\n",
      "521 ...\n",
      "522 ...\n",
      "523 ...\n",
      "524 ...\n",
      "525 ...\n",
      "526 ...\n",
      "527 ...\n",
      "528 ...\n",
      "529 ...\n",
      "530 ...\n",
      "531 ...\n",
      "532 ...\n",
      "533 ...\n",
      "534 ...\n",
      "535 ...\n",
      "536 ...\n",
      "537 ...\n",
      "538 ...\n",
      "539 ...\n",
      "540 ...\n",
      "541 ...\n",
      "542 ...\n",
      "543 ...\n",
      "544 ...\n",
      "545 ...\n",
      "546 ...\n",
      "547 ...\n",
      "548 ...\n",
      "549 ...\n",
      "550 ...\n",
      "551 ...\n",
      "552 ...\n",
      "553 ...\n",
      "554 ...\n",
      "555 ...\n",
      "556 ...\n",
      "557 ...\n",
      "558 ...\n",
      "559 ...\n",
      "560 ...\n",
      "561 ...\n",
      "562 ...\n",
      "563 ...\n",
      "564 ...\n",
      "565 ...\n",
      "566 ...\n",
      "567 ...\n",
      "568 ...\n",
      "569 ...\n",
      "570 ...\n",
      "571 ...\n",
      "572 ...\n",
      "573 ...\n",
      "574 ...\n",
      "575 ...\n",
      "576 ...\n",
      "577 ...\n",
      "578 ...\n",
      "579 ...\n",
      "580 ...\n",
      "581 ...\n",
      "582 ...\n",
      "583 ...\n",
      "584 ...\n",
      "585 ...\n",
      "586 ...\n",
      "587 ...\n",
      "588 ...\n",
      "589 ...\n",
      "590 ...\n",
      "591 ...\n",
      "592 ...\n",
      "593 ...\n",
      "594 ...\n",
      "595 ...\n",
      "596 ...\n",
      "597 ...\n",
      "598 ...\n",
      "599 ...\n",
      "600 ...\n",
      "601 ...\n",
      "602 ...\n",
      "603 ...\n",
      "604 ...\n",
      "605 ...\n",
      "606 ...\n",
      "607 ...\n",
      "608 ...\n",
      "609 ...\n",
      "610 ...\n",
      "611 ...\n",
      "612 ...\n",
      "613 ...\n",
      "614 ...\n",
      "615 ...\n",
      "616 ...\n",
      "617 ...\n",
      "618 ...\n",
      "619 ...\n",
      "620 ...\n",
      "621 ...\n",
      "622 ...\n",
      "623 ...\n",
      "624 ...\n",
      "625 ...\n",
      "626 ...\n",
      "627 ...\n",
      "628 ...\n",
      "629 ...\n",
      "630 ...\n",
      "631 ...\n",
      "632 ...\n",
      "633 ...\n",
      "634 ...\n",
      "635 ...\n",
      "636 ...\n",
      "637 ...\n",
      "638 ...\n",
      "639 ...\n",
      "640 ...\n",
      "641 ...\n",
      "642 ...\n",
      "643 ...\n",
      "644 ...\n",
      "645 ...\n",
      "646 ...\n",
      "647 ...\n",
      "648 ...\n",
      "649 ...\n",
      "650 ...\n",
      "651 ...\n",
      "652 ...\n",
      "653 ...\n",
      "654 ...\n",
      "655 ...\n",
      "656 ...\n",
      "657 ...\n",
      "658 ...\n",
      "659 ...\n",
      "660 ...\n",
      "661 ...\n",
      "662 ...\n",
      "663 ...\n",
      "664 ...\n",
      "665 ...\n",
      "666 ...\n",
      "667 ...\n",
      "668 ...\n",
      "669 ...\n",
      "670 ...\n",
      "671 ...\n",
      "672 ...\n",
      "673 ...\n",
      "674 ...\n",
      "675 ...\n",
      "676 ...\n",
      "677 ...\n",
      "678 ...\n",
      "679 ...\n",
      "680 ...\n",
      "681 ...\n",
      "682 ...\n",
      "683 ...\n",
      "684 ...\n",
      "685 ...\n",
      "686 ...\n",
      "687 ...\n",
      "688 ...\n",
      "689 ...\n",
      "690 ...\n",
      "691 ...\n",
      "692 ...\n",
      "693 ...\n",
      "694 ...\n",
      "695 ...\n",
      "696 ...\n",
      "697 ...\n",
      "698 ...\n",
      "699 ...\n",
      "700 ...\n",
      "701 ...\n",
      "702 ...\n",
      "703 ...\n",
      "704 ...\n",
      "705 ...\n",
      "706 ...\n",
      "707 ...\n",
      "708 ...\n",
      "709 ...\n",
      "710 ...\n",
      "711 ...\n",
      "712 ...\n",
      "713 ...\n",
      "714 ...\n",
      "715 ...\n",
      "716 ...\n",
      "717 ...\n",
      "718 ...\n",
      "719 ...\n",
      "720 ...\n",
      "721 ...\n",
      "722 ...\n",
      "723 ...\n",
      "724 ...\n",
      "725 ...\n",
      "726 ...\n",
      "727 ...\n",
      "728 ...\n",
      "729 ...\n",
      "730 ...\n",
      "731 ...\n",
      "732 ...\n",
      "733 ...\n",
      "734 ...\n",
      "735 ...\n",
      "736 ...\n",
      "737 ...\n",
      "738 ...\n",
      "739 ...\n",
      "740 ...\n",
      "741 ...\n",
      "742 ...\n",
      "743 ...\n",
      "744 ...\n",
      "745 ...\n",
      "746 ...\n",
      "747 ...\n",
      "748 ...\n",
      "749 ...\n",
      "750 ...\n",
      "751 ...\n",
      "752 ...\n",
      "753 ...\n",
      "754 ...\n",
      "755 ...\n",
      "756 ...\n",
      "757 ...\n",
      "758 ...\n",
      "759 ...\n",
      "760 ...\n",
      "761 ...\n",
      "762 ...\n",
      "763 ...\n",
      "764 ...\n",
      "765 ...\n",
      "766 ...\n",
      "767 ...\n",
      "768 ...\n",
      "769 ...\n",
      "770 ...\n",
      "771 ...\n",
      "772 ...\n",
      "773 ...\n",
      "774 ...\n",
      "775 ...\n",
      "776 ...\n",
      "777 ...\n",
      "778 ...\n",
      "779 ...\n",
      "780 ...\n",
      "781 ...\n",
      "782 ...\n",
      "783 ...\n",
      "784 ...\n",
      "785 ...\n",
      "786 ...\n",
      "787 ...\n",
      "788 ...\n",
      "789 ...\n",
      "790 ...\n",
      "791 ...\n",
      "792 ...\n",
      "793 ...\n",
      "794 ...\n",
      "795 ...\n",
      "796 ...\n",
      "797 ...\n",
      "798 ...\n",
      "799 ...\n",
      "800 ...\n",
      "801 ...\n",
      "802 ...\n",
      "803 ...\n",
      "804 ...\n",
      "805 ...\n",
      "806 ...\n",
      "807 ...\n",
      "808 ...\n",
      "809 ...\n",
      "810 ...\n",
      "811 ...\n",
      "812 ...\n",
      "813 ...\n",
      "814 ...\n",
      "815 ...\n",
      "816 ...\n",
      "817 ...\n",
      "818 ...\n",
      "819 ...\n",
      "820 ...\n",
      "821 ...\n",
      "822 ...\n",
      "823 ...\n",
      "824 ...\n",
      "825 ...\n",
      "826 ...\n",
      "827 ...\n",
      "828 ...\n",
      "829 ...\n",
      "830 ...\n",
      "831 ...\n",
      "832 ...\n",
      "833 ...\n",
      "834 ...\n",
      "835 ...\n",
      "836 ...\n",
      "837 ...\n",
      "838 ...\n",
      "839 ...\n",
      "840 ...\n",
      "841 ...\n",
      "842 ...\n",
      "843 ...\n",
      "844 ...\n",
      "845 ...\n",
      "846 ...\n",
      "847 ...\n",
      "848 ...\n",
      "849 ...\n",
      "850 ...\n",
      "851 ...\n",
      "852 ...\n",
      "853 ...\n",
      "854 ...\n",
      "855 ...\n",
      "856 ...\n",
      "857 ...\n",
      "858 ...\n",
      "859 ...\n",
      "860 ...\n",
      "861 ...\n",
      "862 ...\n",
      "863 ...\n",
      "864 ...\n",
      "865 ...\n",
      "866 ...\n",
      "867 ...\n",
      "868 ...\n",
      "869 ...\n",
      "870 ...\n",
      "871 ...\n",
      "872 ...\n",
      "873 ...\n",
      "874 ...\n",
      "875 ...\n",
      "876 ...\n",
      "877 ...\n",
      "878 ...\n",
      "879 ...\n",
      "880 ...\n",
      "881 ...\n",
      "882 ...\n",
      "883 ...\n",
      "884 ...\n",
      "885 ...\n",
      "886 ...\n",
      "887 ...\n",
      "888 ...\n",
      "889 ...\n",
      "890 ...\n",
      "891 ...\n",
      "892 ...\n",
      "893 ...\n",
      "894 ...\n",
      "895 ...\n",
      "896 ...\n",
      "897 ...\n",
      "898 ...\n",
      "899 ...\n",
      "900 ...\n",
      "901 ...\n",
      "902 ...\n",
      "903 ...\n",
      "904 ...\n",
      "905 ...\n",
      "906 ...\n",
      "907 ...\n",
      "908 ...\n",
      "909 ...\n",
      "910 ...\n",
      "911 ...\n",
      "912 ...\n",
      "913 ...\n",
      "914 ...\n",
      "915 ...\n",
      "916 ...\n",
      "917 ...\n",
      "918 ...\n",
      "919 ...\n",
      "920 ...\n",
      "921 ...\n",
      "922 ...\n",
      "923 ...\n",
      "924 ...\n",
      "925 ...\n",
      "926 ...\n",
      "927 ...\n",
      "928 ...\n",
      "929 ...\n",
      "930 ...\n",
      "931 ...\n",
      "932 ...\n",
      "933 ...\n",
      "934 ...\n",
      "935 ...\n",
      "936 ...\n",
      "937 ...\n",
      "938 ...\n",
      "939 ...\n",
      "940 ...\n",
      "941 ...\n",
      "942 ...\n",
      "943 ...\n",
      "944 ...\n",
      "945 ...\n",
      "946 ...\n",
      "947 ...\n",
      "948 ...\n",
      "949 ...\n",
      "950 ...\n",
      "951 ...\n",
      "952 ...\n",
      "953 ...\n",
      "954 ...\n",
      "955 ...\n",
      "956 ...\n",
      "957 ...\n",
      "958 ...\n",
      "959 ...\n",
      "960 ...\n",
      "961 ...\n",
      "962 ...\n",
      "963 ...\n",
      "964 ...\n",
      "965 ...\n",
      "966 ...\n",
      "967 ...\n",
      "968 ...\n",
      "969 ...\n",
      "970 ...\n",
      "971 ...\n",
      "972 ...\n",
      "973 ...\n",
      "974 ...\n",
      "975 ...\n",
      "976 ...\n",
      "977 ...\n",
      "978 ...\n",
      "979 ...\n",
      "980 ...\n",
      "981 ...\n",
      "982 ...\n",
      "983 ...\n",
      "984 ...\n",
      "985 ...\n",
      "986 ...\n",
      "987 ...\n",
      "988 ...\n",
      "989 ...\n",
      "990 ...\n",
      "991 ...\n",
      "992 ...\n",
      "993 ...\n",
      "994 ...\n",
      "995 ...\n",
      "996 ...\n",
      "997 ...\n",
      "998 ...\n",
      "999 ...\n",
      "1000 ...\n",
      "1001 ...\n",
      "1002 ...\n",
      "1003 ...\n",
      "1004 ...\n",
      "1005 ...\n",
      "1006 ...\n",
      "1007 ...\n",
      "1008 ...\n",
      "1009 ...\n",
      "1010 ...\n",
      "1011 ...\n",
      "1012 ...\n",
      "1013 ...\n",
      "1014 ...\n",
      "1015 ...\n",
      "1016 ...\n",
      "1017 ...\n",
      "1018 ...\n",
      "1019 ...\n",
      "1020 ...\n",
      "1021 ...\n",
      "1022 ...\n",
      "1023 ...\n",
      "1024 ...\n",
      "1025 ...\n",
      "1026 ...\n",
      "1027 ...\n",
      "1028 ...\n",
      "1029 ...\n",
      "1030 ...\n",
      "1031 ...\n",
      "1032 ...\n",
      "1033 ...\n",
      "1034 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035 ...\n",
      "1036 ...\n",
      "1037 ...\n",
      "1038 ...\n",
      "1039 ...\n",
      "1040 ...\n",
      "1041 ...\n",
      "1042 ...\n",
      "1043 ...\n",
      "1044 ...\n",
      "1045 ...\n",
      "1046 ...\n",
      "1047 ...\n",
      "1048 ...\n",
      "1049 ...\n",
      "1050 ...\n",
      "1051 ...\n",
      "1052 ...\n",
      "1053 ...\n",
      "1054 ...\n",
      "1055 ...\n",
      "1056 ...\n",
      "1057 ...\n",
      "1058 ...\n",
      "1059 ...\n",
      "1060 ...\n",
      "1061 ...\n",
      "1062 ...\n",
      "1063 ...\n",
      "1064 ...\n",
      "1065 ...\n",
      "1066 ...\n",
      "1067 ...\n",
      "1068 ...\n",
      "1069 ...\n",
      "1070 ...\n",
      "1071 ...\n",
      "1072 ...\n",
      "1073 ...\n",
      "1074 ...\n",
      "1075 ...\n",
      "1076 ...\n",
      "1077 ...\n",
      "1078 ...\n",
      "1079 ...\n",
      "1080 ...\n",
      "1081 ...\n",
      "1082 ...\n",
      "1083 ...\n",
      "1084 ...\n",
      "1085 ...\n",
      "1086 ...\n",
      "1087 ...\n",
      "1088 ...\n",
      "1089 ...\n",
      "1090 ...\n",
      "1091 ...\n",
      "1092 ...\n",
      "1093 ...\n",
      "1094 ...\n",
      "1095 ...\n",
      "1096 ...\n",
      "1097 ...\n",
      "1098 ...\n",
      "1099 ...\n",
      "1100 ...\n",
      "1101 ...\n",
      "1102 ...\n",
      "1103 ...\n",
      "1104 ...\n",
      "1105 ...\n",
      "1106 ...\n",
      "1107 ...\n",
      "1108 ...\n",
      "1109 ...\n",
      "1110 ...\n",
      "1111 ...\n",
      "1112 ...\n",
      "1113 ...\n",
      "1114 ...\n",
      "1115 ...\n",
      "1116 ...\n",
      "1117 ...\n",
      "1118 ...\n",
      "1119 ...\n",
      "1120 ...\n",
      "1121 ...\n",
      "1122 ...\n",
      "1123 ...\n",
      "1124 ...\n",
      "1125 ...\n",
      "1126 ...\n",
      "1127 ...\n",
      "1128 ...\n",
      "1129 ...\n",
      "1130 ...\n",
      "1131 ...\n",
      "1132 ...\n",
      "1133 ...\n",
      "1134 ...\n",
      "1135 ...\n",
      "1136 ...\n",
      "1137 ...\n",
      "1138 ...\n",
      "1139 ...\n",
      "1140 ...\n",
      "1141 ...\n",
      "1142 ...\n",
      "1143 ...\n",
      "1144 ...\n",
      "1145 ...\n",
      "1146 ...\n",
      "1147 ...\n",
      "1148 ...\n",
      "1149 ...\n",
      "1150 ...\n",
      "1151 ...\n",
      "1152 ...\n",
      "1153 ...\n",
      "1154 ...\n",
      "1155 ...\n",
      "1156 ...\n",
      "1157 ...\n",
      "1158 ...\n",
      "1159 ...\n",
      "1160 ...\n",
      "1161 ...\n",
      "1162 ...\n",
      "1163 ...\n",
      "1164 ...\n",
      "1165 ...\n",
      "1166 ...\n",
      "1167 ...\n",
      "1168 ...\n",
      "1169 ...\n",
      "1170 ...\n",
      "1171 ...\n",
      "1172 ...\n",
      "1173 ...\n",
      "1174 ...\n",
      "1175 ...\n",
      "1176 ...\n",
      "1177 ...\n",
      "1178 ...\n",
      "1179 ...\n",
      "1180 ...\n",
      "1181 ...\n",
      "1182 ...\n",
      "1183 ...\n",
      "1184 ...\n",
      "1185 ...\n",
      "1186 ...\n",
      "1187 ...\n",
      "1188 ...\n",
      "1189 ...\n",
      "1190 ...\n",
      "1191 ...\n",
      "1192 ...\n",
      "1193 ...\n",
      "1194 ...\n",
      "1195 ...\n",
      "1196 ...\n",
      "1197 ...\n",
      "1198 ...\n",
      "1199 ...\n",
      "1200 ...\n"
     ]
    }
   ],
   "source": [
    "DATA_val_s = []\n",
    "DATA_val_s_cmplx = []\n",
    "DATA_val_n = []\n",
    "DATA_val_x_cmplx = []\n",
    "DATA_val_x = []\n",
    "\n",
    "with open(VAL_S,'wb') as fs, open(VAL_N,'wb') as fn, open(VAL_X_cmplx,'wb') as fx_cmplx, open(VAL_X,'wb') as fx, open(VAL_S_cmplx,'wb') as fs_cmplx: \n",
    "    count = 1\n",
    "    for file_s, file_n, file_x in zip(sorted(glob.glob(PATH_directory+PATH_val+CLEAN_format_val)),sorted(glob.glob(PATH_directory+PATH_val+NOISE_format_val)),sorted(glob.glob(PATH_directory+PATH_val+MIX_format_val))):\n",
    "        s_cmplx,s = preprossed_data(file_s)\n",
    "        DATA_val_s.append(np.array(s))\n",
    "        np.savetxt(fs, s, fmt='%.5f')\n",
    "        fs.write(b'\\n')\n",
    "        \n",
    "        DATA_val_s_cmplx.append(np.array(s_cmplx))\n",
    "        np.savetxt(fs_cmplx, s_cmplx, fmt='%.5f')\n",
    "        fs_cmplx.write(b'\\n')\n",
    "        \n",
    "        _,n = preprossed_data(file_n)\n",
    "        DATA_val_n.append(np.array(n))\n",
    "        np.savetxt(fn, n, fmt='%.5f')\n",
    "        fn.write(b'\\n')\n",
    "        \n",
    "        x_cmplx,x = preprossed_data(file_x)\n",
    "        DATA_val_x.append(np.array(x))\n",
    "        np.savetxt(fx, x, fmt='%.5f')\n",
    "        fx.write(b'\\n')\n",
    "        \n",
    "        DATA_val_x_cmplx.append(np.array(x_cmplx))\n",
    "        np.savetxt(fx_cmplx, x_cmplx, fmt='%.5f')\n",
    "        fx_cmplx.write(b'\\n')\n",
    "        \n",
    "        print(count, '...')\n",
    "        count += 1\n",
    "        \n",
    "fs.close()\n",
    "fs_cmplx.close()\n",
    "fn.close()\n",
    "fx_cmplx.close()\n",
    "fx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Test Data\n",
    "\n",
    "Here we open the files, and read the Test Dataset. To construct Test output files, we need to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ...\n",
      "2 ...\n",
      "3 ...\n",
      "4 ...\n",
      "5 ...\n",
      "6 ...\n",
      "7 ...\n",
      "8 ...\n",
      "9 ...\n",
      "10 ...\n",
      "11 ...\n",
      "12 ...\n",
      "13 ...\n",
      "14 ...\n",
      "15 ...\n",
      "16 ...\n",
      "17 ...\n",
      "18 ...\n",
      "19 ...\n",
      "20 ...\n",
      "21 ...\n",
      "22 ...\n",
      "23 ...\n",
      "24 ...\n",
      "25 ...\n",
      "26 ...\n",
      "27 ...\n",
      "28 ...\n",
      "29 ...\n",
      "30 ...\n",
      "31 ...\n",
      "32 ...\n",
      "33 ...\n",
      "34 ...\n",
      "35 ...\n",
      "36 ...\n",
      "37 ...\n",
      "38 ...\n",
      "39 ...\n",
      "40 ...\n",
      "41 ...\n",
      "42 ...\n",
      "43 ...\n",
      "44 ...\n",
      "45 ...\n",
      "46 ...\n",
      "47 ...\n",
      "48 ...\n",
      "49 ...\n",
      "50 ...\n",
      "51 ...\n",
      "52 ...\n",
      "53 ...\n",
      "54 ...\n",
      "55 ...\n",
      "56 ...\n",
      "57 ...\n",
      "58 ...\n",
      "59 ...\n",
      "60 ...\n",
      "61 ...\n",
      "62 ...\n",
      "63 ...\n",
      "64 ...\n",
      "65 ...\n",
      "66 ...\n",
      "67 ...\n",
      "68 ...\n",
      "69 ...\n",
      "70 ...\n",
      "71 ...\n",
      "72 ...\n",
      "73 ...\n",
      "74 ...\n",
      "75 ...\n",
      "76 ...\n",
      "77 ...\n",
      "78 ...\n",
      "79 ...\n",
      "80 ...\n",
      "81 ...\n",
      "82 ...\n",
      "83 ...\n",
      "84 ...\n",
      "85 ...\n",
      "86 ...\n",
      "87 ...\n",
      "88 ...\n",
      "89 ...\n",
      "90 ...\n",
      "91 ...\n",
      "92 ...\n",
      "93 ...\n",
      "94 ...\n",
      "95 ...\n",
      "96 ...\n",
      "97 ...\n",
      "98 ...\n",
      "99 ...\n",
      "100 ...\n",
      "101 ...\n",
      "102 ...\n",
      "103 ...\n",
      "104 ...\n",
      "105 ...\n",
      "106 ...\n",
      "107 ...\n",
      "108 ...\n",
      "109 ...\n",
      "110 ...\n",
      "111 ...\n",
      "112 ...\n",
      "113 ...\n",
      "114 ...\n",
      "115 ...\n",
      "116 ...\n",
      "117 ...\n",
      "118 ...\n",
      "119 ...\n",
      "120 ...\n",
      "121 ...\n",
      "122 ...\n",
      "123 ...\n",
      "124 ...\n",
      "125 ...\n",
      "126 ...\n",
      "127 ...\n",
      "128 ...\n",
      "129 ...\n",
      "130 ...\n",
      "131 ...\n",
      "132 ...\n",
      "133 ...\n",
      "134 ...\n",
      "135 ...\n",
      "136 ...\n",
      "137 ...\n",
      "138 ...\n",
      "139 ...\n",
      "140 ...\n",
      "141 ...\n",
      "142 ...\n",
      "143 ...\n",
      "144 ...\n",
      "145 ...\n",
      "146 ...\n",
      "147 ...\n",
      "148 ...\n",
      "149 ...\n",
      "150 ...\n",
      "151 ...\n",
      "152 ...\n",
      "153 ...\n",
      "154 ...\n",
      "155 ...\n",
      "156 ...\n",
      "157 ...\n",
      "158 ...\n",
      "159 ...\n",
      "160 ...\n",
      "161 ...\n",
      "162 ...\n",
      "163 ...\n",
      "164 ...\n",
      "165 ...\n",
      "166 ...\n",
      "167 ...\n",
      "168 ...\n",
      "169 ...\n",
      "170 ...\n",
      "171 ...\n",
      "172 ...\n",
      "173 ...\n",
      "174 ...\n",
      "175 ...\n",
      "176 ...\n",
      "177 ...\n",
      "178 ...\n",
      "179 ...\n",
      "180 ...\n",
      "181 ...\n",
      "182 ...\n",
      "183 ...\n",
      "184 ...\n",
      "185 ...\n",
      "186 ...\n",
      "187 ...\n",
      "188 ...\n",
      "189 ...\n",
      "190 ...\n",
      "191 ...\n",
      "192 ...\n",
      "193 ...\n",
      "194 ...\n",
      "195 ...\n",
      "196 ...\n",
      "197 ...\n",
      "198 ...\n",
      "199 ...\n",
      "200 ...\n",
      "201 ...\n",
      "202 ...\n",
      "203 ...\n",
      "204 ...\n",
      "205 ...\n",
      "206 ...\n",
      "207 ...\n",
      "208 ...\n",
      "209 ...\n",
      "210 ...\n",
      "211 ...\n",
      "212 ...\n",
      "213 ...\n",
      "214 ...\n",
      "215 ...\n",
      "216 ...\n",
      "217 ...\n",
      "218 ...\n",
      "219 ...\n",
      "220 ...\n",
      "221 ...\n",
      "222 ...\n",
      "223 ...\n",
      "224 ...\n",
      "225 ...\n",
      "226 ...\n",
      "227 ...\n",
      "228 ...\n",
      "229 ...\n",
      "230 ...\n",
      "231 ...\n",
      "232 ...\n",
      "233 ...\n",
      "234 ...\n",
      "235 ...\n",
      "236 ...\n",
      "237 ...\n",
      "238 ...\n",
      "239 ...\n",
      "240 ...\n",
      "241 ...\n",
      "242 ...\n",
      "243 ...\n",
      "244 ...\n",
      "245 ...\n",
      "246 ...\n",
      "247 ...\n",
      "248 ...\n",
      "249 ...\n",
      "250 ...\n",
      "251 ...\n",
      "252 ...\n",
      "253 ...\n",
      "254 ...\n",
      "255 ...\n",
      "256 ...\n",
      "257 ...\n",
      "258 ...\n",
      "259 ...\n",
      "260 ...\n",
      "261 ...\n",
      "262 ...\n",
      "263 ...\n",
      "264 ...\n",
      "265 ...\n",
      "266 ...\n",
      "267 ...\n",
      "268 ...\n",
      "269 ...\n",
      "270 ...\n",
      "271 ...\n",
      "272 ...\n",
      "273 ...\n",
      "274 ...\n",
      "275 ...\n",
      "276 ...\n",
      "277 ...\n",
      "278 ...\n",
      "279 ...\n",
      "280 ...\n",
      "281 ...\n",
      "282 ...\n",
      "283 ...\n",
      "284 ...\n",
      "285 ...\n",
      "286 ...\n",
      "287 ...\n",
      "288 ...\n",
      "289 ...\n",
      "290 ...\n",
      "291 ...\n",
      "292 ...\n",
      "293 ...\n",
      "294 ...\n",
      "295 ...\n",
      "296 ...\n",
      "297 ...\n",
      "298 ...\n",
      "299 ...\n",
      "300 ...\n",
      "301 ...\n",
      "302 ...\n",
      "303 ...\n",
      "304 ...\n",
      "305 ...\n",
      "306 ...\n",
      "307 ...\n",
      "308 ...\n",
      "309 ...\n",
      "310 ...\n",
      "311 ...\n",
      "312 ...\n",
      "313 ...\n",
      "314 ...\n",
      "315 ...\n",
      "316 ...\n",
      "317 ...\n",
      "318 ...\n",
      "319 ...\n",
      "320 ...\n",
      "321 ...\n",
      "322 ...\n",
      "323 ...\n",
      "324 ...\n",
      "325 ...\n",
      "326 ...\n",
      "327 ...\n",
      "328 ...\n",
      "329 ...\n",
      "330 ...\n",
      "331 ...\n",
      "332 ...\n",
      "333 ...\n",
      "334 ...\n",
      "335 ...\n",
      "336 ...\n",
      "337 ...\n",
      "338 ...\n",
      "339 ...\n",
      "340 ...\n",
      "341 ...\n",
      "342 ...\n",
      "343 ...\n",
      "344 ...\n",
      "345 ...\n",
      "346 ...\n",
      "347 ...\n",
      "348 ...\n",
      "349 ...\n",
      "350 ...\n",
      "351 ...\n",
      "352 ...\n",
      "353 ...\n",
      "354 ...\n",
      "355 ...\n",
      "356 ...\n",
      "357 ...\n",
      "358 ...\n",
      "359 ...\n",
      "360 ...\n",
      "361 ...\n",
      "362 ...\n",
      "363 ...\n",
      "364 ...\n",
      "365 ...\n",
      "366 ...\n",
      "367 ...\n",
      "368 ...\n",
      "369 ...\n",
      "370 ...\n",
      "371 ...\n",
      "372 ...\n",
      "373 ...\n",
      "374 ...\n",
      "375 ...\n",
      "376 ...\n",
      "377 ...\n",
      "378 ...\n",
      "379 ...\n",
      "380 ...\n",
      "381 ...\n",
      "382 ...\n",
      "383 ...\n",
      "384 ...\n",
      "385 ...\n",
      "386 ...\n",
      "387 ...\n",
      "388 ...\n",
      "389 ...\n",
      "390 ...\n",
      "391 ...\n",
      "392 ...\n",
      "393 ...\n",
      "394 ...\n",
      "395 ...\n",
      "396 ...\n",
      "397 ...\n",
      "398 ...\n",
      "399 ...\n",
      "400 ...\n"
     ]
    }
   ],
   "source": [
    "DATA_test_x_cmplx = []\n",
    "DATA_test_x = []\n",
    "\n",
    "with open(TEST_S,'wb') as fs, open(TEST_N,'wb') as fn, open(TEST_X_cmplx,'wb') as fx_cmplx, open(TEST_X,'wb') as fx: \n",
    "    count = 1\n",
    "    for file_x in sorted(glob.glob(PATH_directory+PATH_test+MIX_format_test)):\n",
    "        x_cmplx,x = preprossed_data(file_x)\n",
    "        DATA_test_x.append(np.array(x))\n",
    "        np.savetxt(fx, x, fmt='%.5f')\n",
    "        fx.write(b'\\n')\n",
    "        \n",
    "        DATA_test_x_cmplx.append(np.array(x_cmplx))\n",
    "        np.savetxt(fx_cmplx, x_cmplx, fmt='%.5f')\n",
    "        fx_cmplx.write(b'\\n')\n",
    "        \n",
    "        print(count,'...')\n",
    "        count += 1\n",
    "        \n",
    "fx_cmplx.close()\n",
    "fx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Function to load data from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_name):\n",
    "    \n",
    "    with open(file_name) as f:\n",
    "        lines=f.readlines()\n",
    "        print(len(lines))\n",
    "        sentence_full=[]\n",
    "        count = 0\n",
    "        sentence=[]\n",
    "        for line in lines:\n",
    "\n",
    "            if count < 513:\n",
    "                if count ==0:\n",
    "                    sentence=np.array(np.fromstring(line, dtype=float, sep=' '), ndmin=2)\n",
    "                    count+=1\n",
    "                else:\n",
    "                    myarray = np.array(np.fromstring(line, dtype=float, sep=' '), ndmin=2)\n",
    "                    sentence=np.concatenate((sentence, myarray), axis=0)\n",
    "                    count+=1\n",
    "            else:\n",
    "                sentence_full.append(sentence) \n",
    "                count=0\n",
    "                sentence=[]\n",
    "                \n",
    "        return sentence_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Train files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616800\n",
      "616800\n",
      "616800\n",
      "616800\n"
     ]
    }
   ],
   "source": [
    "DATA_train_s = load_file(TRAIN_S)\n",
    "DATA_train_n = load_file(TRAIN_N)\n",
    "DATA_train_x_cmplx = load_file(TRAIN_X_cmplx)\n",
    "DATA_train_x = load_file(TRAIN_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Validation files. Do not run this if you want to calculate SNR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA_val_s = load_file(VAL_S)\n",
    "DATA_val_n = load_file(VAL_N)\n",
    "DATA_val_x_cmplx = load_file(VAL_X_cmplx)\n",
    "DATA_val_x = load_file(VAL_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Test files. Do not run this if you want to creat wav output files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA_test_x_cmplx = load_file(TEST_X_cmplx)\n",
    "DATA_test_x = load_file(TEST_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Labels (IRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_train_M=[ (1.0*(DATA_train_s[i]>DATA_train_n[i])) for i in range(len(DATA_train_s)) ]\n",
    "\n",
    "DATA_val_M=[ (1.0*(DATA_val_s[i]>DATA_val_n[i])) for i in range(len(DATA_val_s)) ]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Generator with Mini-Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch_mb(X_,Y_,mini_batch):\n",
    "    \n",
    "    batch_x, batch_y = None, None\n",
    "    \n",
    "    for e,(x,y) in enumerate(zip(X_,Y_)):\n",
    "        \n",
    "        batch_x = np.array(x.T) if batch_x is None else np.concatenate( (batch_x,x.T), axis=0)\n",
    "        batch_y = np.array(y.T) if batch_y is None else np.concatenate( (batch_y,y.T), axis=0)\n",
    "        \n",
    "        if e>0 and (e+1)%10==0:\n",
    "\n",
    "            batch_x, temp_x = None, batch_x\n",
    "            batch_y, temp_y = None, batch_y\n",
    "            \n",
    "            temp_x = temp_x.reshape((-1,Max_RNN,513))\n",
    "            temp_y = temp_y.reshape((-1,Max_RNN,513))\n",
    "            \n",
    "            total_mini_batch = temp_x.shape[0]//mini_batch\n",
    "     \n",
    "            for mb in range(total_mini_batch):\n",
    "                start_b = (mb*mini_batch)\n",
    "                end_b = ((mb+1)*mini_batch)\n",
    "\n",
    "                yield temp_x[start_b:end_b],temp_y[start_b:end_b]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X_,Y_):\n",
    "    \n",
    "    batch_x, batch_y = None, None\n",
    "    \n",
    "    for e,(x,y) in enumerate(zip(X_,Y_)):\n",
    "        \n",
    "        batch_x = np.array(x.T) if batch_x is None else np.concatenate( (batch_x,x.T), axis=0)\n",
    "        batch_y = np.array(y.T) if batch_y is None else np.concatenate( (batch_y,y.T), axis=0)\n",
    "\n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp_x, batch_x = batch_x, None\n",
    "            temp_y, batch_y = batch_y, None\n",
    "            \n",
    "            temp_x = temp_x.reshape((-1,Max_RNN,513))\n",
    "            temp_y = temp_y.reshape((-1,Max_RNN,513))\n",
    "        \n",
    "            yield temp_x,temp_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try various model for this problem. And comparing all these, we choose to model 3 as best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Single Layer RNN (GRU)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(Max_RNN,input_shape=(Max_RNN,513), return_sequences=True))\n",
    "\n",
    "model.add(Dense(513, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit_generator( next_batch(DATA_train_x, DATA_train_M), epochs=20, steps_per_epoch=120, validation_data=next_batch(DATA_val_x, DATA_val_M), validation_steps=120, shuffle=True)\n",
    "\n",
    "# Final evaluation of the model\n",
    "\n",
    "scores = model.evaluate_generator(next_batch(DATA_val_x, DATA_val_M), verbose=0)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Single Layer RNN (GRU) with Mini-batch (10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(Max_RNN,input_shape=(Max_RNN,513), return_sequences=True))\n",
    "\n",
    "model.add(Dense(513, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit_generator( next_batch_mb(DATA_train_x, DATA_train_M,10), epochs=20, steps_per_epoch=700, validation_data=next_batch_mb(DATA_val_x, DATA_val_M,10), validation_steps=700)\n",
    "\n",
    "# Final evaluation of the model\n",
    "\n",
    "scores = model.evaluate_generator(next_batch(DATA_val_x, DATA_val_M), verbose=0)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Two layer Bi-directional RNN (GRU), droupout=0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 5, 10)             15570     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 10)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 5, 10)             480       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5, 513)            5643      \n",
      "=================================================================\n",
      "Total params: 21,693\n",
      "Trainable params: 21,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 3s 25ms/step - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6928 - val_acc: 0.5173\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 606us/step - loss: 0.6927 - acc: 0.5232 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 623us/step - loss: 0.6918 - acc: 0.5446 - val_loss: 0.6916 - val_acc: 0.5311\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 640us/step - loss: 0.6909 - acc: 0.5533 - val_loss: 0.6915 - val_acc: 0.5200\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 492us/step - loss: 0.6904 - acc: 0.5443 - val_loss: 0.6901 - val_acc: 0.5380\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 655us/step - loss: 0.6881 - acc: 0.5841 - val_loss: 0.6903 - val_acc: 0.5305\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 539us/step - loss: 0.6883 - acc: 0.5629 - val_loss: 0.6865 - val_acc: 0.5835\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 588us/step - loss: 0.6877 - acc: 0.5630 - val_loss: 0.6883 - val_acc: 0.5386\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 646us/step - loss: 0.6868 - acc: 0.5766 - val_loss: 0.6873 - val_acc: 0.5517\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 599us/step - loss: 0.6879 - acc: 0.5548 - val_loss: 0.6937 - val_acc: 0.4887\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 531us/step - loss: 0.6927 - acc: 0.5043 - val_loss: 0.6946 - val_acc: 0.4825\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 639us/step - loss: 0.6806 - acc: 0.5999 - val_loss: 0.6880 - val_acc: 0.5260\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 616us/step - loss: 0.6832 - acc: 0.5837 - val_loss: 0.6836 - val_acc: 0.5639\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 591us/step - loss: 0.6779 - acc: 0.6188 - val_loss: 0.6830 - val_acc: 0.5585\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 529us/step - loss: 0.6885 - acc: 0.5422 - val_loss: 0.6956 - val_acc: 0.4847\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 594us/step - loss: 0.6771 - acc: 0.6013 - val_loss: 0.6780 - val_acc: 0.5731\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 592us/step - loss: 0.6870 - acc: 0.5454 - val_loss: 0.7054 - val_acc: 0.4214\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 503us/step - loss: 0.6882 - acc: 0.5271 - val_loss: 0.6837 - val_acc: 0.5528\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 658us/step - loss: 0.6802 - acc: 0.5769 - val_loss: 0.6833 - val_acc: 0.5360\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 560us/step - loss: 0.6784 - acc: 0.5759 - val_loss: 0.6837 - val_acc: 0.5383\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 646us/step - loss: 0.6818 - acc: 0.5744 - val_loss: 0.6787 - val_acc: 0.5732\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 569us/step - loss: 0.6859 - acc: 0.5574 - val_loss: 0.6867 - val_acc: 0.5280\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 515us/step - loss: 0.6788 - acc: 0.5966 - val_loss: 0.6612 - val_acc: 0.6593\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 540us/step - loss: 0.6688 - acc: 0.6368 - val_loss: 0.6735 - val_acc: 0.5881\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 543us/step - loss: 0.6753 - acc: 0.5980 - val_loss: 0.6666 - val_acc: 0.6017\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 522us/step - loss: 0.6747 - acc: 0.6131 - val_loss: 0.6735 - val_acc: 0.5816\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 738us/step - loss: 0.6768 - acc: 0.5748 - val_loss: 0.6852 - val_acc: 0.5325\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 484us/step - loss: 0.6710 - acc: 0.6198 - val_loss: 0.6729 - val_acc: 0.5962\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 623us/step - loss: 0.6725 - acc: 0.6078 - val_loss: 0.6729 - val_acc: 0.5823\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 484us/step - loss: 0.6598 - acc: 0.6243 - val_loss: 0.6613 - val_acc: 0.6106\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 547us/step - loss: 0.6580 - acc: 0.6399 - val_loss: 0.6685 - val_acc: 0.5920\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 562us/step - loss: 0.6718 - acc: 0.5820 - val_loss: 0.6735 - val_acc: 0.5739\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 663us/step - loss: 0.6699 - acc: 0.5975 - val_loss: 0.6641 - val_acc: 0.6097\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 643us/step - loss: 0.6651 - acc: 0.5839 - val_loss: 0.6694 - val_acc: 0.5703\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 452us/step - loss: 0.6940 - acc: 0.5094 - val_loss: 0.6890 - val_acc: 0.5139\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 486us/step - loss: 0.6563 - acc: 0.6351 - val_loss: 0.6617 - val_acc: 0.5956\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 796us/step - loss: 0.6603 - acc: 0.5962 - val_loss: 0.6527 - val_acc: 0.6169\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 712us/step - loss: 0.6592 - acc: 0.5974 - val_loss: 0.6625 - val_acc: 0.5785\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 665us/step - loss: 0.6704 - acc: 0.5595 - val_loss: 0.6607 - val_acc: 0.5698\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 687us/step - loss: 0.6491 - acc: 0.6635 - val_loss: 0.6298 - val_acc: 0.6697\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 749us/step - loss: 0.6785 - acc: 0.5636 - val_loss: 0.6995 - val_acc: 0.5027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 640us/step - loss: 0.6817 - acc: 0.5550 - val_loss: 0.6747 - val_acc: 0.5520\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 601us/step - loss: 0.6559 - acc: 0.6348 - val_loss: 0.6699 - val_acc: 0.5613\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 546us/step - loss: 0.6575 - acc: 0.6116 - val_loss: 0.6622 - val_acc: 0.5822\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 693us/step - loss: 0.6854 - acc: 0.5019 - val_loss: 0.6709 - val_acc: 0.5498\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 519us/step - loss: 0.6636 - acc: 0.5790 - val_loss: 0.6570 - val_acc: 0.6021\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 578us/step - loss: 0.6642 - acc: 0.5813 - val_loss: 0.6626 - val_acc: 0.5822\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 457us/step - loss: 0.6527 - acc: 0.6292 - val_loss: 0.6550 - val_acc: 0.6087\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 512us/step - loss: 0.6589 - acc: 0.6057 - val_loss: 0.6586 - val_acc: 0.5720\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 617us/step - loss: 0.6604 - acc: 0.5826 - val_loss: 0.6529 - val_acc: 0.6134\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 522us/step - loss: 0.6994 - acc: 0.4794 - val_loss: 0.6975 - val_acc: 0.4715\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 611us/step - loss: 0.6791 - acc: 0.5264 - val_loss: 0.6776 - val_acc: 0.5362\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 461us/step - loss: 0.6712 - acc: 0.5884 - val_loss: 0.6796 - val_acc: 0.5595\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 561us/step - loss: 0.6741 - acc: 0.5851 - val_loss: 0.6738 - val_acc: 0.5793\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 657us/step - loss: 0.6753 - acc: 0.5838 - val_loss: 0.6783 - val_acc: 0.5702\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 713us/step - loss: 0.6739 - acc: 0.5877 - val_loss: 0.6720 - val_acc: 0.5704\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 643us/step - loss: 0.6720 - acc: 0.6078 - val_loss: 0.6771 - val_acc: 0.5877\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 560us/step - loss: 0.6697 - acc: 0.6016 - val_loss: 0.6565 - val_acc: 0.6058\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 616us/step - loss: 0.6606 - acc: 0.5880 - val_loss: 0.6749 - val_acc: 0.5385\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 755us/step - loss: 0.6620 - acc: 0.5819 - val_loss: 0.6651 - val_acc: 0.5728\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 611us/step - loss: 0.6640 - acc: 0.5848 - val_loss: 0.6812 - val_acc: 0.5083\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 616us/step - loss: 0.6335 - acc: 0.6520 - val_loss: 0.6463 - val_acc: 0.6016\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 645us/step - loss: 0.6759 - acc: 0.5673 - val_loss: 0.6821 - val_acc: 0.5373\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 626us/step - loss: 0.6491 - acc: 0.6224 - val_loss: 0.6511 - val_acc: 0.6040\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 621us/step - loss: 0.6687 - acc: 0.5727 - val_loss: 0.6409 - val_acc: 0.6324\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 498us/step - loss: 0.6497 - acc: 0.6006 - val_loss: 0.6555 - val_acc: 0.5985\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 575us/step - loss: 0.6677 - acc: 0.5826 - val_loss: 0.6597 - val_acc: 0.6001\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 570us/step - loss: 0.6617 - acc: 0.5960 - val_loss: 0.6458 - val_acc: 0.6179\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 570us/step - loss: 0.6690 - acc: 0.5879 - val_loss: 0.6694 - val_acc: 0.5901\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 519us/step - loss: 0.6341 - acc: 0.6810 - val_loss: 0.6326 - val_acc: 0.6790\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 503us/step - loss: 0.6484 - acc: 0.6488 - val_loss: 0.6356 - val_acc: 0.6713\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 657us/step - loss: 0.6431 - acc: 0.6486 - val_loss: 0.6479 - val_acc: 0.6457\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 645us/step - loss: 0.6389 - acc: 0.6660 - val_loss: 0.6387 - val_acc: 0.6365\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 732us/step - loss: 0.6267 - acc: 0.6813 - val_loss: 0.6276 - val_acc: 0.6729\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 586us/step - loss: 0.6112 - acc: 0.6820 - val_loss: 0.6306 - val_acc: 0.6330\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 695us/step - loss: 0.6847 - acc: 0.5356 - val_loss: 0.6478 - val_acc: 0.6030\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 474us/step - loss: 0.6503 - acc: 0.6049 - val_loss: 0.6328 - val_acc: 0.6442\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 591us/step - loss: 0.6203 - acc: 0.6687 - val_loss: 0.6455 - val_acc: 0.6342\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 639us/step - loss: 0.6110 - acc: 0.6690 - val_loss: 0.6321 - val_acc: 0.6446\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 514us/step - loss: 0.6372 - acc: 0.6088 - val_loss: 0.6545 - val_acc: 0.5972\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 679us/step - loss: 0.6909 - acc: 0.5544 - val_loss: 0.6904 - val_acc: 0.5580\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 790us/step - loss: 0.6575 - acc: 0.5726 - val_loss: 0.6371 - val_acc: 0.6237\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 542us/step - loss: 0.6621 - acc: 0.5779 - val_loss: 0.6493 - val_acc: 0.6207\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 674us/step - loss: 0.6614 - acc: 0.6217 - val_loss: 0.6617 - val_acc: 0.5888\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 597us/step - loss: 0.6602 - acc: 0.6094 - val_loss: 0.6488 - val_acc: 0.6208\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 546us/step - loss: 0.6615 - acc: 0.6077 - val_loss: 0.6529 - val_acc: 0.6140\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 701us/step - loss: 0.6614 - acc: 0.6006 - val_loss: 0.6368 - val_acc: 0.6306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 610us/step - loss: 0.6752 - acc: 0.5580 - val_loss: 0.6511 - val_acc: 0.6313\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 697us/step - loss: 0.6407 - acc: 0.6452 - val_loss: 0.6428 - val_acc: 0.6377\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 577us/step - loss: 0.6512 - acc: 0.6073 - val_loss: 0.6427 - val_acc: 0.6543\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 597us/step - loss: 0.6924 - acc: 0.5582 - val_loss: 0.6875 - val_acc: 0.5742\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 692us/step - loss: 0.6423 - acc: 0.6516 - val_loss: 0.6464 - val_acc: 0.6281\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 558us/step - loss: 0.6561 - acc: 0.6109 - val_loss: 0.6550 - val_acc: 0.6073\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 586us/step - loss: 0.6468 - acc: 0.6581 - val_loss: 0.6276 - val_acc: 0.7087\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 524us/step - loss: 0.6473 - acc: 0.6475 - val_loss: 0.6429 - val_acc: 0.6460\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 593us/step - loss: 0.6481 - acc: 0.6319 - val_loss: 0.6273 - val_acc: 0.6748\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 596us/step - loss: 0.6404 - acc: 0.6477 - val_loss: 0.6181 - val_acc: 0.6857\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 633us/step - loss: 0.6282 - acc: 0.6765 - val_loss: 0.6273 - val_acc: 0.6744\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 543us/step - loss: 0.6310 - acc: 0.6662 - val_loss: 0.6199 - val_acc: 0.7051\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 650us/step - loss: 0.6166 - acc: 0.6983 - val_loss: 0.5956 - val_acc: 0.7271\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 549us/step - loss: 0.6346 - acc: 0.6357 - val_loss: 0.6069 - val_acc: 0.6848\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 755us/step - loss: 0.6318 - acc: 0.6491 - val_loss: 0.6477 - val_acc: 0.6163\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 540us/step - loss: 0.6402 - acc: 0.6308 - val_loss: 0.6173 - val_acc: 0.6705\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 547us/step - loss: 0.6265 - acc: 0.6567 - val_loss: 0.6255 - val_acc: 0.6595\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 519us/step - loss: 0.6149 - acc: 0.6900 - val_loss: 0.6186 - val_acc: 0.6676\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 657us/step - loss: 0.6098 - acc: 0.6760 - val_loss: 0.6119 - val_acc: 0.6832\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 538us/step - loss: 0.6294 - acc: 0.6431 - val_loss: 0.6222 - val_acc: 0.6641\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 663us/step - loss: 0.6605 - acc: 0.6128 - val_loss: 0.6441 - val_acc: 0.6407\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 513us/step - loss: 0.6177 - acc: 0.6768 - val_loss: 0.6066 - val_acc: 0.7030\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 856us/step - loss: 0.6240 - acc: 0.6597 - val_loss: 0.5868 - val_acc: 0.7208\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 634us/step - loss: 0.6303 - acc: 0.6324 - val_loss: 0.5960 - val_acc: 0.7039\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 632us/step - loss: 0.6500 - acc: 0.6166 - val_loss: 0.6308 - val_acc: 0.6492\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 586us/step - loss: 0.6224 - acc: 0.6581 - val_loss: 0.6024 - val_acc: 0.6931\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 645us/step - loss: 0.6030 - acc: 0.6870 - val_loss: 0.5844 - val_acc: 0.7082\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 543us/step - loss: 0.5940 - acc: 0.7021 - val_loss: 0.6101 - val_acc: 0.6798\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 664us/step - loss: 0.5888 - acc: 0.7027 - val_loss: 0.5751 - val_acc: 0.7266\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 504us/step - loss: 0.6280 - acc: 0.6582 - val_loss: 0.6056 - val_acc: 0.6861\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 672us/step - loss: 0.6458 - acc: 0.6463 - val_loss: 0.6320 - val_acc: 0.6715\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 593us/step - loss: 0.5999 - acc: 0.6850 - val_loss: 0.5995 - val_acc: 0.6710\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 521us/step - loss: 0.6328 - acc: 0.6452 - val_loss: 0.6082 - val_acc: 0.6784\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.5519 - acc: 0.7462 - val_loss: 0.5892 - val_acc: 0.6836\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 652us/step - loss: 0.6151 - acc: 0.6754 - val_loss: 0.5914 - val_acc: 0.7129\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 659us/step - loss: 0.5851 - acc: 0.6962 - val_loss: 0.6023 - val_acc: 0.6741\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 730us/step - loss: 0.5942 - acc: 0.6890 - val_loss: 0.6110 - val_acc: 0.6696\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 557us/step - loss: 0.5950 - acc: 0.6796 - val_loss: 0.6104 - val_acc: 0.6570\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 687us/step - loss: 0.5717 - acc: 0.7129 - val_loss: 0.6039 - val_acc: 0.6791\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 586us/step - loss: 0.6113 - acc: 0.6602 - val_loss: 0.5927 - val_acc: 0.6889\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 520us/step - loss: 0.6245 - acc: 0.6438 - val_loss: 0.6098 - val_acc: 0.6752\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 631us/step - loss: 0.6066 - acc: 0.6641 - val_loss: 0.5979 - val_acc: 0.6911\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 610us/step - loss: 0.6258 - acc: 0.6529 - val_loss: 0.6279 - val_acc: 0.6741\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 511us/step - loss: 0.6718 - acc: 0.5986 - val_loss: 0.6229 - val_acc: 0.6748\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 712us/step - loss: 0.6196 - acc: 0.6772 - val_loss: 0.6179 - val_acc: 0.6848\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 628us/step - loss: 0.6188 - acc: 0.6736 - val_loss: 0.5861 - val_acc: 0.7004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 633us/step - loss: 0.6122 - acc: 0.6627 - val_loss: 0.6145 - val_acc: 0.6745\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 541us/step - loss: 0.6689 - acc: 0.5971 - val_loss: 0.6371 - val_acc: 0.6485\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 616us/step - loss: 0.5989 - acc: 0.6965 - val_loss: 0.5693 - val_acc: 0.7415\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 575us/step - loss: 0.6422 - acc: 0.6369 - val_loss: 0.6675 - val_acc: 0.6381\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 536us/step - loss: 0.6081 - acc: 0.6804 - val_loss: 0.6026 - val_acc: 0.6955\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 666us/step - loss: 0.6165 - acc: 0.6713 - val_loss: 0.5837 - val_acc: 0.7283\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 623us/step - loss: 0.5960 - acc: 0.7080 - val_loss: 0.6078 - val_acc: 0.6893\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 680us/step - loss: 0.5976 - acc: 0.6813 - val_loss: 0.6036 - val_acc: 0.6884\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 587us/step - loss: 0.6616 - acc: 0.5908 - val_loss: 0.6429 - val_acc: 0.6206\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 538us/step - loss: 0.6538 - acc: 0.5975 - val_loss: 0.5719 - val_acc: 0.7238\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 570us/step - loss: 0.6184 - acc: 0.6576 - val_loss: 0.5764 - val_acc: 0.7321\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 537us/step - loss: 0.6252 - acc: 0.6287 - val_loss: 0.5708 - val_acc: 0.7290\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 463us/step - loss: 0.6194 - acc: 0.6502 - val_loss: 0.5684 - val_acc: 0.7280\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 687us/step - loss: 0.5970 - acc: 0.6871 - val_loss: 0.5895 - val_acc: 0.7038\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 633us/step - loss: 0.6323 - acc: 0.6384 - val_loss: 0.5922 - val_acc: 0.7028\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 623us/step - loss: 0.6061 - acc: 0.6696 - val_loss: 0.5892 - val_acc: 0.6938\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 511us/step - loss: 0.5806 - acc: 0.6959 - val_loss: 0.5849 - val_acc: 0.6966\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 615us/step - loss: 0.5934 - acc: 0.6674 - val_loss: 0.5848 - val_acc: 0.7120\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 555us/step - loss: 0.6143 - acc: 0.6500 - val_loss: 0.6048 - val_acc: 0.6646\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 682us/step - loss: 0.5718 - acc: 0.7025 - val_loss: 0.5440 - val_acc: 0.7774\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 608us/step - loss: 0.5900 - acc: 0.6845 - val_loss: 0.5995 - val_acc: 0.6726\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 505us/step - loss: 0.6181 - acc: 0.6685 - val_loss: 0.5924 - val_acc: 0.7017\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 529us/step - loss: 0.5774 - acc: 0.6963 - val_loss: 0.5645 - val_acc: 0.7363\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 796us/step - loss: 0.6012 - acc: 0.6548 - val_loss: 0.5695 - val_acc: 0.7044\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 692us/step - loss: 0.5671 - acc: 0.7284 - val_loss: 0.5626 - val_acc: 0.7310\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 702us/step - loss: 0.6221 - acc: 0.6382 - val_loss: 0.5985 - val_acc: 0.6608\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 659us/step - loss: 0.5597 - acc: 0.7277 - val_loss: 0.5308 - val_acc: 0.7591\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 690us/step - loss: 0.6613 - acc: 0.6378 - val_loss: 0.7179 - val_acc: 0.5654\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 631us/step - loss: 0.6829 - acc: 0.5901 - val_loss: 0.6487 - val_acc: 0.6287\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 596us/step - loss: 0.6151 - acc: 0.6652 - val_loss: 0.6282 - val_acc: 0.6517\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 538us/step - loss: 0.6348 - acc: 0.6572 - val_loss: 0.6318 - val_acc: 0.6609\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 639us/step - loss: 0.6358 - acc: 0.6599 - val_loss: 0.6049 - val_acc: 0.6846\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 535us/step - loss: 0.6316 - acc: 0.6405 - val_loss: 0.6139 - val_acc: 0.6691\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 621us/step - loss: 0.6413 - acc: 0.6114 - val_loss: 0.6415 - val_acc: 0.6095\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 492us/step - loss: 0.6475 - acc: 0.6057 - val_loss: 0.6216 - val_acc: 0.6463\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 542us/step - loss: 0.6273 - acc: 0.6473 - val_loss: 0.6089 - val_acc: 0.6749\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 624us/step - loss: 0.6159 - acc: 0.6505 - val_loss: 0.6172 - val_acc: 0.6661\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 475us/step - loss: 0.6189 - acc: 0.6784 - val_loss: 0.6065 - val_acc: 0.6994\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 644us/step - loss: 0.5947 - acc: 0.7031 - val_loss: 0.6040 - val_acc: 0.6969\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 539us/step - loss: 0.6183 - acc: 0.6783 - val_loss: 0.6085 - val_acc: 0.6942\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 520us/step - loss: 0.6351 - acc: 0.6462 - val_loss: 0.6146 - val_acc: 0.6778\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 629us/step - loss: 0.6227 - acc: 0.6521 - val_loss: 0.6180 - val_acc: 0.6918\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 685us/step - loss: 0.5997 - acc: 0.7072 - val_loss: 0.6063 - val_acc: 0.6872\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 639us/step - loss: 0.6098 - acc: 0.6852 - val_loss: 0.6227 - val_acc: 0.6690\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 624us/step - loss: 0.6278 - acc: 0.6572 - val_loss: 0.5913 - val_acc: 0.7097\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 652us/step - loss: 0.6164 - acc: 0.6693 - val_loss: 0.6183 - val_acc: 0.6809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 891us/step - loss: 0.6172 - acc: 0.6570 - val_loss: 0.6207 - val_acc: 0.6718\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 657us/step - loss: 0.6213 - acc: 0.6643 - val_loss: 0.6210 - val_acc: 0.6778\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 715us/step - loss: 0.5697 - acc: 0.7198 - val_loss: 0.5815 - val_acc: 0.7290\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 658us/step - loss: 0.6366 - acc: 0.6452 - val_loss: 0.6107 - val_acc: 0.6808\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 654us/step - loss: 0.5897 - acc: 0.6947 - val_loss: 0.5689 - val_acc: 0.7176\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 636us/step - loss: 0.6094 - acc: 0.6893 - val_loss: 0.5813 - val_acc: 0.7103\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 483us/step - loss: 0.5840 - acc: 0.6945 - val_loss: 0.5995 - val_acc: 0.6894\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 560us/step - loss: 0.6327 - acc: 0.6408 - val_loss: 0.6138 - val_acc: 0.6614\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 596us/step - loss: 0.6234 - acc: 0.6597 - val_loss: 0.5893 - val_acc: 0.7059\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 569us/step - loss: 0.6209 - acc: 0.6854 - val_loss: 0.6226 - val_acc: 0.6929\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 547us/step - loss: 0.5623 - acc: 0.7395 - val_loss: 0.5688 - val_acc: 0.7238\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 542us/step - loss: 0.6071 - acc: 0.6781 - val_loss: 0.5741 - val_acc: 0.7212\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 662us/step - loss: 0.5940 - acc: 0.7034 - val_loss: 0.5978 - val_acc: 0.7014\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 636us/step - loss: 0.5922 - acc: 0.6928 - val_loss: 0.5844 - val_acc: 0.6941\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 699us/step - loss: 0.5690 - acc: 0.7318 - val_loss: 0.5781 - val_acc: 0.7193\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 546us/step - loss: 0.5500 - acc: 0.7355 - val_loss: 0.5735 - val_acc: 0.7121\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 611us/step - loss: 0.6427 - acc: 0.6368 - val_loss: 0.6048 - val_acc: 0.6852\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 522us/step - loss: 0.6091 - acc: 0.6856 - val_loss: 0.5857 - val_acc: 0.6985\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 649us/step - loss: 0.5892 - acc: 0.6785 - val_loss: 0.6088 - val_acc: 0.6912\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 642us/step - loss: 0.5881 - acc: 0.6761 - val_loss: 0.5943 - val_acc: 0.6955\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 516us/step - loss: 0.5956 - acc: 0.6909 - val_loss: 0.6184 - val_acc: 0.6793\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 657us/step - loss: 0.6416 - acc: 0.6381 - val_loss: 0.6427 - val_acc: 0.6541\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 818us/step - loss: 0.5819 - acc: 0.6954 - val_loss: 0.5860 - val_acc: 0.7020\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 552us/step - loss: 0.6022 - acc: 0.6842 - val_loss: 0.5917 - val_acc: 0.6992\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 677us/step - loss: 0.6089 - acc: 0.6850 - val_loss: 0.6172 - val_acc: 0.6661\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 626us/step - loss: 0.6311 - acc: 0.6508 - val_loss: 0.6112 - val_acc: 0.6571\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 529us/step - loss: 0.6150 - acc: 0.6566 - val_loss: 0.6082 - val_acc: 0.6635\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 644us/step - loss: 0.6327 - acc: 0.6387 - val_loss: 0.5695 - val_acc: 0.7033\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 657us/step - loss: 0.6438 - acc: 0.6357 - val_loss: 0.6003 - val_acc: 0.6843\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.5821 - acc: 0.6998 - val_loss: 0.5850 - val_acc: 0.7148\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 574us/step - loss: 0.5893 - acc: 0.6957 - val_loss: 0.5767 - val_acc: 0.7280\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.6622 - acc: 0.6537 - val_loss: 0.6631 - val_acc: 0.6522\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 682us/step - loss: 0.5958 - acc: 0.7057 - val_loss: 0.5988 - val_acc: 0.6999\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 553us/step - loss: 0.5994 - acc: 0.6846 - val_loss: 0.5976 - val_acc: 0.6940\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 596us/step - loss: 0.5765 - acc: 0.7177 - val_loss: 0.5434 - val_acc: 0.7569\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 552us/step - loss: 0.5874 - acc: 0.7143 - val_loss: 0.5830 - val_acc: 0.6976\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 593us/step - loss: 0.5967 - acc: 0.6835 - val_loss: 0.5672 - val_acc: 0.7220\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 594us/step - loss: 0.5924 - acc: 0.6938 - val_loss: 0.5601 - val_acc: 0.7298\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 644us/step - loss: 0.5886 - acc: 0.7069 - val_loss: 0.5881 - val_acc: 0.6929\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 609us/step - loss: 0.5946 - acc: 0.6966 - val_loss: 0.5653 - val_acc: 0.7363\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 657us/step - loss: 0.5615 - acc: 0.7170 - val_loss: 0.5434 - val_acc: 0.7335\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 479us/step - loss: 0.6271 - acc: 0.6409 - val_loss: 0.5696 - val_acc: 0.7054\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 744us/step - loss: 0.5974 - acc: 0.6810 - val_loss: 0.6452 - val_acc: 0.6307\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 496us/step - loss: 0.6309 - acc: 0.6492 - val_loss: 0.6011 - val_acc: 0.6732\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 519us/step - loss: 0.6182 - acc: 0.6661 - val_loss: 0.6013 - val_acc: 0.6808\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 481us/step - loss: 0.5971 - acc: 0.6897 - val_loss: 0.5943 - val_acc: 0.6912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 619us/step - loss: 0.5781 - acc: 0.7115 - val_loss: 0.5742 - val_acc: 0.7184\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 499us/step - loss: 0.6179 - acc: 0.6552 - val_loss: 0.6130 - val_acc: 0.6707\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 600us/step - loss: 0.6433 - acc: 0.6357 - val_loss: 0.6281 - val_acc: 0.6601\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 473us/step - loss: 0.5928 - acc: 0.6930 - val_loss: 0.5793 - val_acc: 0.7190\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 589us/step - loss: 0.6041 - acc: 0.6752 - val_loss: 0.5534 - val_acc: 0.7317\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 583us/step - loss: 0.6205 - acc: 0.6396 - val_loss: 0.5652 - val_acc: 0.7121\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 603us/step - loss: 0.6324 - acc: 0.6425 - val_loss: 0.6067 - val_acc: 0.6818\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 533us/step - loss: 0.5835 - acc: 0.7024 - val_loss: 0.5618 - val_acc: 0.7358\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 587us/step - loss: 0.5619 - acc: 0.7087 - val_loss: 0.5484 - val_acc: 0.7252\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.5725 - acc: 0.7102 - val_loss: 0.5853 - val_acc: 0.6988\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 591us/step - loss: 0.5467 - acc: 0.7225 - val_loss: 0.5441 - val_acc: 0.7362\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 477us/step - loss: 0.5966 - acc: 0.6960 - val_loss: 0.5711 - val_acc: 0.7086\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 599us/step - loss: 0.6070 - acc: 0.6844 - val_loss: 0.5980 - val_acc: 0.6966\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 571us/step - loss: 0.5956 - acc: 0.6681 - val_loss: 0.5770 - val_acc: 0.6948\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 509us/step - loss: 0.6118 - acc: 0.6658 - val_loss: 0.5731 - val_acc: 0.7173\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 694us/step - loss: 0.5282 - acc: 0.7546 - val_loss: 0.5669 - val_acc: 0.7080\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 534us/step - loss: 0.5869 - acc: 0.7033 - val_loss: 0.5660 - val_acc: 0.7245\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 618us/step - loss: 0.5596 - acc: 0.7197 - val_loss: 0.5744 - val_acc: 0.7042\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 717us/step - loss: 0.5539 - acc: 0.7350 - val_loss: 0.5725 - val_acc: 0.7190\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 558us/step - loss: 0.5605 - acc: 0.7233 - val_loss: 0.5761 - val_acc: 0.7062\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 676us/step - loss: 0.5406 - acc: 0.7471 - val_loss: 0.5802 - val_acc: 0.6973\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 578us/step - loss: 0.5979 - acc: 0.6648 - val_loss: 0.5755 - val_acc: 0.7036\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 536us/step - loss: 0.6026 - acc: 0.6682 - val_loss: 0.5782 - val_acc: 0.7080\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 566us/step - loss: 0.5823 - acc: 0.6777 - val_loss: 0.5691 - val_acc: 0.7102\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 567us/step - loss: 0.5996 - acc: 0.6824 - val_loss: 0.5923 - val_acc: 0.7055\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 503us/step - loss: 0.6607 - acc: 0.6152 - val_loss: 0.6068 - val_acc: 0.6899\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 679us/step - loss: 0.5993 - acc: 0.7004 - val_loss: 0.5917 - val_acc: 0.7099\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 605us/step - loss: 0.5980 - acc: 0.6950 - val_loss: 0.5574 - val_acc: 0.7278\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 628us/step - loss: 0.5846 - acc: 0.6950 - val_loss: 0.5839 - val_acc: 0.6999\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 556us/step - loss: 0.6675 - acc: 0.6095 - val_loss: 0.6281 - val_acc: 0.6564\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 658us/step - loss: 0.5756 - acc: 0.7160 - val_loss: 0.5363 - val_acc: 0.7650\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 608us/step - loss: 0.6203 - acc: 0.6707 - val_loss: 0.6311 - val_acc: 0.6782\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 528us/step - loss: 0.5833 - acc: 0.7131 - val_loss: 0.5782 - val_acc: 0.7179\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 682us/step - loss: 0.5930 - acc: 0.7033 - val_loss: 0.5545 - val_acc: 0.7532\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 597us/step - loss: 0.5708 - acc: 0.7206 - val_loss: 0.5890 - val_acc: 0.7022\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 639us/step - loss: 0.5697 - acc: 0.7122 - val_loss: 0.5799 - val_acc: 0.7123\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 532us/step - loss: 0.6322 - acc: 0.6264 - val_loss: 0.6148 - val_acc: 0.6589\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 531us/step - loss: 0.6453 - acc: 0.6142 - val_loss: 0.5498 - val_acc: 0.7484\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 556us/step - loss: 0.6088 - acc: 0.6662 - val_loss: 0.5495 - val_acc: 0.7447\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 593us/step - loss: 0.6139 - acc: 0.6374 - val_loss: 0.5454 - val_acc: 0.7439\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 497us/step - loss: 0.6021 - acc: 0.6765 - val_loss: 0.5393 - val_acc: 0.7510\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 667us/step - loss: 0.5787 - acc: 0.6991 - val_loss: 0.5639 - val_acc: 0.7227\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 518us/step - loss: 0.6182 - acc: 0.6564 - val_loss: 0.5625 - val_acc: 0.7223\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 642us/step - loss: 0.5879 - acc: 0.6942 - val_loss: 0.5647 - val_acc: 0.7149\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 488us/step - loss: 0.5609 - acc: 0.7209 - val_loss: 0.5630 - val_acc: 0.7158\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 665us/step - loss: 0.5991 - acc: 0.6536 - val_loss: 0.5805 - val_acc: 0.7073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 600us/step - loss: 0.5925 - acc: 0.6758 - val_loss: 0.5931 - val_acc: 0.6842\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 682us/step - loss: 0.5529 - acc: 0.7223 - val_loss: 0.5127 - val_acc: 0.7959\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 651us/step - loss: 0.5641 - acc: 0.7116 - val_loss: 0.5784 - val_acc: 0.6930\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 493us/step - loss: 0.6051 - acc: 0.6772 - val_loss: 0.5776 - val_acc: 0.7063\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 478us/step - loss: 0.5584 - acc: 0.7136 - val_loss: 0.5408 - val_acc: 0.7486\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 776us/step - loss: 0.5827 - acc: 0.6852 - val_loss: 0.5506 - val_acc: 0.7184\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 664us/step - loss: 0.5448 - acc: 0.7381 - val_loss: 0.5335 - val_acc: 0.7550\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 676us/step - loss: 0.6097 - acc: 0.6541 - val_loss: 0.5689 - val_acc: 0.7143\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 612us/step - loss: 0.5325 - acc: 0.7613 - val_loss: 0.5040 - val_acc: 0.7778\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 650us/step - loss: 0.6386 - acc: 0.6798 - val_loss: 0.6816 - val_acc: 0.6136\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 648us/step - loss: 0.6608 - acc: 0.6235 - val_loss: 0.6328 - val_acc: 0.6513\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 604us/step - loss: 0.6078 - acc: 0.6758 - val_loss: 0.6090 - val_acc: 0.6844\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 482us/step - loss: 0.6271 - acc: 0.6677 - val_loss: 0.6176 - val_acc: 0.6730\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 653us/step - loss: 0.6151 - acc: 0.6766 - val_loss: 0.5823 - val_acc: 0.7129\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 556us/step - loss: 0.6080 - acc: 0.6717 - val_loss: 0.5969 - val_acc: 0.6949\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 685us/step - loss: 0.6175 - acc: 0.6558 - val_loss: 0.6059 - val_acc: 0.6728\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 525us/step - loss: 0.6132 - acc: 0.6586 - val_loss: 0.5878 - val_acc: 0.7052\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 523us/step - loss: 0.5986 - acc: 0.6906 - val_loss: 0.5863 - val_acc: 0.6934\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 609us/step - loss: 0.6022 - acc: 0.6647 - val_loss: 0.5989 - val_acc: 0.6887\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 483us/step - loss: 0.5982 - acc: 0.6959 - val_loss: 0.5848 - val_acc: 0.7170\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 604us/step - loss: 0.5732 - acc: 0.7184 - val_loss: 0.5765 - val_acc: 0.7182\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 527us/step - loss: 0.6008 - acc: 0.6889 - val_loss: 0.5765 - val_acc: 0.7174\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 550us/step - loss: 0.6203 - acc: 0.6646 - val_loss: 0.5944 - val_acc: 0.6902\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 621us/step - loss: 0.6071 - acc: 0.6720 - val_loss: 0.5847 - val_acc: 0.7154\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 677us/step - loss: 0.5718 - acc: 0.7266 - val_loss: 0.5830 - val_acc: 0.7057\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 607us/step - loss: 0.5920 - acc: 0.7021 - val_loss: 0.6012 - val_acc: 0.6833\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 590us/step - loss: 0.6117 - acc: 0.6713 - val_loss: 0.5621 - val_acc: 0.7410\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 674us/step - loss: 0.5952 - acc: 0.6908 - val_loss: 0.5974 - val_acc: 0.6939\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 757us/step - loss: 0.5980 - acc: 0.6838 - val_loss: 0.5965 - val_acc: 0.6961\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 657us/step - loss: 0.5946 - acc: 0.6906 - val_loss: 0.5921 - val_acc: 0.7001\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 667us/step - loss: 0.5428 - acc: 0.7429 - val_loss: 0.5522 - val_acc: 0.7462\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 722us/step - loss: 0.6099 - acc: 0.6756 - val_loss: 0.5758 - val_acc: 0.7178\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 617us/step - loss: 0.5606 - acc: 0.7226 - val_loss: 0.5385 - val_acc: 0.7409\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 638us/step - loss: 0.5864 - acc: 0.7088 - val_loss: 0.5604 - val_acc: 0.7239\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 493us/step - loss: 0.5593 - acc: 0.7139 - val_loss: 0.5724 - val_acc: 0.7105\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 561us/step - loss: 0.6244 - acc: 0.6454 - val_loss: 0.6003 - val_acc: 0.6680\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 550us/step - loss: 0.6070 - acc: 0.6768 - val_loss: 0.5749 - val_acc: 0.7142\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 548us/step - loss: 0.5954 - acc: 0.7003 - val_loss: 0.5996 - val_acc: 0.7040\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 515us/step - loss: 0.5370 - acc: 0.7566 - val_loss: 0.5477 - val_acc: 0.7344\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 506us/step - loss: 0.5839 - acc: 0.7020 - val_loss: 0.5504 - val_acc: 0.7364\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 649us/step - loss: 0.5741 - acc: 0.7219 - val_loss: 0.5739 - val_acc: 0.7184\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 623us/step - loss: 0.5746 - acc: 0.7112 - val_loss: 0.5748 - val_acc: 0.6986\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 674us/step - loss: 0.5464 - acc: 0.7501 - val_loss: 0.5557 - val_acc: 0.7390\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 536us/step - loss: 0.5398 - acc: 0.7398 - val_loss: 0.5543 - val_acc: 0.7277\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 630us/step - loss: 0.6227 - acc: 0.6555 - val_loss: 0.5778 - val_acc: 0.7107\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 531us/step - loss: 0.5901 - acc: 0.7021 - val_loss: 0.5627 - val_acc: 0.7200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 699us/step - loss: 0.5768 - acc: 0.6877 - val_loss: 0.5832 - val_acc: 0.7074\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 654us/step - loss: 0.5703 - acc: 0.6990 - val_loss: 0.5663 - val_acc: 0.7217\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 563us/step - loss: 0.5731 - acc: 0.7100 - val_loss: 0.5974 - val_acc: 0.6957\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 629us/step - loss: 0.6183 - acc: 0.6634 - val_loss: 0.6235 - val_acc: 0.6729\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 794us/step - loss: 0.5623 - acc: 0.7106 - val_loss: 0.5633 - val_acc: 0.7210\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 533us/step - loss: 0.5857 - acc: 0.6894 - val_loss: 0.5776 - val_acc: 0.7022\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 690us/step - loss: 0.5922 - acc: 0.6942 - val_loss: 0.6021 - val_acc: 0.6821\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 619us/step - loss: 0.6016 - acc: 0.6916 - val_loss: 0.5860 - val_acc: 0.6935\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 539us/step - loss: 0.5931 - acc: 0.6888 - val_loss: 0.5868 - val_acc: 0.6903\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 781us/step - loss: 0.6151 - acc: 0.6561 - val_loss: 0.5496 - val_acc: 0.7254\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 615us/step - loss: 0.6317 - acc: 0.6534 - val_loss: 0.5759 - val_acc: 0.7076\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 731us/step - loss: 0.5602 - acc: 0.7255 - val_loss: 0.5683 - val_acc: 0.7245\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 542us/step - loss: 0.5750 - acc: 0.7032 - val_loss: 0.5532 - val_acc: 0.7411\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.6221 - acc: 0.6903 - val_loss: 0.6282 - val_acc: 0.6795\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 651us/step - loss: 0.5803 - acc: 0.7183 - val_loss: 0.5845 - val_acc: 0.7062\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 535us/step - loss: 0.5777 - acc: 0.7069 - val_loss: 0.5760 - val_acc: 0.7107\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 560us/step - loss: 0.5541 - acc: 0.7236 - val_loss: 0.5172 - val_acc: 0.7708\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 500us/step - loss: 0.5594 - acc: 0.7339 - val_loss: 0.5567 - val_acc: 0.7259\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 571us/step - loss: 0.5870 - acc: 0.6924 - val_loss: 0.5465 - val_acc: 0.7388\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 677us/step - loss: 0.5742 - acc: 0.7115 - val_loss: 0.5478 - val_acc: 0.7346\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 611us/step - loss: 0.5729 - acc: 0.7217 - val_loss: 0.5753 - val_acc: 0.7111\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 559us/step - loss: 0.5883 - acc: 0.6976 - val_loss: 0.5452 - val_acc: 0.7435\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 617us/step - loss: 0.5441 - acc: 0.7311 - val_loss: 0.5264 - val_acc: 0.7487\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 456us/step - loss: 0.6036 - acc: 0.6840 - val_loss: 0.5559 - val_acc: 0.7291\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 737us/step - loss: 0.5869 - acc: 0.6922 - val_loss: 0.6370 - val_acc: 0.6436\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 517us/step - loss: 0.6233 - acc: 0.6574 - val_loss: 0.5958 - val_acc: 0.6848\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 519us/step - loss: 0.6043 - acc: 0.6693 - val_loss: 0.5908 - val_acc: 0.6912\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 485us/step - loss: 0.5871 - acc: 0.6975 - val_loss: 0.5828 - val_acc: 0.7033\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 621us/step - loss: 0.5656 - acc: 0.7131 - val_loss: 0.5560 - val_acc: 0.7249\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 474us/step - loss: 0.6141 - acc: 0.6697 - val_loss: 0.6006 - val_acc: 0.6825\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 620us/step - loss: 0.6190 - acc: 0.6613 - val_loss: 0.6060 - val_acc: 0.6769\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 537us/step - loss: 0.5825 - acc: 0.7048 - val_loss: 0.5570 - val_acc: 0.7265\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 650us/step - loss: 0.5918 - acc: 0.6879 - val_loss: 0.5388 - val_acc: 0.7383\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 619us/step - loss: 0.6076 - acc: 0.6486 - val_loss: 0.5481 - val_acc: 0.7308\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 619us/step - loss: 0.6134 - acc: 0.6644 - val_loss: 0.5975 - val_acc: 0.6913\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 607us/step - loss: 0.5696 - acc: 0.7132 - val_loss: 0.5465 - val_acc: 0.7410\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 656us/step - loss: 0.5486 - acc: 0.7270 - val_loss: 0.5315 - val_acc: 0.7447\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5641 - acc: 0.7182 - val_loss: 0.5628 - val_acc: 0.7186\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 567us/step - loss: 0.5345 - acc: 0.7367 - val_loss: 0.5265 - val_acc: 0.7449\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 542us/step - loss: 0.5716 - acc: 0.7183 - val_loss: 0.5455 - val_acc: 0.7367\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 613us/step - loss: 0.5803 - acc: 0.7055 - val_loss: 0.5736 - val_acc: 0.7200\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 659us/step - loss: 0.5847 - acc: 0.6855 - val_loss: 0.5603 - val_acc: 0.7138\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 568us/step - loss: 0.5915 - acc: 0.6914 - val_loss: 0.5522 - val_acc: 0.7342\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 699us/step - loss: 0.5177 - acc: 0.7676 - val_loss: 0.5519 - val_acc: 0.7205\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 554us/step - loss: 0.5661 - acc: 0.7243 - val_loss: 0.5444 - val_acc: 0.7351\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 617us/step - loss: 0.5391 - acc: 0.7418 - val_loss: 0.5518 - val_acc: 0.7165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 689us/step - loss: 0.5361 - acc: 0.7428 - val_loss: 0.5510 - val_acc: 0.7363\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 512us/step - loss: 0.5476 - acc: 0.7288 - val_loss: 0.5591 - val_acc: 0.7202\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 660us/step - loss: 0.5233 - acc: 0.7635 - val_loss: 0.5705 - val_acc: 0.6983\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 518us/step - loss: 0.5914 - acc: 0.6755 - val_loss: 0.5543 - val_acc: 0.7202\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 519us/step - loss: 0.5815 - acc: 0.6887 - val_loss: 0.5574 - val_acc: 0.7228\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 581us/step - loss: 0.5581 - acc: 0.6969 - val_loss: 0.5420 - val_acc: 0.7399\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 579us/step - loss: 0.5725 - acc: 0.6998 - val_loss: 0.5635 - val_acc: 0.7202\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 524us/step - loss: 0.6408 - acc: 0.6351 - val_loss: 0.5886 - val_acc: 0.7020\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 647us/step - loss: 0.5805 - acc: 0.7080 - val_loss: 0.5697 - val_acc: 0.7213\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 604us/step - loss: 0.5884 - acc: 0.6953 - val_loss: 0.5430 - val_acc: 0.7347\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 614us/step - loss: 0.5751 - acc: 0.7036 - val_loss: 0.5657 - val_acc: 0.7169\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 547us/step - loss: 0.6582 - acc: 0.6162 - val_loss: 0.6111 - val_acc: 0.6664\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 606us/step - loss: 0.5608 - acc: 0.7230 - val_loss: 0.5189 - val_acc: 0.7676\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 585us/step - loss: 0.6022 - acc: 0.6895 - val_loss: 0.5957 - val_acc: 0.6978\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 512us/step - loss: 0.5546 - acc: 0.7233 - val_loss: 0.5606 - val_acc: 0.7293\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 636us/step - loss: 0.5813 - acc: 0.7071 - val_loss: 0.5413 - val_acc: 0.7535\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 552us/step - loss: 0.5610 - acc: 0.7232 - val_loss: 0.5751 - val_acc: 0.7140\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 647us/step - loss: 0.5555 - acc: 0.7170 - val_loss: 0.5628 - val_acc: 0.7196\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 584us/step - loss: 0.6081 - acc: 0.6590 - val_loss: 0.5991 - val_acc: 0.6768\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 517us/step - loss: 0.6267 - acc: 0.6344 - val_loss: 0.5301 - val_acc: 0.7572\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 563us/step - loss: 0.5863 - acc: 0.6863 - val_loss: 0.5288 - val_acc: 0.7541\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 545us/step - loss: 0.5986 - acc: 0.6536 - val_loss: 0.5256 - val_acc: 0.7550\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 472us/step - loss: 0.5786 - acc: 0.7034 - val_loss: 0.5171 - val_acc: 0.7661\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 662us/step - loss: 0.5564 - acc: 0.7157 - val_loss: 0.5429 - val_acc: 0.7382\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 515us/step - loss: 0.6043 - acc: 0.6664 - val_loss: 0.5384 - val_acc: 0.7414\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 630us/step - loss: 0.5626 - acc: 0.7079 - val_loss: 0.5370 - val_acc: 0.7325\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 503us/step - loss: 0.5442 - acc: 0.7331 - val_loss: 0.5477 - val_acc: 0.7267\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 630us/step - loss: 0.5943 - acc: 0.6674 - val_loss: 0.5668 - val_acc: 0.7124\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 582us/step - loss: 0.5769 - acc: 0.6928 - val_loss: 0.5724 - val_acc: 0.7060\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 694us/step - loss: 0.5341 - acc: 0.7299 - val_loss: 0.4925 - val_acc: 0.8029\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 688us/step - loss: 0.5416 - acc: 0.7238 - val_loss: 0.5521 - val_acc: 0.7136\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 478us/step - loss: 0.5918 - acc: 0.6882 - val_loss: 0.5559 - val_acc: 0.7224\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 500us/step - loss: 0.5371 - acc: 0.7356 - val_loss: 0.5162 - val_acc: 0.7676\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 781us/step - loss: 0.5612 - acc: 0.7049 - val_loss: 0.5299 - val_acc: 0.7348\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 656us/step - loss: 0.5261 - acc: 0.7475 - val_loss: 0.5092 - val_acc: 0.7689\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 708us/step - loss: 0.5862 - acc: 0.6824 - val_loss: 0.5431 - val_acc: 0.7279\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 609us/step - loss: 0.5095 - acc: 0.7732 - val_loss: 0.4834 - val_acc: 0.7912\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 707us/step - loss: 0.6144 - acc: 0.7019 - val_loss: 0.6449 - val_acc: 0.6489\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 681us/step - loss: 0.6432 - acc: 0.6429 - val_loss: 0.6173 - val_acc: 0.6592\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 643us/step - loss: 0.5925 - acc: 0.6827 - val_loss: 0.5882 - val_acc: 0.6965\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 496us/step - loss: 0.6057 - acc: 0.6813 - val_loss: 0.6031 - val_acc: 0.6796\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 673us/step - loss: 0.5954 - acc: 0.7014 - val_loss: 0.5565 - val_acc: 0.7300\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 578us/step - loss: 0.5860 - acc: 0.6935 - val_loss: 0.5749 - val_acc: 0.7094\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 649us/step - loss: 0.6011 - acc: 0.6708 - val_loss: 0.5887 - val_acc: 0.6828\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 505us/step - loss: 0.6143 - acc: 0.6493 - val_loss: 0.5685 - val_acc: 0.7018\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 553us/step - loss: 0.5781 - acc: 0.7028 - val_loss: 0.5691 - val_acc: 0.7098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 628us/step - loss: 0.5766 - acc: 0.6927 - val_loss: 0.5749 - val_acc: 0.7052\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 512us/step - loss: 0.5800 - acc: 0.7086 - val_loss: 0.5734 - val_acc: 0.7236\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 725us/step - loss: 0.5647 - acc: 0.7182 - val_loss: 0.5654 - val_acc: 0.7248\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 531us/step - loss: 0.5932 - acc: 0.6912 - val_loss: 0.5610 - val_acc: 0.7252\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 534us/step - loss: 0.5978 - acc: 0.6848 - val_loss: 0.5722 - val_acc: 0.7040\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 631us/step - loss: 0.5897 - acc: 0.6891 - val_loss: 0.5552 - val_acc: 0.7314\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 697us/step - loss: 0.5541 - acc: 0.7336 - val_loss: 0.5678 - val_acc: 0.7125\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 644us/step - loss: 0.5753 - acc: 0.7165 - val_loss: 0.5722 - val_acc: 0.7042\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 538us/step - loss: 0.5939 - acc: 0.6894 - val_loss: 0.5353 - val_acc: 0.7528\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 597us/step - loss: 0.5758 - acc: 0.7077 - val_loss: 0.5790 - val_acc: 0.7045\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 756us/step - loss: 0.5722 - acc: 0.7092 - val_loss: 0.5719 - val_acc: 0.7056\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 653us/step - loss: 0.5702 - acc: 0.7095 - val_loss: 0.5688 - val_acc: 0.7170\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 604us/step - loss: 0.5203 - acc: 0.7591 - val_loss: 0.5257 - val_acc: 0.7579\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 683us/step - loss: 0.5999 - acc: 0.6838 - val_loss: 0.5513 - val_acc: 0.7306\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 593us/step - loss: 0.5438 - acc: 0.7388 - val_loss: 0.5205 - val_acc: 0.7503\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 652us/step - loss: 0.5663 - acc: 0.7148 - val_loss: 0.5434 - val_acc: 0.7371\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 479us/step - loss: 0.5488 - acc: 0.7196 - val_loss: 0.5491 - val_acc: 0.7204\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 627us/step - loss: 0.6011 - acc: 0.6659 - val_loss: 0.5812 - val_acc: 0.6864\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 594us/step - loss: 0.5829 - acc: 0.6899 - val_loss: 0.5567 - val_acc: 0.7255\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 535us/step - loss: 0.5696 - acc: 0.7235 - val_loss: 0.5762 - val_acc: 0.7212\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 522us/step - loss: 0.5190 - acc: 0.7663 - val_loss: 0.5291 - val_acc: 0.7414\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 504us/step - loss: 0.5697 - acc: 0.7153 - val_loss: 0.5315 - val_acc: 0.7496\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 669us/step - loss: 0.5591 - acc: 0.7322 - val_loss: 0.5468 - val_acc: 0.7328\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 609us/step - loss: 0.5519 - acc: 0.7248 - val_loss: 0.5583 - val_acc: 0.7087\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 690us/step - loss: 0.5306 - acc: 0.7590 - val_loss: 0.5377 - val_acc: 0.7462\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 486us/step - loss: 0.5203 - acc: 0.7471 - val_loss: 0.5360 - val_acc: 0.7364\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 556us/step - loss: 0.6076 - acc: 0.6659 - val_loss: 0.5616 - val_acc: 0.7164\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 531us/step - loss: 0.5738 - acc: 0.7079 - val_loss: 0.5437 - val_acc: 0.7306\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 616us/step - loss: 0.5565 - acc: 0.7030 - val_loss: 0.5643 - val_acc: 0.7113\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 683us/step - loss: 0.5499 - acc: 0.7129 - val_loss: 0.5449 - val_acc: 0.7364\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 529us/step - loss: 0.5635 - acc: 0.7169 - val_loss: 0.5794 - val_acc: 0.6999\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 602us/step - loss: 0.6054 - acc: 0.6717 - val_loss: 0.6065 - val_acc: 0.6766\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 747us/step - loss: 0.5426 - acc: 0.7334 - val_loss: 0.5485 - val_acc: 0.7227\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 589us/step - loss: 0.5764 - acc: 0.6983 - val_loss: 0.5694 - val_acc: 0.7052\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 666us/step - loss: 0.5906 - acc: 0.6905 - val_loss: 0.5924 - val_acc: 0.6874\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 638us/step - loss: 0.5902 - acc: 0.7041 - val_loss: 0.5689 - val_acc: 0.7041\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 559us/step - loss: 0.5738 - acc: 0.6988 - val_loss: 0.5672 - val_acc: 0.7067\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 756us/step - loss: 0.5870 - acc: 0.6801 - val_loss: 0.5370 - val_acc: 0.7325\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 714us/step - loss: 0.6079 - acc: 0.6694 - val_loss: 0.5538 - val_acc: 0.7245\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 723us/step - loss: 0.5502 - acc: 0.7294 - val_loss: 0.5530 - val_acc: 0.7282\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 622us/step - loss: 0.5496 - acc: 0.7282 - val_loss: 0.5353 - val_acc: 0.7474\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.6092 - acc: 0.7009 - val_loss: 0.6143 - val_acc: 0.6844\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 650us/step - loss: 0.5732 - acc: 0.7158 - val_loss: 0.5719 - val_acc: 0.7083\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 554us/step - loss: 0.5698 - acc: 0.7039 - val_loss: 0.5605 - val_acc: 0.7184\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 664us/step - loss: 0.5406 - acc: 0.7312 - val_loss: 0.5010 - val_acc: 0.7751\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 515us/step - loss: 0.5458 - acc: 0.7431 - val_loss: 0.5438 - val_acc: 0.7360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 562us/step - loss: 0.5765 - acc: 0.6966 - val_loss: 0.5313 - val_acc: 0.7470\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 563us/step - loss: 0.5601 - acc: 0.7197 - val_loss: 0.5344 - val_acc: 0.7432\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 634us/step - loss: 0.5523 - acc: 0.7359 - val_loss: 0.5580 - val_acc: 0.7216\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 568us/step - loss: 0.5696 - acc: 0.7078 - val_loss: 0.5236 - val_acc: 0.7520\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 628us/step - loss: 0.5257 - acc: 0.7392 - val_loss: 0.5108 - val_acc: 0.7571\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 497us/step - loss: 0.5851 - acc: 0.6999 - val_loss: 0.5410 - val_acc: 0.7388\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 758us/step - loss: 0.5751 - acc: 0.7036 - val_loss: 0.6305 - val_acc: 0.6480\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 480us/step - loss: 0.6225 - acc: 0.6508 - val_loss: 0.5923 - val_acc: 0.6853\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 524us/step - loss: 0.5933 - acc: 0.6775 - val_loss: 0.5789 - val_acc: 0.6968\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 569us/step - loss: 0.5721 - acc: 0.7045 - val_loss: 0.5644 - val_acc: 0.7136\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 603us/step - loss: 0.5445 - acc: 0.7206 - val_loss: 0.5381 - val_acc: 0.7312\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 488us/step - loss: 0.6034 - acc: 0.6803 - val_loss: 0.5776 - val_acc: 0.6958\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 593us/step - loss: 0.5992 - acc: 0.6801 - val_loss: 0.5856 - val_acc: 0.6912\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 499us/step - loss: 0.5608 - acc: 0.7088 - val_loss: 0.5355 - val_acc: 0.7367\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 580us/step - loss: 0.5722 - acc: 0.6982 - val_loss: 0.5200 - val_acc: 0.7499\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 592us/step - loss: 0.6047 - acc: 0.6510 - val_loss: 0.5508 - val_acc: 0.7293\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 587us/step - loss: 0.6115 - acc: 0.6736 - val_loss: 0.5916 - val_acc: 0.6969\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 542us/step - loss: 0.5570 - acc: 0.7195 - val_loss: 0.5352 - val_acc: 0.7492\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 660us/step - loss: 0.5518 - acc: 0.7239 - val_loss: 0.5244 - val_acc: 0.7456\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.5596 - acc: 0.7199 - val_loss: 0.5511 - val_acc: 0.7237\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 621us/step - loss: 0.5189 - acc: 0.7463 - val_loss: 0.5132 - val_acc: 0.7503\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 485us/step - loss: 0.5617 - acc: 0.7173 - val_loss: 0.5344 - val_acc: 0.7448\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 587us/step - loss: 0.5694 - acc: 0.7127 - val_loss: 0.5632 - val_acc: 0.7262\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 581us/step - loss: 0.5665 - acc: 0.7028 - val_loss: 0.5432 - val_acc: 0.7231\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 507us/step - loss: 0.5790 - acc: 0.6997 - val_loss: 0.5403 - val_acc: 0.7393\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.5092 - acc: 0.7640 - val_loss: 0.5373 - val_acc: 0.7252\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 574us/step - loss: 0.5491 - acc: 0.7352 - val_loss: 0.5249 - val_acc: 0.7465\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 609us/step - loss: 0.5181 - acc: 0.7542 - val_loss: 0.5317 - val_acc: 0.7312\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 691us/step - loss: 0.5283 - acc: 0.7457 - val_loss: 0.5404 - val_acc: 0.7418\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 518us/step - loss: 0.5310 - acc: 0.7394 - val_loss: 0.5445 - val_acc: 0.7293\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 653us/step - loss: 0.5112 - acc: 0.7654 - val_loss: 0.5643 - val_acc: 0.6995\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 537us/step - loss: 0.5833 - acc: 0.6917 - val_loss: 0.5402 - val_acc: 0.7265\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 526us/step - loss: 0.5739 - acc: 0.6894 - val_loss: 0.5519 - val_acc: 0.7238\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 630us/step - loss: 0.5401 - acc: 0.7140 - val_loss: 0.5280 - val_acc: 0.7421\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 615us/step - loss: 0.5636 - acc: 0.7033 - val_loss: 0.5566 - val_acc: 0.7201\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 498us/step - loss: 0.6401 - acc: 0.6406 - val_loss: 0.5898 - val_acc: 0.7021\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 656us/step - loss: 0.5747 - acc: 0.7089 - val_loss: 0.5580 - val_acc: 0.7211\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 576us/step - loss: 0.5742 - acc: 0.7014 - val_loss: 0.5262 - val_acc: 0.7444\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 623us/step - loss: 0.5554 - acc: 0.7118 - val_loss: 0.5473 - val_acc: 0.7284\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 600us/step - loss: 0.6568 - acc: 0.6258 - val_loss: 0.6020 - val_acc: 0.6764\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 594us/step - loss: 0.5419 - acc: 0.7324 - val_loss: 0.5068 - val_acc: 0.7644\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 581us/step - loss: 0.5856 - acc: 0.6988 - val_loss: 0.5739 - val_acc: 0.7118\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 495us/step - loss: 0.5380 - acc: 0.7353 - val_loss: 0.5510 - val_acc: 0.7331\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 651us/step - loss: 0.5654 - acc: 0.7196 - val_loss: 0.5293 - val_acc: 0.7488\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 543us/step - loss: 0.5457 - acc: 0.7320 - val_loss: 0.5642 - val_acc: 0.7208\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 662us/step - loss: 0.5451 - acc: 0.7228 - val_loss: 0.5497 - val_acc: 0.7238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 558us/step - loss: 0.5993 - acc: 0.6678 - val_loss: 0.5961 - val_acc: 0.6766\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 538us/step - loss: 0.6084 - acc: 0.6602 - val_loss: 0.5150 - val_acc: 0.7588\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 539us/step - loss: 0.5626 - acc: 0.7045 - val_loss: 0.5156 - val_acc: 0.7613\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 532us/step - loss: 0.5926 - acc: 0.6589 - val_loss: 0.5149 - val_acc: 0.7579\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 683us/step - loss: 0.5597 - acc: 0.7161 - val_loss: 0.5015 - val_acc: 0.7727\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 667us/step - loss: 0.5393 - acc: 0.7260 - val_loss: 0.5248 - val_acc: 0.7480\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 496us/step - loss: 0.5929 - acc: 0.6785 - val_loss: 0.5263 - val_acc: 0.7498\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 650us/step - loss: 0.5453 - acc: 0.7222 - val_loss: 0.5189 - val_acc: 0.7456\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 498us/step - loss: 0.5341 - acc: 0.7377 - val_loss: 0.5354 - val_acc: 0.7363\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 573us/step - loss: 0.5940 - acc: 0.6740 - val_loss: 0.5534 - val_acc: 0.7179\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 559us/step - loss: 0.5624 - acc: 0.7088 - val_loss: 0.5579 - val_acc: 0.7146\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 650us/step - loss: 0.5178 - acc: 0.7430 - val_loss: 0.4783 - val_acc: 0.8077\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 665us/step - loss: 0.5261 - acc: 0.7380 - val_loss: 0.5376 - val_acc: 0.7217\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 495us/step - loss: 0.5734 - acc: 0.7013 - val_loss: 0.5439 - val_acc: 0.7245\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 505us/step - loss: 0.5181 - acc: 0.7498 - val_loss: 0.5005 - val_acc: 0.7733\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 742us/step - loss: 0.5459 - acc: 0.7247 - val_loss: 0.5202 - val_acc: 0.7408\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 675us/step - loss: 0.5144 - acc: 0.7512 - val_loss: 0.4942 - val_acc: 0.7700\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 661us/step - loss: 0.5683 - acc: 0.6961 - val_loss: 0.5283 - val_acc: 0.7364\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 616us/step - loss: 0.4907 - acc: 0.7808 - val_loss: 0.4644 - val_acc: 0.8052\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 636us/step - loss: 0.6130 - acc: 0.7002 - val_loss: 0.6399 - val_acc: 0.6572\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 651us/step - loss: 0.6492 - acc: 0.6404 - val_loss: 0.6211 - val_acc: 0.6596\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 586us/step - loss: 0.5916 - acc: 0.6854 - val_loss: 0.5922 - val_acc: 0.6842\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 466us/step - loss: 0.5946 - acc: 0.6989 - val_loss: 0.5939 - val_acc: 0.6967\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 675us/step - loss: 0.5951 - acc: 0.6954 - val_loss: 0.5465 - val_acc: 0.7404\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 528us/step - loss: 0.5698 - acc: 0.7033 - val_loss: 0.5558 - val_acc: 0.7231\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 645us/step - loss: 0.5821 - acc: 0.6898 - val_loss: 0.5697 - val_acc: 0.7071\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 544us/step - loss: 0.6034 - acc: 0.6624 - val_loss: 0.5557 - val_acc: 0.7103\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 533us/step - loss: 0.5619 - acc: 0.7095 - val_loss: 0.5605 - val_acc: 0.7166\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 621us/step - loss: 0.5626 - acc: 0.7120 - val_loss: 0.5643 - val_acc: 0.7138\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 512us/step - loss: 0.5678 - acc: 0.7173 - val_loss: 0.5567 - val_acc: 0.7308\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 598us/step - loss: 0.5554 - acc: 0.7231 - val_loss: 0.5464 - val_acc: 0.7397\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 487us/step - loss: 0.5800 - acc: 0.6990 - val_loss: 0.5496 - val_acc: 0.7332\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 496us/step - loss: 0.5895 - acc: 0.6911 - val_loss: 0.5625 - val_acc: 0.7072\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 675us/step - loss: 0.5856 - acc: 0.6927 - val_loss: 0.5420 - val_acc: 0.7397\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 828us/step - loss: 0.5480 - acc: 0.7338 - val_loss: 0.5564 - val_acc: 0.7221\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 587us/step - loss: 0.5644 - acc: 0.7223 - val_loss: 0.5615 - val_acc: 0.7121\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 575us/step - loss: 0.5901 - acc: 0.6866 - val_loss: 0.5234 - val_acc: 0.7585\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 617us/step - loss: 0.5675 - acc: 0.7152 - val_loss: 0.5727 - val_acc: 0.7079\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 749us/step - loss: 0.5603 - acc: 0.7195 - val_loss: 0.5586 - val_acc: 0.7154\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 626us/step - loss: 0.5560 - acc: 0.7198 - val_loss: 0.5532 - val_acc: 0.7281\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 645us/step - loss: 0.5064 - acc: 0.7660 - val_loss: 0.5096 - val_acc: 0.7644\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 649us/step - loss: 0.5900 - acc: 0.6940 - val_loss: 0.5401 - val_acc: 0.7323\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 635us/step - loss: 0.5316 - acc: 0.7445 - val_loss: 0.5108 - val_acc: 0.7535\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 685us/step - loss: 0.5576 - acc: 0.7179 - val_loss: 0.5332 - val_acc: 0.7437\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 614us/step - loss: 0.5388 - acc: 0.7268 - val_loss: 0.5374 - val_acc: 0.7308\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 565us/step - loss: 0.5999 - acc: 0.6658 - val_loss: 0.5732 - val_acc: 0.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 537us/step - loss: 0.5746 - acc: 0.6942 - val_loss: 0.5487 - val_acc: 0.7277\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 541us/step - loss: 0.5593 - acc: 0.7298 - val_loss: 0.5707 - val_acc: 0.7236\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 531us/step - loss: 0.5109 - acc: 0.7660 - val_loss: 0.5180 - val_acc: 0.7462\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 507us/step - loss: 0.5631 - acc: 0.7147 - val_loss: 0.5207 - val_acc: 0.7551\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 633us/step - loss: 0.5481 - acc: 0.7363 - val_loss: 0.5334 - val_acc: 0.7411\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 579us/step - loss: 0.5482 - acc: 0.7236 - val_loss: 0.5505 - val_acc: 0.7125\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 646us/step - loss: 0.5207 - acc: 0.7618 - val_loss: 0.5280 - val_acc: 0.7491\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 496us/step - loss: 0.5154 - acc: 0.7506 - val_loss: 0.5252 - val_acc: 0.7403\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 602us/step - loss: 0.5993 - acc: 0.6746 - val_loss: 0.5479 - val_acc: 0.7243\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 517us/step - loss: 0.5630 - acc: 0.7128 - val_loss: 0.5302 - val_acc: 0.7404\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 621us/step - loss: 0.5490 - acc: 0.7119 - val_loss: 0.5530 - val_acc: 0.7154\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 596us/step - loss: 0.5393 - acc: 0.7229 - val_loss: 0.5304 - val_acc: 0.7483\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 529us/step - loss: 0.5533 - acc: 0.7226 - val_loss: 0.5672 - val_acc: 0.7105\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 683us/step - loss: 0.6005 - acc: 0.6819 - val_loss: 0.5921 - val_acc: 0.6882\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 779us/step - loss: 0.5256 - acc: 0.7452 - val_loss: 0.5338 - val_acc: 0.7305\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 508us/step - loss: 0.5616 - acc: 0.7068 - val_loss: 0.5614 - val_acc: 0.7092\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 669us/step - loss: 0.5801 - acc: 0.7073 - val_loss: 0.5836 - val_acc: 0.6929\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 627us/step - loss: 0.5680 - acc: 0.7162 - val_loss: 0.5513 - val_acc: 0.7219\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 554us/step - loss: 0.5519 - acc: 0.7224 - val_loss: 0.5511 - val_acc: 0.7215\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 686us/step - loss: 0.5620 - acc: 0.7118 - val_loss: 0.5151 - val_acc: 0.7538\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 596us/step - loss: 0.5984 - acc: 0.6824 - val_loss: 0.5423 - val_acc: 0.7313\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 660us/step - loss: 0.5374 - acc: 0.7398 - val_loss: 0.5407 - val_acc: 0.7379\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 538us/step - loss: 0.5385 - acc: 0.7381 - val_loss: 0.5263 - val_acc: 0.7516\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.6013 - acc: 0.7046 - val_loss: 0.5993 - val_acc: 0.6986\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 639us/step - loss: 0.5681 - acc: 0.7173 - val_loss: 0.5597 - val_acc: 0.7206\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 573us/step - loss: 0.5608 - acc: 0.7144 - val_loss: 0.5505 - val_acc: 0.7231\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 585us/step - loss: 0.5256 - acc: 0.7461 - val_loss: 0.4877 - val_acc: 0.7795\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 506us/step - loss: 0.5355 - acc: 0.7478 - val_loss: 0.5334 - val_acc: 0.7436\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 611us/step - loss: 0.5703 - acc: 0.7022 - val_loss: 0.5216 - val_acc: 0.7527\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 591us/step - loss: 0.5519 - acc: 0.7276 - val_loss: 0.5263 - val_acc: 0.7474\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 635us/step - loss: 0.5530 - acc: 0.7359 - val_loss: 0.5551 - val_acc: 0.7249\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 537us/step - loss: 0.5698 - acc: 0.7021 - val_loss: 0.5196 - val_acc: 0.7551\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 681us/step - loss: 0.5202 - acc: 0.7496 - val_loss: 0.5050 - val_acc: 0.7558\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 545us/step - loss: 0.5766 - acc: 0.7097 - val_loss: 0.5368 - val_acc: 0.7393\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 834us/step - loss: 0.5699 - acc: 0.7034 - val_loss: 0.6322 - val_acc: 0.6512\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 486us/step - loss: 0.6192 - acc: 0.6551 - val_loss: 0.5902 - val_acc: 0.6863\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 546us/step - loss: 0.5861 - acc: 0.6861 - val_loss: 0.5737 - val_acc: 0.7001\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 507us/step - loss: 0.5656 - acc: 0.7126 - val_loss: 0.5565 - val_acc: 0.7181\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 684us/step - loss: 0.5343 - acc: 0.7310 - val_loss: 0.5271 - val_acc: 0.7397\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 496us/step - loss: 0.5905 - acc: 0.6911 - val_loss: 0.5631 - val_acc: 0.7068\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 683us/step - loss: 0.5832 - acc: 0.6947 - val_loss: 0.5686 - val_acc: 0.7070\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 478us/step - loss: 0.5530 - acc: 0.7170 - val_loss: 0.5238 - val_acc: 0.7460\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 574us/step - loss: 0.5628 - acc: 0.7018 - val_loss: 0.5067 - val_acc: 0.7609\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 573us/step - loss: 0.6078 - acc: 0.6455 - val_loss: 0.5456 - val_acc: 0.7296\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 657us/step - loss: 0.5998 - acc: 0.6872 - val_loss: 0.5831 - val_acc: 0.7075\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 541us/step - loss: 0.5482 - acc: 0.7253 - val_loss: 0.5293 - val_acc: 0.7527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 613us/step - loss: 0.5434 - acc: 0.7313 - val_loss: 0.5146 - val_acc: 0.7529\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.5581 - acc: 0.7231 - val_loss: 0.5418 - val_acc: 0.7337\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 644us/step - loss: 0.5146 - acc: 0.7474 - val_loss: 0.5059 - val_acc: 0.7560\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 499us/step - loss: 0.5555 - acc: 0.7225 - val_loss: 0.5256 - val_acc: 0.7508\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 612us/step - loss: 0.5662 - acc: 0.7188 - val_loss: 0.5579 - val_acc: 0.7312\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 618us/step - loss: 0.5636 - acc: 0.7049 - val_loss: 0.5317 - val_acc: 0.7288\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 554us/step - loss: 0.5705 - acc: 0.7055 - val_loss: 0.5344 - val_acc: 0.7418\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4941 - acc: 0.7746 - val_loss: 0.5309 - val_acc: 0.7342\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 525us/step - loss: 0.5350 - acc: 0.7438 - val_loss: 0.5141 - val_acc: 0.7532\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 599us/step - loss: 0.5095 - acc: 0.7628 - val_loss: 0.5192 - val_acc: 0.7397\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 651us/step - loss: 0.5195 - acc: 0.7523 - val_loss: 0.5303 - val_acc: 0.7493\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 524us/step - loss: 0.5241 - acc: 0.7443 - val_loss: 0.5351 - val_acc: 0.7360\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 668us/step - loss: 0.5052 - acc: 0.7659 - val_loss: 0.5602 - val_acc: 0.7029\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 545us/step - loss: 0.5746 - acc: 0.6983 - val_loss: 0.5204 - val_acc: 0.7356\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 555us/step - loss: 0.5635 - acc: 0.6959 - val_loss: 0.5368 - val_acc: 0.7338\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 649us/step - loss: 0.5262 - acc: 0.7258 - val_loss: 0.5129 - val_acc: 0.7508\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 578us/step - loss: 0.5424 - acc: 0.7214 - val_loss: 0.5369 - val_acc: 0.7363\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 567us/step - loss: 0.6294 - acc: 0.6494 - val_loss: 0.5821 - val_acc: 0.7093\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 696us/step - loss: 0.5683 - acc: 0.7171 - val_loss: 0.5542 - val_acc: 0.7228\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 603us/step - loss: 0.5629 - acc: 0.7086 - val_loss: 0.5150 - val_acc: 0.7478\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 591us/step - loss: 0.5486 - acc: 0.7165 - val_loss: 0.5405 - val_acc: 0.7304\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 579us/step - loss: 0.6565 - acc: 0.6301 - val_loss: 0.5997 - val_acc: 0.6819\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 636us/step - loss: 0.5306 - acc: 0.7384 - val_loss: 0.4976 - val_acc: 0.7683\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 590us/step - loss: 0.5885 - acc: 0.7038 - val_loss: 0.5791 - val_acc: 0.7072\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 490us/step - loss: 0.5373 - acc: 0.7384 - val_loss: 0.5446 - val_acc: 0.7371\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 698us/step - loss: 0.5560 - acc: 0.7280 - val_loss: 0.5228 - val_acc: 0.7509\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 595us/step - loss: 0.5358 - acc: 0.7328 - val_loss: 0.5553 - val_acc: 0.7271\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 732us/step - loss: 0.5372 - acc: 0.7286 - val_loss: 0.5435 - val_acc: 0.7279\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 618us/step - loss: 0.5862 - acc: 0.6842 - val_loss: 0.5851 - val_acc: 0.6886\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 527us/step - loss: 0.6002 - acc: 0.6676 - val_loss: 0.5095 - val_acc: 0.7628\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 553us/step - loss: 0.5576 - acc: 0.7108 - val_loss: 0.5110 - val_acc: 0.7631\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 576us/step - loss: 0.5835 - acc: 0.6705 - val_loss: 0.5118 - val_acc: 0.7602\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 498us/step - loss: 0.5536 - acc: 0.7225 - val_loss: 0.4950 - val_acc: 0.7792\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 659us/step - loss: 0.5302 - acc: 0.7364 - val_loss: 0.5206 - val_acc: 0.7493\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 477us/step - loss: 0.5847 - acc: 0.6877 - val_loss: 0.5210 - val_acc: 0.7482\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 644us/step - loss: 0.5314 - acc: 0.7328 - val_loss: 0.5142 - val_acc: 0.7499\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 513us/step - loss: 0.5316 - acc: 0.7360 - val_loss: 0.5355 - val_acc: 0.7345\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 654us/step - loss: 0.5896 - acc: 0.6885 - val_loss: 0.5512 - val_acc: 0.7194\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 586us/step - loss: 0.5606 - acc: 0.7041 - val_loss: 0.5554 - val_acc: 0.7162\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 675us/step - loss: 0.5034 - acc: 0.7564 - val_loss: 0.4668 - val_acc: 0.8085\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 619us/step - loss: 0.5163 - acc: 0.7486 - val_loss: 0.5233 - val_acc: 0.7313\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 488us/step - loss: 0.5650 - acc: 0.7110 - val_loss: 0.5269 - val_acc: 0.7348\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 490us/step - loss: 0.5168 - acc: 0.7485 - val_loss: 0.4887 - val_acc: 0.7801\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 765us/step - loss: 0.5324 - acc: 0.7358 - val_loss: 0.5036 - val_acc: 0.7576\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 661us/step - loss: 0.5072 - acc: 0.7542 - val_loss: 0.4821 - val_acc: 0.7743\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 681us/step - loss: 0.5613 - acc: 0.7041 - val_loss: 0.5136 - val_acc: 0.7450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 642us/step - loss: 0.4833 - acc: 0.7824 - val_loss: 0.4555 - val_acc: 0.8057\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 671us/step - loss: 0.5855 - acc: 0.7193 - val_loss: 0.6119 - val_acc: 0.6870\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 706us/step - loss: 0.6226 - acc: 0.6638 - val_loss: 0.5994 - val_acc: 0.6831\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 537us/step - loss: 0.5718 - acc: 0.7045 - val_loss: 0.5676 - val_acc: 0.7089\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 481us/step - loss: 0.5910 - acc: 0.7019 - val_loss: 0.5857 - val_acc: 0.6991\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 638us/step - loss: 0.5744 - acc: 0.7166 - val_loss: 0.5340 - val_acc: 0.7486\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 522us/step - loss: 0.5627 - acc: 0.7115 - val_loss: 0.5486 - val_acc: 0.7292\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 631us/step - loss: 0.5756 - acc: 0.7005 - val_loss: 0.5665 - val_acc: 0.7078\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 524us/step - loss: 0.5956 - acc: 0.6806 - val_loss: 0.5532 - val_acc: 0.7144\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 558us/step - loss: 0.5584 - acc: 0.7160 - val_loss: 0.5516 - val_acc: 0.7252\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 636us/step - loss: 0.5547 - acc: 0.7212 - val_loss: 0.5555 - val_acc: 0.7226\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 514us/step - loss: 0.5568 - acc: 0.7239 - val_loss: 0.5410 - val_acc: 0.7388\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 609us/step - loss: 0.5362 - acc: 0.7405 - val_loss: 0.5331 - val_acc: 0.7486\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 544us/step - loss: 0.5689 - acc: 0.7103 - val_loss: 0.5345 - val_acc: 0.7437\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 570us/step - loss: 0.5858 - acc: 0.6954 - val_loss: 0.5549 - val_acc: 0.7158\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 615us/step - loss: 0.5823 - acc: 0.6974 - val_loss: 0.5307 - val_acc: 0.7489\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 664us/step - loss: 0.5449 - acc: 0.7318 - val_loss: 0.5572 - val_acc: 0.7186\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 603us/step - loss: 0.5622 - acc: 0.7248 - val_loss: 0.5544 - val_acc: 0.7229\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 548us/step - loss: 0.5778 - acc: 0.7038 - val_loss: 0.5178 - val_acc: 0.7602\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 597us/step - loss: 0.5621 - acc: 0.7242 - val_loss: 0.5694 - val_acc: 0.7120\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 712us/step - loss: 0.5619 - acc: 0.7192 - val_loss: 0.5591 - val_acc: 0.7147\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 596us/step - loss: 0.5498 - acc: 0.7202 - val_loss: 0.5442 - val_acc: 0.7361\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 595us/step - loss: 0.5008 - acc: 0.7648 - val_loss: 0.4979 - val_acc: 0.7731\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 658us/step - loss: 0.5914 - acc: 0.6953 - val_loss: 0.5365 - val_acc: 0.7362\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 609us/step - loss: 0.5281 - acc: 0.7477 - val_loss: 0.5004 - val_acc: 0.7661\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 635us/step - loss: 0.5573 - acc: 0.7152 - val_loss: 0.5318 - val_acc: 0.7434\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 482us/step - loss: 0.5465 - acc: 0.7197 - val_loss: 0.5294 - val_acc: 0.7414\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 601us/step - loss: 0.5812 - acc: 0.6885 - val_loss: 0.5559 - val_acc: 0.7093\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 581us/step - loss: 0.5639 - acc: 0.7100 - val_loss: 0.5412 - val_acc: 0.7307\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 550us/step - loss: 0.5552 - acc: 0.7309 - val_loss: 0.5610 - val_acc: 0.7339\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 498us/step - loss: 0.5064 - acc: 0.7649 - val_loss: 0.5124 - val_acc: 0.7524\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 511us/step - loss: 0.5582 - acc: 0.7233 - val_loss: 0.5138 - val_acc: 0.7595\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 677us/step - loss: 0.5422 - acc: 0.7433 - val_loss: 0.5274 - val_acc: 0.7491\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 601us/step - loss: 0.5373 - acc: 0.7346 - val_loss: 0.5441 - val_acc: 0.7210\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 718us/step - loss: 0.5117 - acc: 0.7670 - val_loss: 0.5203 - val_acc: 0.7545\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 513us/step - loss: 0.5061 - acc: 0.7542 - val_loss: 0.5168 - val_acc: 0.7475\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 660us/step - loss: 0.5901 - acc: 0.6878 - val_loss: 0.5428 - val_acc: 0.7289\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 589us/step - loss: 0.5634 - acc: 0.7153 - val_loss: 0.5259 - val_acc: 0.7436\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 645us/step - loss: 0.5431 - acc: 0.7204 - val_loss: 0.5501 - val_acc: 0.7197\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 685us/step - loss: 0.5351 - acc: 0.7245 - val_loss: 0.5216 - val_acc: 0.7527\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 606us/step - loss: 0.5451 - acc: 0.7312 - val_loss: 0.5573 - val_acc: 0.7200\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 671us/step - loss: 0.5923 - acc: 0.6895 - val_loss: 0.5798 - val_acc: 0.7039\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 833us/step - loss: 0.5162 - acc: 0.7526 - val_loss: 0.5236 - val_acc: 0.7377\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 511us/step - loss: 0.5495 - acc: 0.7249 - val_loss: 0.5455 - val_acc: 0.7252\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 678us/step - loss: 0.5660 - acc: 0.7149 - val_loss: 0.5783 - val_acc: 0.6997\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 562us/step - loss: 0.5750 - acc: 0.7093 - val_loss: 0.5523 - val_acc: 0.7180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 547us/step - loss: 0.5536 - acc: 0.7220 - val_loss: 0.5441 - val_acc: 0.7266\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 680us/step - loss: 0.5623 - acc: 0.7089 - val_loss: 0.5079 - val_acc: 0.7548\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 616us/step - loss: 0.5918 - acc: 0.6890 - val_loss: 0.5347 - val_acc: 0.7370\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 656us/step - loss: 0.5295 - acc: 0.7475 - val_loss: 0.5298 - val_acc: 0.7446\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 509us/step - loss: 0.5277 - acc: 0.7450 - val_loss: 0.5175 - val_acc: 0.7554\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.5990 - acc: 0.7068 - val_loss: 0.5971 - val_acc: 0.7008\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 623us/step - loss: 0.5636 - acc: 0.7204 - val_loss: 0.5494 - val_acc: 0.7332\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 561us/step - loss: 0.5569 - acc: 0.7122 - val_loss: 0.5425 - val_acc: 0.7293\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 594us/step - loss: 0.5166 - acc: 0.7535 - val_loss: 0.4798 - val_acc: 0.7821\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 559us/step - loss: 0.5326 - acc: 0.7470 - val_loss: 0.5260 - val_acc: 0.7481\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 579us/step - loss: 0.5623 - acc: 0.7123 - val_loss: 0.5153 - val_acc: 0.7557\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 569us/step - loss: 0.5484 - acc: 0.7283 - val_loss: 0.5195 - val_acc: 0.7527\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 624us/step - loss: 0.5423 - acc: 0.7454 - val_loss: 0.5453 - val_acc: 0.7335\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 555us/step - loss: 0.5592 - acc: 0.7125 - val_loss: 0.5127 - val_acc: 0.7607\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 684us/step - loss: 0.5111 - acc: 0.7570 - val_loss: 0.4992 - val_acc: 0.7600\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 536us/step - loss: 0.5651 - acc: 0.7106 - val_loss: 0.5298 - val_acc: 0.7439\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 772us/step - loss: 0.5607 - acc: 0.7142 - val_loss: 0.6197 - val_acc: 0.6605\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 482us/step - loss: 0.6046 - acc: 0.6705 - val_loss: 0.5749 - val_acc: 0.6978\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 517us/step - loss: 0.5788 - acc: 0.6943 - val_loss: 0.5595 - val_acc: 0.7107\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 488us/step - loss: 0.5548 - acc: 0.7217 - val_loss: 0.5494 - val_acc: 0.7216\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 645us/step - loss: 0.5287 - acc: 0.7347 - val_loss: 0.5201 - val_acc: 0.7464\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 499us/step - loss: 0.5785 - acc: 0.7030 - val_loss: 0.5563 - val_acc: 0.7117\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 610us/step - loss: 0.5739 - acc: 0.7030 - val_loss: 0.5538 - val_acc: 0.7234\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 482us/step - loss: 0.5475 - acc: 0.7186 - val_loss: 0.5160 - val_acc: 0.7540\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 578us/step - loss: 0.5508 - acc: 0.7158 - val_loss: 0.4977 - val_acc: 0.7671\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 657us/step - loss: 0.6066 - acc: 0.6549 - val_loss: 0.5431 - val_acc: 0.7316\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 677us/step - loss: 0.5962 - acc: 0.6861 - val_loss: 0.5802 - val_acc: 0.7129\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 540us/step - loss: 0.5406 - acc: 0.7323 - val_loss: 0.5232 - val_acc: 0.7559\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 579us/step - loss: 0.5385 - acc: 0.7320 - val_loss: 0.5122 - val_acc: 0.7557\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.5560 - acc: 0.7236 - val_loss: 0.5352 - val_acc: 0.7401\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 634us/step - loss: 0.5123 - acc: 0.7501 - val_loss: 0.5024 - val_acc: 0.7615\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 482us/step - loss: 0.5475 - acc: 0.7322 - val_loss: 0.5209 - val_acc: 0.7554\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 578us/step - loss: 0.5570 - acc: 0.7247 - val_loss: 0.5528 - val_acc: 0.7345\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 549us/step - loss: 0.5575 - acc: 0.7115 - val_loss: 0.5262 - val_acc: 0.7326\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 577us/step - loss: 0.5647 - acc: 0.7079 - val_loss: 0.5279 - val_acc: 0.7458\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 688us/step - loss: 0.4976 - acc: 0.7691 - val_loss: 0.5280 - val_acc: 0.7343\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 563us/step - loss: 0.5347 - acc: 0.7393 - val_loss: 0.5080 - val_acc: 0.7582\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 588us/step - loss: 0.5037 - acc: 0.7616 - val_loss: 0.5113 - val_acc: 0.7465\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 646us/step - loss: 0.5155 - acc: 0.7477 - val_loss: 0.5258 - val_acc: 0.7516\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 640us/step - loss: 0.5158 - acc: 0.7504 - val_loss: 0.5297 - val_acc: 0.7378\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 661us/step - loss: 0.5029 - acc: 0.7676 - val_loss: 0.5552 - val_acc: 0.7046\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 541us/step - loss: 0.5688 - acc: 0.7061 - val_loss: 0.5136 - val_acc: 0.7392\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 595us/step - loss: 0.5576 - acc: 0.7006 - val_loss: 0.5321 - val_acc: 0.7370\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 558us/step - loss: 0.5204 - acc: 0.7336 - val_loss: 0.5049 - val_acc: 0.7542\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 546us/step - loss: 0.5375 - acc: 0.7207 - val_loss: 0.5280 - val_acc: 0.7429\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 475us/step - loss: 0.6264 - acc: 0.6585 - val_loss: 0.5808 - val_acc: 0.7115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 636us/step - loss: 0.5625 - acc: 0.7176 - val_loss: 0.5486 - val_acc: 0.7248\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 580us/step - loss: 0.5623 - acc: 0.7093 - val_loss: 0.5095 - val_acc: 0.7518\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 592us/step - loss: 0.5353 - acc: 0.7313 - val_loss: 0.5301 - val_acc: 0.7389\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 536us/step - loss: 0.6593 - acc: 0.6304 - val_loss: 0.5986 - val_acc: 0.6879\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.5193 - acc: 0.7451 - val_loss: 0.4925 - val_acc: 0.7717\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 641us/step - loss: 0.5924 - acc: 0.7049 - val_loss: 0.5735 - val_acc: 0.7115\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 497us/step - loss: 0.5296 - acc: 0.7450 - val_loss: 0.5407 - val_acc: 0.7405\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 614us/step - loss: 0.5488 - acc: 0.7327 - val_loss: 0.5205 - val_acc: 0.7513\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 552us/step - loss: 0.5368 - acc: 0.7359 - val_loss: 0.5503 - val_acc: 0.7280\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 671us/step - loss: 0.5337 - acc: 0.7332 - val_loss: 0.5359 - val_acc: 0.7330\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 573us/step - loss: 0.5799 - acc: 0.6909 - val_loss: 0.5766 - val_acc: 0.6974\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 529us/step - loss: 0.5852 - acc: 0.6871 - val_loss: 0.5031 - val_acc: 0.7663\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 530us/step - loss: 0.5594 - acc: 0.7122 - val_loss: 0.5056 - val_acc: 0.7659\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 564us/step - loss: 0.5759 - acc: 0.6814 - val_loss: 0.5050 - val_acc: 0.7662\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 484us/step - loss: 0.5436 - acc: 0.7343 - val_loss: 0.4851 - val_acc: 0.7887\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 691us/step - loss: 0.5180 - acc: 0.7505 - val_loss: 0.5075 - val_acc: 0.7583\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 492us/step - loss: 0.5816 - acc: 0.6923 - val_loss: 0.5134 - val_acc: 0.7539\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 620us/step - loss: 0.5262 - acc: 0.7397 - val_loss: 0.5067 - val_acc: 0.7573\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 503us/step - loss: 0.5218 - acc: 0.7464 - val_loss: 0.5260 - val_acc: 0.7410\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 631us/step - loss: 0.5659 - acc: 0.7051 - val_loss: 0.5247 - val_acc: 0.7403\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 620us/step - loss: 0.5536 - acc: 0.7065 - val_loss: 0.5473 - val_acc: 0.7189\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 783us/step - loss: 0.4942 - acc: 0.7622 - val_loss: 0.4632 - val_acc: 0.8070\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 624us/step - loss: 0.5066 - acc: 0.7541 - val_loss: 0.5179 - val_acc: 0.7375\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 480us/step - loss: 0.5620 - acc: 0.7171 - val_loss: 0.5251 - val_acc: 0.7395\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 490us/step - loss: 0.5043 - acc: 0.7604 - val_loss: 0.4836 - val_acc: 0.7837\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 759us/step - loss: 0.5275 - acc: 0.7358 - val_loss: 0.4998 - val_acc: 0.7547\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 684us/step - loss: 0.4975 - acc: 0.7640 - val_loss: 0.4760 - val_acc: 0.7796\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 646us/step - loss: 0.5515 - acc: 0.7126 - val_loss: 0.5044 - val_acc: 0.7546\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 626us/step - loss: 0.4794 - acc: 0.7839 - val_loss: 0.4502 - val_acc: 0.8098\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 633us/step - loss: 0.5826 - acc: 0.7274 - val_loss: 0.6004 - val_acc: 0.6990\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 626us/step - loss: 0.6234 - acc: 0.6629 - val_loss: 0.5967 - val_acc: 0.6895\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 548us/step - loss: 0.5633 - acc: 0.7118 - val_loss: 0.5639 - val_acc: 0.7118\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 481us/step - loss: 0.5855 - acc: 0.7069 - val_loss: 0.5831 - val_acc: 0.7024\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 667us/step - loss: 0.5758 - acc: 0.7164 - val_loss: 0.5333 - val_acc: 0.7523\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 557us/step - loss: 0.5524 - acc: 0.7212 - val_loss: 0.5447 - val_acc: 0.7301\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 758us/step - loss: 0.5712 - acc: 0.7033 - val_loss: 0.5559 - val_acc: 0.7228\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 516us/step - loss: 0.5777 - acc: 0.6980 - val_loss: 0.5443 - val_acc: 0.7236\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 514us/step - loss: 0.5485 - acc: 0.7259 - val_loss: 0.5492 - val_acc: 0.7246\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 663us/step - loss: 0.5502 - acc: 0.7271 - val_loss: 0.5508 - val_acc: 0.7272\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 500us/step - loss: 0.5517 - acc: 0.7243 - val_loss: 0.5396 - val_acc: 0.7413\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 574us/step - loss: 0.5370 - acc: 0.7370 - val_loss: 0.5296 - val_acc: 0.7515\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 527us/step - loss: 0.5690 - acc: 0.7117 - val_loss: 0.5336 - val_acc: 0.7456\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 486us/step - loss: 0.5760 - acc: 0.7068 - val_loss: 0.5512 - val_acc: 0.7221\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 581us/step - loss: 0.5830 - acc: 0.6977 - val_loss: 0.5251 - val_acc: 0.7509\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 649us/step - loss: 0.5349 - acc: 0.7371 - val_loss: 0.5488 - val_acc: 0.7275\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 608us/step - loss: 0.5654 - acc: 0.7199 - val_loss: 0.5508 - val_acc: 0.7250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 607us/step - loss: 0.5789 - acc: 0.6987 - val_loss: 0.5141 - val_acc: 0.7649\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 744us/step - loss: 0.5567 - acc: 0.7244 - val_loss: 0.5638 - val_acc: 0.7188\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 728us/step - loss: 0.5527 - acc: 0.7242 - val_loss: 0.5460 - val_acc: 0.7279\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 639us/step - loss: 0.5396 - acc: 0.7335 - val_loss: 0.5367 - val_acc: 0.7379\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 600us/step - loss: 0.4841 - acc: 0.7847 - val_loss: 0.4945 - val_acc: 0.7740\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 623us/step - loss: 0.5847 - acc: 0.7009 - val_loss: 0.5271 - val_acc: 0.7382\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 567us/step - loss: 0.5173 - acc: 0.7502 - val_loss: 0.5013 - val_acc: 0.7575\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 666us/step - loss: 0.5414 - acc: 0.7330 - val_loss: 0.5220 - val_acc: 0.7479\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 486us/step - loss: 0.5337 - acc: 0.7254 - val_loss: 0.5211 - val_acc: 0.7500\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 646us/step - loss: 0.5891 - acc: 0.6817 - val_loss: 0.5609 - val_acc: 0.7046\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 596us/step - loss: 0.5590 - acc: 0.7113 - val_loss: 0.5365 - val_acc: 0.7338\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 604us/step - loss: 0.5444 - acc: 0.7359 - val_loss: 0.5498 - val_acc: 0.7396\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 528us/step - loss: 0.4994 - acc: 0.7710 - val_loss: 0.5046 - val_acc: 0.7571\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 496us/step - loss: 0.5534 - acc: 0.7239 - val_loss: 0.5073 - val_acc: 0.7640\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 642us/step - loss: 0.5350 - acc: 0.7487 - val_loss: 0.5202 - val_acc: 0.7513\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 629us/step - loss: 0.5293 - acc: 0.7414 - val_loss: 0.5408 - val_acc: 0.7257\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 669us/step - loss: 0.5082 - acc: 0.7701 - val_loss: 0.5186 - val_acc: 0.7534\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 536us/step - loss: 0.4979 - acc: 0.7600 - val_loss: 0.5105 - val_acc: 0.7524\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 634us/step - loss: 0.5921 - acc: 0.6899 - val_loss: 0.5340 - val_acc: 0.7349\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 482us/step - loss: 0.5580 - acc: 0.7179 - val_loss: 0.5174 - val_acc: 0.7527\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 600us/step - loss: 0.5460 - acc: 0.7149 - val_loss: 0.5456 - val_acc: 0.7235\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 634us/step - loss: 0.5304 - acc: 0.7285 - val_loss: 0.5150 - val_acc: 0.7561\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 519us/step - loss: 0.5450 - acc: 0.7315 - val_loss: 0.5531 - val_acc: 0.7230\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 622us/step - loss: 0.5805 - acc: 0.7038 - val_loss: 0.5687 - val_acc: 0.7155\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 791us/step - loss: 0.5057 - acc: 0.7626 - val_loss: 0.5168 - val_acc: 0.7405\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 505us/step - loss: 0.5406 - acc: 0.7308 - val_loss: 0.5438 - val_acc: 0.7279\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 691us/step - loss: 0.5637 - acc: 0.7201 - val_loss: 0.5763 - val_acc: 0.7031\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 625us/step - loss: 0.5615 - acc: 0.7231 - val_loss: 0.5476 - val_acc: 0.7199\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 546us/step - loss: 0.5415 - acc: 0.7276 - val_loss: 0.5372 - val_acc: 0.7304\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 612us/step - loss: 0.5527 - acc: 0.7180 - val_loss: 0.5080 - val_acc: 0.7552\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 637us/step - loss: 0.5922 - acc: 0.6916 - val_loss: 0.5277 - val_acc: 0.7421\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 680us/step - loss: 0.5254 - acc: 0.7452 - val_loss: 0.5237 - val_acc: 0.7505\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 548us/step - loss: 0.5173 - acc: 0.7531 - val_loss: 0.5086 - val_acc: 0.7590\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.5930 - acc: 0.7078 - val_loss: 0.5907 - val_acc: 0.7049\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 628us/step - loss: 0.5641 - acc: 0.7174 - val_loss: 0.5481 - val_acc: 0.7362\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 548us/step - loss: 0.5484 - acc: 0.7224 - val_loss: 0.5353 - val_acc: 0.7359\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 616us/step - loss: 0.5113 - acc: 0.7555 - val_loss: 0.4761 - val_acc: 0.7820\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 505us/step - loss: 0.5224 - acc: 0.7566 - val_loss: 0.5207 - val_acc: 0.7530\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 565us/step - loss: 0.5626 - acc: 0.7100 - val_loss: 0.5119 - val_acc: 0.7566\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 549us/step - loss: 0.5468 - acc: 0.7310 - val_loss: 0.5180 - val_acc: 0.7513\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 624us/step - loss: 0.5408 - acc: 0.7444 - val_loss: 0.5415 - val_acc: 0.7360\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 634us/step - loss: 0.5551 - acc: 0.7150 - val_loss: 0.5112 - val_acc: 0.7587\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 624us/step - loss: 0.5089 - acc: 0.7590 - val_loss: 0.4955 - val_acc: 0.7608\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 523us/step - loss: 0.5535 - acc: 0.7239 - val_loss: 0.5210 - val_acc: 0.7487\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 704us/step - loss: 0.5505 - acc: 0.7199 - val_loss: 0.6107 - val_acc: 0.6682\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 472us/step - loss: 0.6007 - acc: 0.6730 - val_loss: 0.5685 - val_acc: 0.7038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 508us/step - loss: 0.5550 - acc: 0.7141 - val_loss: 0.5533 - val_acc: 0.7164\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 522us/step - loss: 0.5469 - acc: 0.7259 - val_loss: 0.5438 - val_acc: 0.7247\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 622us/step - loss: 0.5268 - acc: 0.7373 - val_loss: 0.5176 - val_acc: 0.7463\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 501us/step - loss: 0.5804 - acc: 0.7002 - val_loss: 0.5478 - val_acc: 0.7214\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 611us/step - loss: 0.5669 - acc: 0.7111 - val_loss: 0.5440 - val_acc: 0.7314\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 462us/step - loss: 0.5425 - acc: 0.7242 - val_loss: 0.5097 - val_acc: 0.7591\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 549us/step - loss: 0.5465 - acc: 0.7200 - val_loss: 0.4876 - val_acc: 0.7781\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 586us/step - loss: 0.5840 - acc: 0.6763 - val_loss: 0.5249 - val_acc: 0.7409\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 611us/step - loss: 0.5844 - acc: 0.6981 - val_loss: 0.5638 - val_acc: 0.7269\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 593us/step - loss: 0.5290 - acc: 0.7472 - val_loss: 0.5117 - val_acc: 0.7603\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 634us/step - loss: 0.5240 - acc: 0.7428 - val_loss: 0.5022 - val_acc: 0.7636\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.5464 - acc: 0.7308 - val_loss: 0.5275 - val_acc: 0.7453\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 652us/step - loss: 0.5018 - acc: 0.7567 - val_loss: 0.4957 - val_acc: 0.7695\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 521us/step - loss: 0.5448 - acc: 0.7322 - val_loss: 0.5163 - val_acc: 0.7579\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 656us/step - loss: 0.5533 - acc: 0.7284 - val_loss: 0.5467 - val_acc: 0.7378\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 617us/step - loss: 0.5506 - acc: 0.7180 - val_loss: 0.5157 - val_acc: 0.7413\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 524us/step - loss: 0.5572 - acc: 0.7238 - val_loss: 0.5244 - val_acc: 0.7495\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 691us/step - loss: 0.4910 - acc: 0.7675 - val_loss: 0.5180 - val_acc: 0.7457\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 550us/step - loss: 0.5238 - acc: 0.7497 - val_loss: 0.5037 - val_acc: 0.7614\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 612us/step - loss: 0.5023 - acc: 0.7654 - val_loss: 0.5045 - val_acc: 0.7541\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 667us/step - loss: 0.5110 - acc: 0.7477 - val_loss: 0.5232 - val_acc: 0.7517\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 495us/step - loss: 0.5176 - acc: 0.7487 - val_loss: 0.5269 - val_acc: 0.7388\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 721us/step - loss: 0.4945 - acc: 0.7688 - val_loss: 0.5482 - val_acc: 0.7130\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 576us/step - loss: 0.5659 - acc: 0.7089 - val_loss: 0.5062 - val_acc: 0.7483\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 503us/step - loss: 0.5511 - acc: 0.7101 - val_loss: 0.5281 - val_acc: 0.7397\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 631us/step - loss: 0.5145 - acc: 0.7442 - val_loss: 0.4997 - val_acc: 0.7595\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 581us/step - loss: 0.5297 - acc: 0.7299 - val_loss: 0.5201 - val_acc: 0.7486\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 523us/step - loss: 0.6230 - acc: 0.6602 - val_loss: 0.5753 - val_acc: 0.7160\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 656us/step - loss: 0.5574 - acc: 0.7202 - val_loss: 0.5457 - val_acc: 0.7268\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 578us/step - loss: 0.5561 - acc: 0.7196 - val_loss: 0.5044 - val_acc: 0.7544\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 575us/step - loss: 0.5355 - acc: 0.7357 - val_loss: 0.5305 - val_acc: 0.7372\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 538us/step - loss: 0.6530 - acc: 0.6391 - val_loss: 0.5902 - val_acc: 0.6952\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 629us/step - loss: 0.5261 - acc: 0.7425 - val_loss: 0.4886 - val_acc: 0.7753\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 575us/step - loss: 0.5883 - acc: 0.7061 - val_loss: 0.5721 - val_acc: 0.7141\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 497us/step - loss: 0.5296 - acc: 0.7479 - val_loss: 0.5364 - val_acc: 0.7438\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 616us/step - loss: 0.5482 - acc: 0.7329 - val_loss: 0.5173 - val_acc: 0.7540\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 501us/step - loss: 0.5334 - acc: 0.7374 - val_loss: 0.5458 - val_acc: 0.7306\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 673us/step - loss: 0.5256 - acc: 0.7428 - val_loss: 0.5305 - val_acc: 0.7361\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 564us/step - loss: 0.5732 - acc: 0.6970 - val_loss: 0.5698 - val_acc: 0.7022\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 550us/step - loss: 0.5853 - acc: 0.6872 - val_loss: 0.4998 - val_acc: 0.7650\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 581us/step - loss: 0.5504 - acc: 0.7201 - val_loss: 0.5018 - val_acc: 0.7672\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 521us/step - loss: 0.5719 - acc: 0.6837 - val_loss: 0.5015 - val_acc: 0.7686\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 520us/step - loss: 0.5392 - acc: 0.7356 - val_loss: 0.4803 - val_acc: 0.7896\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 649us/step - loss: 0.5082 - acc: 0.7584 - val_loss: 0.5017 - val_acc: 0.7599\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 507us/step - loss: 0.5762 - acc: 0.6958 - val_loss: 0.5094 - val_acc: 0.7564\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 657us/step - loss: 0.5216 - acc: 0.7428 - val_loss: 0.5016 - val_acc: 0.7621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 493us/step - loss: 0.5193 - acc: 0.7441 - val_loss: 0.5207 - val_acc: 0.7462\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 660us/step - loss: 0.5589 - acc: 0.7082 - val_loss: 0.5127 - val_acc: 0.7503\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 644us/step - loss: 0.5453 - acc: 0.7154 - val_loss: 0.5427 - val_acc: 0.7221\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 693us/step - loss: 0.4873 - acc: 0.7744 - val_loss: 0.4592 - val_acc: 0.8076\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 635us/step - loss: 0.5097 - acc: 0.7532 - val_loss: 0.5155 - val_acc: 0.7387\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 492us/step - loss: 0.5558 - acc: 0.7155 - val_loss: 0.5237 - val_acc: 0.7414\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 483us/step - loss: 0.5004 - acc: 0.7626 - val_loss: 0.4782 - val_acc: 0.7892\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 759us/step - loss: 0.5185 - acc: 0.7394 - val_loss: 0.4960 - val_acc: 0.7618\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 687us/step - loss: 0.4936 - acc: 0.7634 - val_loss: 0.4682 - val_acc: 0.7851\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 693us/step - loss: 0.5563 - acc: 0.7126 - val_loss: 0.5041 - val_acc: 0.7537\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 631us/step - loss: 0.4690 - acc: 0.7936 - val_loss: 0.4415 - val_acc: 0.8111\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 655us/step - loss: 0.5686 - acc: 0.7321 - val_loss: 0.5915 - val_acc: 0.7069\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 628us/step - loss: 0.6186 - acc: 0.6698 - val_loss: 0.5907 - val_acc: 0.6964\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 571us/step - loss: 0.5632 - acc: 0.7112 - val_loss: 0.5528 - val_acc: 0.7264\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 476us/step - loss: 0.5800 - acc: 0.7133 - val_loss: 0.5789 - val_acc: 0.7032\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 790us/step - loss: 0.5666 - acc: 0.7282 - val_loss: 0.5236 - val_acc: 0.7595\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 521us/step - loss: 0.5442 - acc: 0.7311 - val_loss: 0.5358 - val_acc: 0.7363\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 645us/step - loss: 0.5684 - acc: 0.7071 - val_loss: 0.5510 - val_acc: 0.7243\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 502us/step - loss: 0.5843 - acc: 0.6911 - val_loss: 0.5426 - val_acc: 0.7255\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 539us/step - loss: 0.5454 - acc: 0.7272 - val_loss: 0.5421 - val_acc: 0.7329\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 663us/step - loss: 0.5446 - acc: 0.7284 - val_loss: 0.5492 - val_acc: 0.7308\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 517us/step - loss: 0.5528 - acc: 0.7230 - val_loss: 0.5350 - val_acc: 0.7466\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 625us/step - loss: 0.5299 - acc: 0.7442 - val_loss: 0.5243 - val_acc: 0.7548\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 538us/step - loss: 0.5557 - acc: 0.7239 - val_loss: 0.5229 - val_acc: 0.7537\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 492us/step - loss: 0.5707 - acc: 0.7111 - val_loss: 0.5455 - val_acc: 0.7257\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 672us/step - loss: 0.5728 - acc: 0.7079 - val_loss: 0.5169 - val_acc: 0.7552\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 661us/step - loss: 0.5308 - acc: 0.7435 - val_loss: 0.5413 - val_acc: 0.7344\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 610us/step - loss: 0.5598 - acc: 0.7198 - val_loss: 0.5489 - val_acc: 0.7276\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 587us/step - loss: 0.5856 - acc: 0.6908 - val_loss: 0.5114 - val_acc: 0.7650\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 611us/step - loss: 0.5545 - acc: 0.7244 - val_loss: 0.5600 - val_acc: 0.7211\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 778us/step - loss: 0.5523 - acc: 0.7245 - val_loss: 0.5418 - val_acc: 0.7325\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 580us/step - loss: 0.5426 - acc: 0.7286 - val_loss: 0.5337 - val_acc: 0.7428\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 679us/step - loss: 0.4867 - acc: 0.7730 - val_loss: 0.4858 - val_acc: 0.7752\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 619us/step - loss: 0.5833 - acc: 0.7014 - val_loss: 0.5262 - val_acc: 0.7370\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 595us/step - loss: 0.5182 - acc: 0.7462 - val_loss: 0.4998 - val_acc: 0.7572\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 717us/step - loss: 0.5341 - acc: 0.7361 - val_loss: 0.5146 - val_acc: 0.7539\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 481us/step - loss: 0.5286 - acc: 0.7314 - val_loss: 0.5167 - val_acc: 0.7540\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 662us/step - loss: 0.5805 - acc: 0.6897 - val_loss: 0.5618 - val_acc: 0.7032\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 664us/step - loss: 0.5606 - acc: 0.7099 - val_loss: 0.5382 - val_acc: 0.7317\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 616us/step - loss: 0.5464 - acc: 0.7389 - val_loss: 0.5481 - val_acc: 0.7402\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 527us/step - loss: 0.4954 - acc: 0.7736 - val_loss: 0.5015 - val_acc: 0.7607\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 501us/step - loss: 0.5474 - acc: 0.7255 - val_loss: 0.5057 - val_acc: 0.7665\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 712us/step - loss: 0.5294 - acc: 0.7532 - val_loss: 0.5106 - val_acc: 0.7593\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 600us/step - loss: 0.5248 - acc: 0.7459 - val_loss: 0.5379 - val_acc: 0.7283\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 684us/step - loss: 0.5031 - acc: 0.7741 - val_loss: 0.5137 - val_acc: 0.7566\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 514us/step - loss: 0.4967 - acc: 0.7599 - val_loss: 0.5068 - val_acc: 0.7559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 674us/step - loss: 0.5841 - acc: 0.6913 - val_loss: 0.5279 - val_acc: 0.7370\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 508us/step - loss: 0.5482 - acc: 0.7292 - val_loss: 0.5114 - val_acc: 0.7565\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 632us/step - loss: 0.5461 - acc: 0.7121 - val_loss: 0.5408 - val_acc: 0.7260\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 686us/step - loss: 0.5283 - acc: 0.7287 - val_loss: 0.5063 - val_acc: 0.7623\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 509us/step - loss: 0.5311 - acc: 0.7380 - val_loss: 0.5394 - val_acc: 0.7329\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 714us/step - loss: 0.5679 - acc: 0.7150 - val_loss: 0.5582 - val_acc: 0.7253\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 932us/step - loss: 0.4977 - acc: 0.7688 - val_loss: 0.5122 - val_acc: 0.7437\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 510us/step - loss: 0.5353 - acc: 0.7316 - val_loss: 0.5351 - val_acc: 0.7343\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 687us/step - loss: 0.5579 - acc: 0.7211 - val_loss: 0.5718 - val_acc: 0.7076\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 592us/step - loss: 0.5519 - acc: 0.7301 - val_loss: 0.5402 - val_acc: 0.7266\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 593us/step - loss: 0.5359 - acc: 0.7340 - val_loss: 0.5295 - val_acc: 0.7369\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 707us/step - loss: 0.5499 - acc: 0.7171 - val_loss: 0.5010 - val_acc: 0.7590\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 582us/step - loss: 0.5909 - acc: 0.6942 - val_loss: 0.5232 - val_acc: 0.7439\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 659us/step - loss: 0.5177 - acc: 0.7532 - val_loss: 0.5177 - val_acc: 0.7548\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 509us/step - loss: 0.5153 - acc: 0.7535 - val_loss: 0.5040 - val_acc: 0.7621\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.5838 - acc: 0.7133 - val_loss: 0.5865 - val_acc: 0.7082\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 629us/step - loss: 0.5657 - acc: 0.7177 - val_loss: 0.5440 - val_acc: 0.7367\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 542us/step - loss: 0.5441 - acc: 0.7216 - val_loss: 0.5314 - val_acc: 0.7399\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 560us/step - loss: 0.5076 - acc: 0.7545 - val_loss: 0.4702 - val_acc: 0.7867\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 517us/step - loss: 0.5204 - acc: 0.7545 - val_loss: 0.5180 - val_acc: 0.7574\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 581us/step - loss: 0.5601 - acc: 0.7149 - val_loss: 0.5063 - val_acc: 0.7583\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 576us/step - loss: 0.5403 - acc: 0.7375 - val_loss: 0.5154 - val_acc: 0.7537\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 623us/step - loss: 0.5329 - acc: 0.7489 - val_loss: 0.5339 - val_acc: 0.7433\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 561us/step - loss: 0.5450 - acc: 0.7234 - val_loss: 0.4999 - val_acc: 0.7676\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 627us/step - loss: 0.4982 - acc: 0.7668 - val_loss: 0.4896 - val_acc: 0.7644\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 514us/step - loss: 0.5504 - acc: 0.7259 - val_loss: 0.5152 - val_acc: 0.7530\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 749us/step - loss: 0.5471 - acc: 0.7266 - val_loss: 0.6013 - val_acc: 0.6770\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 468us/step - loss: 0.5918 - acc: 0.6795 - val_loss: 0.5605 - val_acc: 0.7096\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 550us/step - loss: 0.5549 - acc: 0.7160 - val_loss: 0.5442 - val_acc: 0.7225\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 486us/step - loss: 0.5409 - acc: 0.7309 - val_loss: 0.5339 - val_acc: 0.7339\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 592us/step - loss: 0.5203 - acc: 0.7453 - val_loss: 0.5085 - val_acc: 0.7544\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 469us/step - loss: 0.5689 - acc: 0.7091 - val_loss: 0.5393 - val_acc: 0.7307\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 608us/step - loss: 0.5603 - acc: 0.7189 - val_loss: 0.5413 - val_acc: 0.7342\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 486us/step - loss: 0.5324 - acc: 0.7351 - val_loss: 0.5078 - val_acc: 0.7605\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 583us/step - loss: 0.5389 - acc: 0.7273 - val_loss: 0.4823 - val_acc: 0.7836\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 594us/step - loss: 0.5846 - acc: 0.6782 - val_loss: 0.5255 - val_acc: 0.7457\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 616us/step - loss: 0.5810 - acc: 0.7012 - val_loss: 0.5612 - val_acc: 0.7325\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 554us/step - loss: 0.5412 - acc: 0.7364 - val_loss: 0.5125 - val_acc: 0.7603\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 623us/step - loss: 0.5255 - acc: 0.7411 - val_loss: 0.4980 - val_acc: 0.7664\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.5444 - acc: 0.7345 - val_loss: 0.5213 - val_acc: 0.7506\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 735us/step - loss: 0.4959 - acc: 0.7604 - val_loss: 0.4903 - val_acc: 0.7749\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 521us/step - loss: 0.5378 - acc: 0.7362 - val_loss: 0.5120 - val_acc: 0.7602\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 652us/step - loss: 0.5451 - acc: 0.7292 - val_loss: 0.5389 - val_acc: 0.7427\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 603us/step - loss: 0.5513 - acc: 0.7151 - val_loss: 0.5111 - val_acc: 0.7451\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 497us/step - loss: 0.5579 - acc: 0.7220 - val_loss: 0.5224 - val_acc: 0.7498\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.4902 - acc: 0.7710 - val_loss: 0.5189 - val_acc: 0.7429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 522us/step - loss: 0.5203 - acc: 0.7533 - val_loss: 0.4999 - val_acc: 0.7656\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 621us/step - loss: 0.4963 - acc: 0.7709 - val_loss: 0.5011 - val_acc: 0.7568\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 689us/step - loss: 0.5097 - acc: 0.7566 - val_loss: 0.5211 - val_acc: 0.7538\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 531us/step - loss: 0.5101 - acc: 0.7563 - val_loss: 0.5277 - val_acc: 0.7359\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 698us/step - loss: 0.4943 - acc: 0.7689 - val_loss: 0.5506 - val_acc: 0.7089\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 572us/step - loss: 0.5632 - acc: 0.7082 - val_loss: 0.5016 - val_acc: 0.7513\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 527us/step - loss: 0.5514 - acc: 0.7085 - val_loss: 0.5261 - val_acc: 0.7413\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 639us/step - loss: 0.5116 - acc: 0.7474 - val_loss: 0.4965 - val_acc: 0.7602\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 625us/step - loss: 0.5289 - acc: 0.7322 - val_loss: 0.5200 - val_acc: 0.7492\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 577us/step - loss: 0.6186 - acc: 0.6662 - val_loss: 0.5776 - val_acc: 0.7133\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 689us/step - loss: 0.5555 - acc: 0.7184 - val_loss: 0.5409 - val_acc: 0.7311\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 576us/step - loss: 0.5489 - acc: 0.7239 - val_loss: 0.5021 - val_acc: 0.7560\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 634us/step - loss: 0.5312 - acc: 0.7418 - val_loss: 0.5253 - val_acc: 0.7388\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 544us/step - loss: 0.6558 - acc: 0.6393 - val_loss: 0.5887 - val_acc: 0.6984\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 686us/step - loss: 0.5155 - acc: 0.7494 - val_loss: 0.4864 - val_acc: 0.7767\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 617us/step - loss: 0.5829 - acc: 0.7080 - val_loss: 0.5713 - val_acc: 0.7128\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 542us/step - loss: 0.5235 - acc: 0.7499 - val_loss: 0.5338 - val_acc: 0.7437\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 662us/step - loss: 0.5421 - acc: 0.7363 - val_loss: 0.5158 - val_acc: 0.7545\n",
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 559us/step - loss: 0.5341 - acc: 0.7324 - val_loss: 0.5434 - val_acc: 0.7308\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 654us/step - loss: 0.5262 - acc: 0.7371 - val_loss: 0.5279 - val_acc: 0.7382\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 615us/step - loss: 0.5717 - acc: 0.7011 - val_loss: 0.5710 - val_acc: 0.7031\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 542us/step - loss: 0.5772 - acc: 0.6924 - val_loss: 0.4976 - val_acc: 0.7666\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 565us/step - loss: 0.5443 - acc: 0.7256 - val_loss: 0.5006 - val_acc: 0.7698\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 528us/step - loss: 0.5616 - acc: 0.6943 - val_loss: 0.5001 - val_acc: 0.7669\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 510us/step - loss: 0.5356 - acc: 0.7404 - val_loss: 0.4795 - val_acc: 0.7869\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 673us/step - loss: 0.5060 - acc: 0.7646 - val_loss: 0.4990 - val_acc: 0.7613\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 493us/step - loss: 0.5735 - acc: 0.6975 - val_loss: 0.5069 - val_acc: 0.7578\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 608us/step - loss: 0.5191 - acc: 0.7451 - val_loss: 0.5009 - val_acc: 0.7621\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 507us/step - loss: 0.5184 - acc: 0.7424 - val_loss: 0.5195 - val_acc: 0.7449\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 645us/step - loss: 0.5569 - acc: 0.7124 - val_loss: 0.5118 - val_acc: 0.7536\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 567us/step - loss: 0.5412 - acc: 0.7203 - val_loss: 0.5408 - val_acc: 0.7249\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 669us/step - loss: 0.4848 - acc: 0.7725 - val_loss: 0.4574 - val_acc: 0.8065\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 629us/step - loss: 0.4953 - acc: 0.7698 - val_loss: 0.5090 - val_acc: 0.7455\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 455us/step - loss: 0.5507 - acc: 0.7165 - val_loss: 0.5131 - val_acc: 0.7504\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 496us/step - loss: 0.4974 - acc: 0.7675 - val_loss: 0.4733 - val_acc: 0.7941\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 791us/step - loss: 0.5146 - acc: 0.7466 - val_loss: 0.4898 - val_acc: 0.7666\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 663us/step - loss: 0.4905 - acc: 0.7583 - val_loss: 0.4656 - val_acc: 0.7866\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 680us/step - loss: 0.5473 - acc: 0.7210 - val_loss: 0.4971 - val_acc: 0.7615\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 647us/step - loss: 0.4663 - acc: 0.7934 - val_loss: 0.4429 - val_acc: 0.8031\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 659us/step - loss: 0.5615 - acc: 0.7418 - val_loss: 0.5835 - val_acc: 0.7134\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 664us/step - loss: 0.6182 - acc: 0.6720 - val_loss: 0.5912 - val_acc: 0.6990\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 583us/step - loss: 0.5567 - acc: 0.7183 - val_loss: 0.5543 - val_acc: 0.7266\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 479us/step - loss: 0.5796 - acc: 0.7164 - val_loss: 0.5745 - val_acc: 0.7076\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 664us/step - loss: 0.5677 - acc: 0.7240 - val_loss: 0.5243 - val_acc: 0.7591\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 516us/step - loss: 0.5423 - acc: 0.7294 - val_loss: 0.5343 - val_acc: 0.7376\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 697us/step - loss: 0.5637 - acc: 0.7113 - val_loss: 0.5452 - val_acc: 0.7319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 503us/step - loss: 0.5728 - acc: 0.7057 - val_loss: 0.5397 - val_acc: 0.7295\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 550us/step - loss: 0.5426 - acc: 0.7313 - val_loss: 0.5398 - val_acc: 0.7314\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 700us/step - loss: 0.5422 - acc: 0.7315 - val_loss: 0.5452 - val_acc: 0.7343\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 545us/step - loss: 0.5449 - acc: 0.7319 - val_loss: 0.5320 - val_acc: 0.7484\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 702us/step - loss: 0.5225 - acc: 0.7516 - val_loss: 0.5210 - val_acc: 0.7565\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 495us/step - loss: 0.5614 - acc: 0.7195 - val_loss: 0.5194 - val_acc: 0.7556\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 494us/step - loss: 0.5714 - acc: 0.7113 - val_loss: 0.5420 - val_acc: 0.7316\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 596us/step - loss: 0.5774 - acc: 0.7026 - val_loss: 0.5131 - val_acc: 0.7583\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.5296 - acc: 0.7438 - val_loss: 0.5397 - val_acc: 0.7351\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 623us/step - loss: 0.5590 - acc: 0.7276 - val_loss: 0.5466 - val_acc: 0.7292\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 570us/step - loss: 0.5861 - acc: 0.6924 - val_loss: 0.5111 - val_acc: 0.7640\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 667us/step - loss: 0.5567 - acc: 0.7265 - val_loss: 0.5551 - val_acc: 0.7232\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 831us/step - loss: 0.5499 - acc: 0.7245 - val_loss: 0.5357 - val_acc: 0.7377\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 641us/step - loss: 0.5396 - acc: 0.7326 - val_loss: 0.5231 - val_acc: 0.7536\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 625us/step - loss: 0.4809 - acc: 0.7763 - val_loss: 0.4726 - val_acc: 0.7887\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 624us/step - loss: 0.5815 - acc: 0.6991 - val_loss: 0.5183 - val_acc: 0.7443\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 576us/step - loss: 0.5145 - acc: 0.7526 - val_loss: 0.4926 - val_acc: 0.7636\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 693us/step - loss: 0.5360 - acc: 0.7366 - val_loss: 0.5164 - val_acc: 0.7530\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 500us/step - loss: 0.5311 - acc: 0.7275 - val_loss: 0.5119 - val_acc: 0.7595\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 561us/step - loss: 0.5787 - acc: 0.6919 - val_loss: 0.5517 - val_acc: 0.7143\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 562us/step - loss: 0.5611 - acc: 0.7084 - val_loss: 0.5352 - val_acc: 0.7361\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 550us/step - loss: 0.5437 - acc: 0.7418 - val_loss: 0.5467 - val_acc: 0.7428\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 531us/step - loss: 0.4929 - acc: 0.7746 - val_loss: 0.4982 - val_acc: 0.7639\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 520us/step - loss: 0.5407 - acc: 0.7328 - val_loss: 0.5036 - val_acc: 0.7677\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 655us/step - loss: 0.5291 - acc: 0.7522 - val_loss: 0.5058 - val_acc: 0.7636\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 657us/step - loss: 0.5229 - acc: 0.7469 - val_loss: 0.5352 - val_acc: 0.7314\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 734us/step - loss: 0.4977 - acc: 0.7793 - val_loss: 0.5055 - val_acc: 0.7617\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 599us/step - loss: 0.4960 - acc: 0.7602 - val_loss: 0.5044 - val_acc: 0.7564\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 634us/step - loss: 0.5777 - acc: 0.6992 - val_loss: 0.5247 - val_acc: 0.7429\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 533us/step - loss: 0.5461 - acc: 0.7282 - val_loss: 0.5095 - val_acc: 0.7609\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 658us/step - loss: 0.5414 - acc: 0.7193 - val_loss: 0.5394 - val_acc: 0.7312\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 776us/step - loss: 0.5224 - acc: 0.7345 - val_loss: 0.5034 - val_acc: 0.7649\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 550us/step - loss: 0.5333 - acc: 0.7384 - val_loss: 0.5382 - val_acc: 0.7361\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 682us/step - loss: 0.5656 - acc: 0.7199 - val_loss: 0.5544 - val_acc: 0.7283\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 842us/step - loss: 0.4903 - acc: 0.7719 - val_loss: 0.5063 - val_acc: 0.7495\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 551us/step - loss: 0.5302 - acc: 0.7408 - val_loss: 0.5302 - val_acc: 0.7390\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 647us/step - loss: 0.5518 - acc: 0.7254 - val_loss: 0.5666 - val_acc: 0.7115\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 641us/step - loss: 0.5491 - acc: 0.7339 - val_loss: 0.5366 - val_acc: 0.7303\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 543us/step - loss: 0.5373 - acc: 0.7324 - val_loss: 0.5279 - val_acc: 0.7367\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 641us/step - loss: 0.5418 - acc: 0.7250 - val_loss: 0.4979 - val_acc: 0.7634\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 706us/step - loss: 0.5872 - acc: 0.6999 - val_loss: 0.5180 - val_acc: 0.7473\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 665us/step - loss: 0.5119 - acc: 0.7593 - val_loss: 0.5141 - val_acc: 0.7572\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 538us/step - loss: 0.5177 - acc: 0.7569 - val_loss: 0.4962 - val_acc: 0.7720\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.5933 - acc: 0.7096 - val_loss: 0.6030 - val_acc: 0.7012\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 662us/step - loss: 0.5672 - acc: 0.7170 - val_loss: 0.5437 - val_acc: 0.7349\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 580us/step - loss: 0.5416 - acc: 0.7246 - val_loss: 0.5297 - val_acc: 0.7430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 633us/step - loss: 0.5051 - acc: 0.7624 - val_loss: 0.4700 - val_acc: 0.7872\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 533us/step - loss: 0.5216 - acc: 0.7572 - val_loss: 0.5138 - val_acc: 0.7590\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 782us/step - loss: 0.5669 - acc: 0.7120 - val_loss: 0.5074 - val_acc: 0.7562\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 560us/step - loss: 0.5436 - acc: 0.7336 - val_loss: 0.5144 - val_acc: 0.7531\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 670us/step - loss: 0.5294 - acc: 0.7517 - val_loss: 0.5344 - val_acc: 0.7442\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 603us/step - loss: 0.5413 - acc: 0.7288 - val_loss: 0.4948 - val_acc: 0.7729\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 610us/step - loss: 0.5027 - acc: 0.7616 - val_loss: 0.4891 - val_acc: 0.7653\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 453us/step - loss: 0.5441 - acc: 0.7303 - val_loss: 0.5123 - val_acc: 0.7523\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 668us/step - loss: 0.5420 - acc: 0.7287 - val_loss: 0.5996 - val_acc: 0.6815\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 525us/step - loss: 0.5886 - acc: 0.6856 - val_loss: 0.5581 - val_acc: 0.7129\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 512us/step - loss: 0.5510 - acc: 0.7188 - val_loss: 0.5438 - val_acc: 0.7241\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 476us/step - loss: 0.5428 - acc: 0.7271 - val_loss: 0.5345 - val_acc: 0.7316\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 633us/step - loss: 0.5161 - acc: 0.7498 - val_loss: 0.5069 - val_acc: 0.7556\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 488us/step - loss: 0.5643 - acc: 0.7106 - val_loss: 0.5378 - val_acc: 0.7323\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 594us/step - loss: 0.5580 - acc: 0.7170 - val_loss: 0.5337 - val_acc: 0.7407\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 457us/step - loss: 0.5322 - acc: 0.7323 - val_loss: 0.5024 - val_acc: 0.7660\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 572us/step - loss: 0.5321 - acc: 0.7379 - val_loss: 0.4776 - val_acc: 0.7894\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 558us/step - loss: 0.5760 - acc: 0.6886 - val_loss: 0.5144 - val_acc: 0.7533\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 680us/step - loss: 0.5653 - acc: 0.7098 - val_loss: 0.5507 - val_acc: 0.7416\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 582us/step - loss: 0.5262 - acc: 0.7455 - val_loss: 0.5032 - val_acc: 0.7667\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 684us/step - loss: 0.5140 - acc: 0.7498 - val_loss: 0.4963 - val_acc: 0.7660\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5413 - acc: 0.7367 - val_loss: 0.5192 - val_acc: 0.7522\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 560us/step - loss: 0.4940 - acc: 0.7645 - val_loss: 0.4915 - val_acc: 0.7740\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 483us/step - loss: 0.5390 - acc: 0.7331 - val_loss: 0.5126 - val_acc: 0.7587\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 605us/step - loss: 0.5472 - acc: 0.7317 - val_loss: 0.5392 - val_acc: 0.7470\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 590us/step - loss: 0.5394 - acc: 0.7251 - val_loss: 0.5072 - val_acc: 0.7491\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 518us/step - loss: 0.5491 - acc: 0.7280 - val_loss: 0.5228 - val_acc: 0.7490\n",
      "Train on 130 samples, validate on 130 samples\n",
      "Epoch 1/1\n",
      "130/130 [==============================] - 0s 685us/step - loss: 0.4853 - acc: 0.7712 - val_loss: 0.5207 - val_acc: 0.7449\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 573us/step - loss: 0.5186 - acc: 0.7534 - val_loss: 0.5001 - val_acc: 0.7649\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 654us/step - loss: 0.4969 - acc: 0.7678 - val_loss: 0.5008 - val_acc: 0.7547\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 651us/step - loss: 0.5106 - acc: 0.7544 - val_loss: 0.5217 - val_acc: 0.7499\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 487us/step - loss: 0.5156 - acc: 0.7524 - val_loss: 0.5268 - val_acc: 0.7348\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 659us/step - loss: 0.4888 - acc: 0.7733 - val_loss: 0.5490 - val_acc: 0.7124\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 535us/step - loss: 0.5561 - acc: 0.7143 - val_loss: 0.4967 - val_acc: 0.7570\n",
      "Train on 278 samples, validate on 278 samples\n",
      "Epoch 1/1\n",
      "278/278 [==============================] - 0s 522us/step - loss: 0.5503 - acc: 0.7103 - val_loss: 0.5254 - val_acc: 0.7420\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 601us/step - loss: 0.5078 - acc: 0.7488 - val_loss: 0.4948 - val_acc: 0.7611\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 575us/step - loss: 0.5233 - acc: 0.7384 - val_loss: 0.5187 - val_acc: 0.7493\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 461us/step - loss: 0.6235 - acc: 0.6573 - val_loss: 0.5836 - val_acc: 0.7076\n",
      "Train on 138 samples, validate on 138 samples\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 625us/step - loss: 0.5576 - acc: 0.7222 - val_loss: 0.5466 - val_acc: 0.7251\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 590us/step - loss: 0.5501 - acc: 0.7194 - val_loss: 0.5024 - val_acc: 0.7550\n",
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 611us/step - loss: 0.5242 - acc: 0.7460 - val_loss: 0.5313 - val_acc: 0.7314\n",
      "Train on 262 samples, validate on 262 samples\n",
      "Epoch 1/1\n",
      "262/262 [==============================] - 0s 516us/step - loss: 0.6537 - acc: 0.6418 - val_loss: 0.5851 - val_acc: 0.7004\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 553us/step - loss: 0.5119 - acc: 0.7493 - val_loss: 0.4832 - val_acc: 0.7807\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 588us/step - loss: 0.5848 - acc: 0.7087 - val_loss: 0.5722 - val_acc: 0.7091\n",
      "Train on 188 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "188/188 [==============================] - 0s 493us/step - loss: 0.5295 - acc: 0.7476 - val_loss: 0.5320 - val_acc: 0.7447\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 626us/step - loss: 0.5398 - acc: 0.7374 - val_loss: 0.5136 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 517us/step - loss: 0.5243 - acc: 0.7444 - val_loss: 0.5416 - val_acc: 0.7304\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 722us/step - loss: 0.5205 - acc: 0.7446 - val_loss: 0.5242 - val_acc: 0.7413\n",
      "Train on 330 samples, validate on 330 samples\n",
      "Epoch 1/1\n",
      "330/330 [==============================] - 0s 604us/step - loss: 0.5645 - acc: 0.7072 - val_loss: 0.5663 - val_acc: 0.7061\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 501us/step - loss: 0.5743 - acc: 0.6960 - val_loss: 0.4952 - val_acc: 0.7659\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "256/256 [==============================] - 0s 537us/step - loss: 0.5422 - acc: 0.7245 - val_loss: 0.4956 - val_acc: 0.7695\n",
      "Train on 264 samples, validate on 264 samples\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 535us/step - loss: 0.5627 - acc: 0.6957 - val_loss: 0.4961 - val_acc: 0.7689\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 482us/step - loss: 0.5325 - acc: 0.7421 - val_loss: 0.4717 - val_acc: 0.7937\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 676us/step - loss: 0.4999 - acc: 0.7668 - val_loss: 0.4941 - val_acc: 0.7639\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 533us/step - loss: 0.5747 - acc: 0.7012 - val_loss: 0.5031 - val_acc: 0.7598\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 626us/step - loss: 0.5172 - acc: 0.7455 - val_loss: 0.4925 - val_acc: 0.7683\n",
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 474us/step - loss: 0.5161 - acc: 0.7421 - val_loss: 0.5141 - val_acc: 0.7514\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 585us/step - loss: 0.5539 - acc: 0.7165 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 613us/step - loss: 0.5371 - acc: 0.7244 - val_loss: 0.5360 - val_acc: 0.7307\n",
      "Train on 204 samples, validate on 204 samples\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 659us/step - loss: 0.4813 - acc: 0.7758 - val_loss: 0.4526 - val_acc: 0.8099\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 610us/step - loss: 0.4938 - acc: 0.7694 - val_loss: 0.5032 - val_acc: 0.7506\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 491us/step - loss: 0.5440 - acc: 0.7298 - val_loss: 0.5092 - val_acc: 0.7534\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 470us/step - loss: 0.4927 - acc: 0.7691 - val_loss: 0.4684 - val_acc: 0.7958\n",
      "Train on 114 samples, validate on 114 samples\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 783us/step - loss: 0.5173 - acc: 0.7463 - val_loss: 0.4871 - val_acc: 0.7684\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 663us/step - loss: 0.4890 - acc: 0.7662 - val_loss: 0.4626 - val_acc: 0.7897\n",
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 0s 657us/step - loss: 0.5401 - acc: 0.7347 - val_loss: 0.4935 - val_acc: 0.7638\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 590us/step - loss: 0.4610 - acc: 0.7933 - val_loss: 0.4397 - val_acc: 0.8054\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 684us/step - loss: 0.5644 - acc: 0.7402 - val_loss: 0.5811 - val_acc: 0.7151\n",
      "Train on 210 samples, validate on 210 samples\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 665us/step - loss: 0.6087 - acc: 0.6858 - val_loss: 0.5938 - val_acc: 0.6996\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 614us/step - loss: 0.5515 - acc: 0.7195 - val_loss: 0.5556 - val_acc: 0.7264\n",
      "Train on 198 samples, validate on 198 samples\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 598us/step - loss: 0.5784 - acc: 0.7161 - val_loss: 0.5701 - val_acc: 0.7134\n",
      "Train on 206 samples, validate on 206 samples\n",
      "Epoch 1/1\n",
      "206/206 [==============================] - 0s 705us/step - loss: 0.5652 - acc: 0.7280 - val_loss: 0.5231 - val_acc: 0.7605\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 523us/step - loss: 0.5435 - acc: 0.7294 - val_loss: 0.5291 - val_acc: 0.7435\n",
      "Train on 214 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 0s 663us/step - loss: 0.5603 - acc: 0.7143 - val_loss: 0.5442 - val_acc: 0.7284\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 527us/step - loss: 0.5729 - acc: 0.7098 - val_loss: 0.5372 - val_acc: 0.7302\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 575us/step - loss: 0.5413 - acc: 0.7361 - val_loss: 0.5336 - val_acc: 0.7390\n",
      "Train on 222 samples, validate on 222 samples\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 582us/step - loss: 0.5363 - acc: 0.7382 - val_loss: 0.5398 - val_acc: 0.7386\n",
      "Train on 296 samples, validate on 296 samples\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 0s 490us/step - loss: 0.5447 - acc: 0.7312 - val_loss: 0.5253 - val_acc: 0.7518\n",
      "Train on 230 samples, validate on 230 samples\n",
      "Epoch 1/1\n",
      "230/230 [==============================] - 0s 602us/step - loss: 0.5215 - acc: 0.7453 - val_loss: 0.5168 - val_acc: 0.7597\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 466us/step - loss: 0.5525 - acc: 0.7265 - val_loss: 0.5217 - val_acc: 0.7540\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 546us/step - loss: 0.5626 - acc: 0.7179 - val_loss: 0.5420 - val_acc: 0.7313\n",
      "Train on 218 samples, validate on 218 samples\n",
      "Epoch 1/1\n",
      "218/218 [==============================] - 0s 714us/step - loss: 0.5691 - acc: 0.7072 - val_loss: 0.5102 - val_acc: 0.7612\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 820us/step - loss: 0.5336 - acc: 0.7416 - val_loss: 0.5443 - val_acc: 0.7300\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 599us/step - loss: 0.5521 - acc: 0.7329 - val_loss: 0.5397 - val_acc: 0.7385\n",
      "Train on 252 samples, validate on 252 samples\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 575us/step - loss: 0.5646 - acc: 0.7126 - val_loss: 0.5031 - val_acc: 0.7717\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 644us/step - loss: 0.5484 - acc: 0.7297 - val_loss: 0.5456 - val_acc: 0.7314\n",
      "Train on 118 samples, validate on 118 samples\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 0s 777us/step - loss: 0.5467 - acc: 0.7272 - val_loss: 0.5383 - val_acc: 0.7331\n",
      "Train on 232 samples, validate on 232 samples\n",
      "Epoch 1/1\n",
      "232/232 [==============================] - 0s 593us/step - loss: 0.5310 - acc: 0.7439 - val_loss: 0.5215 - val_acc: 0.7550\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 545us/step - loss: 0.4799 - acc: 0.7766 - val_loss: 0.4687 - val_acc: 0.7917\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 629us/step - loss: 0.5709 - acc: 0.7072 - val_loss: 0.5141 - val_acc: 0.7463\n",
      "Train on 156 samples, validate on 156 samples\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 581us/step - loss: 0.5129 - acc: 0.7489 - val_loss: 0.4881 - val_acc: 0.7686\n",
      "Train on 212 samples, validate on 212 samples\n",
      "Epoch 1/1\n",
      "212/212 [==============================] - 0s 665us/step - loss: 0.5323 - acc: 0.7388 - val_loss: 0.5118 - val_acc: 0.7559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 491us/step - loss: 0.5245 - acc: 0.7401 - val_loss: 0.5064 - val_acc: 0.7628\n",
      "Train on 164 samples, validate on 164 samples\n",
      "Epoch 1/1\n",
      "164/164 [==============================] - 0s 578us/step - loss: 0.5744 - acc: 0.7009 - val_loss: 0.5360 - val_acc: 0.7302\n",
      "Train on 346 samples, validate on 346 samples\n",
      "Epoch 1/1\n",
      "346/346 [==============================] - 0s 627us/step - loss: 0.5467 - acc: 0.7235 - val_loss: 0.5260 - val_acc: 0.7423\n",
      "Train on 172 samples, validate on 172 samples\n",
      "Epoch 1/1\n",
      "172/172 [==============================] - 0s 609us/step - loss: 0.5308 - acc: 0.7507 - val_loss: 0.5379 - val_acc: 0.7475\n",
      "Train on 286 samples, validate on 286 samples\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 0s 502us/step - loss: 0.4922 - acc: 0.7719 - val_loss: 0.4950 - val_acc: 0.7687\n",
      "Train on 186 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 471us/step - loss: 0.5419 - acc: 0.7316 - val_loss: 0.5003 - val_acc: 0.7696\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 679us/step - loss: 0.5271 - acc: 0.7541 - val_loss: 0.5027 - val_acc: 0.7682\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 603us/step - loss: 0.5164 - acc: 0.7544 - val_loss: 0.5326 - val_acc: 0.7341\n",
      "Train on 132 samples, validate on 132 samples\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 0s 668us/step - loss: 0.4980 - acc: 0.7787 - val_loss: 0.5050 - val_acc: 0.7625\n",
      "Train on 280 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "280/280 [==============================] - 0s 510us/step - loss: 0.4937 - acc: 0.7638 - val_loss: 0.5026 - val_acc: 0.7583\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 599us/step - loss: 0.5811 - acc: 0.7021 - val_loss: 0.5219 - val_acc: 0.7462\n",
      "Train on 190 samples, validate on 190 samples\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 0s 500us/step - loss: 0.5418 - acc: 0.7342 - val_loss: 0.5058 - val_acc: 0.7624\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 611us/step - loss: 0.5405 - acc: 0.7240 - val_loss: 0.5348 - val_acc: 0.7351\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 588us/step - loss: 0.5206 - acc: 0.7312 - val_loss: 0.5004 - val_acc: 0.7636\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 488us/step - loss: 0.5249 - acc: 0.7464 - val_loss: 0.5298 - val_acc: 0.7437\n",
      "Train on 142 samples, validate on 142 samples\n",
      "Epoch 1/1\n",
      "142/142 [==============================] - 0s 608us/step - loss: 0.5636 - acc: 0.7227 - val_loss: 0.5473 - val_acc: 0.7345\n",
      "Train on 108 samples, validate on 108 samples\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 778us/step - loss: 0.4891 - acc: 0.7702 - val_loss: 0.5014 - val_acc: 0.7557\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 509us/step - loss: 0.5210 - acc: 0.7472 - val_loss: 0.5275 - val_acc: 0.7409\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.5520 - acc: 0.7271 - val_loss: 0.5641 - val_acc: 0.7130\n",
      "Train on 152 samples, validate on 152 samples\n",
      "Epoch 1/1\n",
      "152/152 [==============================] - 0s 638us/step - loss: 0.5488 - acc: 0.7265 - val_loss: 0.5377 - val_acc: 0.7295\n",
      "Train on 174 samples, validate on 174 samples\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 637us/step - loss: 0.5284 - acc: 0.7389 - val_loss: 0.5240 - val_acc: 0.7385\n",
      "Train on 140 samples, validate on 140 samples\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 0s 725us/step - loss: 0.5321 - acc: 0.7334 - val_loss: 0.4955 - val_acc: 0.7653\n",
      "Train on 228 samples, validate on 228 samples\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 637us/step - loss: 0.5920 - acc: 0.7000 - val_loss: 0.5164 - val_acc: 0.7479\n",
      "Train on 202 samples, validate on 202 samples\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 0s 703us/step - loss: 0.5125 - acc: 0.7547 - val_loss: 0.5117 - val_acc: 0.7573\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 557us/step - loss: 0.5179 - acc: 0.7513 - val_loss: 0.4949 - val_acc: 0.7687\n",
      "Train on 242 samples, validate on 242 samples\n",
      "Epoch 1/1\n",
      "242/242 [==============================] - 0s 601us/step - loss: 0.5670 - acc: 0.7193 - val_loss: 0.5762 - val_acc: 0.7157\n",
      "Train on 144 samples, validate on 144 samples\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 674us/step - loss: 0.5670 - acc: 0.7116 - val_loss: 0.5364 - val_acc: 0.7400\n",
      "Train on 356 samples, validate on 356 samples\n",
      "Epoch 1/1\n",
      "356/356 [==============================] - 0s 572us/step - loss: 0.5328 - acc: 0.7349 - val_loss: 0.5233 - val_acc: 0.7473\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 598us/step - loss: 0.5011 - acc: 0.7607 - val_loss: 0.4648 - val_acc: 0.7890\n",
      "Train on 184 samples, validate on 184 samples\n",
      "Epoch 1/1\n",
      "184/184 [==============================] - 0s 506us/step - loss: 0.5180 - acc: 0.7589 - val_loss: 0.5090 - val_acc: 0.7656\n",
      "Train on 238 samples, validate on 238 samples\n",
      "Epoch 1/1\n",
      "238/238 [==============================] - 0s 599us/step - loss: 0.5545 - acc: 0.7151 - val_loss: 0.4996 - val_acc: 0.7609\n",
      "Train on 340 samples, validate on 340 samples\n",
      "Epoch 1/1\n",
      "340/340 [==============================] - 0s 547us/step - loss: 0.5422 - acc: 0.7342 - val_loss: 0.5161 - val_acc: 0.7513\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 625us/step - loss: 0.5334 - acc: 0.7475 - val_loss: 0.5306 - val_acc: 0.7481\n",
      "Train on 260 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 0s 557us/step - loss: 0.5398 - acc: 0.7291 - val_loss: 0.4949 - val_acc: 0.7716\n",
      "Train on 216 samples, validate on 216 samples\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 601us/step - loss: 0.5051 - acc: 0.7592 - val_loss: 0.4848 - val_acc: 0.7676\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 500us/step - loss: 0.5424 - acc: 0.7279 - val_loss: 0.5174 - val_acc: 0.7499\n",
      "Train on 124 samples, validate on 124 samples\n",
      "Epoch 1/1\n",
      "124/124 [==============================] - 0s 737us/step - loss: 0.5363 - acc: 0.7318 - val_loss: 0.6000 - val_acc: 0.6817\n",
      "Train on 192 samples, validate on 192 samples\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 503us/step - loss: 0.5907 - acc: 0.6803 - val_loss: 0.5588 - val_acc: 0.7125\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 521us/step - loss: 0.5492 - acc: 0.7188 - val_loss: 0.5405 - val_acc: 0.7269\n",
      "Train on 282 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 490us/step - loss: 0.5396 - acc: 0.7324 - val_loss: 0.5314 - val_acc: 0.7336\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/1\n",
      "220/220 [==============================] - 0s 637us/step - loss: 0.5153 - acc: 0.7499 - val_loss: 0.5044 - val_acc: 0.7566\n",
      "Train on 194 samples, validate on 194 samples\n",
      "Epoch 1/1\n",
      "194/194 [==============================] - 0s 498us/step - loss: 0.5575 - acc: 0.7191 - val_loss: 0.5316 - val_acc: 0.7348\n",
      "Train on 302 samples, validate on 302 samples\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 0s 598us/step - loss: 0.5448 - acc: 0.7344 - val_loss: 0.5266 - val_acc: 0.7459\n",
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 497us/step - loss: 0.5241 - acc: 0.7395 - val_loss: 0.4987 - val_acc: 0.7705\n",
      "Train on 160 samples, validate on 160 samples\n",
      "Epoch 1/1\n",
      "160/160 [==============================] - 0s 578us/step - loss: 0.5276 - acc: 0.7380 - val_loss: 0.4726 - val_acc: 0.7926\n",
      "Train on 158 samples, validate on 158 samples\n",
      "Epoch 1/1\n",
      "158/158 [==============================] - 0s 558us/step - loss: 0.5676 - acc: 0.7028 - val_loss: 0.5103 - val_acc: 0.7571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154 samples, validate on 154 samples\n",
      "Epoch 1/1\n",
      "154/154 [==============================] - 0s 600us/step - loss: 0.5635 - acc: 0.7122 - val_loss: 0.5453 - val_acc: 0.7456\n",
      "Train on 166 samples, validate on 166 samples\n",
      "Epoch 1/1\n",
      "166/166 [==============================] - 0s 571us/step - loss: 0.5231 - acc: 0.7416 - val_loss: 0.5027 - val_acc: 0.7694\n",
      "Train on 224 samples, validate on 224 samples\n",
      "Epoch 1/1\n",
      "224/224 [==============================] - 0s 632us/step - loss: 0.5196 - acc: 0.7466 - val_loss: 0.4952 - val_acc: 0.7667\n",
      "Train on 294 samples, validate on 294 samples\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.5374 - acc: 0.7405 - val_loss: 0.5149 - val_acc: 0.7554\n",
      "Train on 150 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 625us/step - loss: 0.4987 - acc: 0.7586 - val_loss: 0.4854 - val_acc: 0.7774\n",
      "Train on 196 samples, validate on 196 samples\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 0s 491us/step - loss: 0.5355 - acc: 0.7400 - val_loss: 0.5061 - val_acc: 0.7657\n",
      "Train on 148 samples, validate on 148 samples\n",
      "Epoch 1/1\n",
      "148/148 [==============================] - 0s 668us/step - loss: 0.5373 - acc: 0.7383 - val_loss: 0.5327 - val_acc: 0.7512\n",
      "Train on 234 samples, validate on 234 samples\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 609us/step - loss: 0.5415 - acc: 0.7225 - val_loss: 0.5026 - val_acc: 0.7561\n",
      "Train on 180 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 571us/step - loss: 0.5553 - acc: 0.7250 - val_loss: 0.5203 - val_acc: 0.7509\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(GRU(Max_RNN, return_sequences=True), input_shape=(Max_RNN,513)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(GRU(Max_RNN, return_sequences=True)))\n",
    "\n",
    "model.add(Dense(513, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "for ep in range(10):\n",
    "    for (b_x,b_y), (v_x,v_y) in zip(next_batch(DATA_train_x, DATA_train_M), next_batch(DATA_val_x, DATA_val_M)):\n",
    "        model.fit(b_x, b_y, validation_data=(v_x,v_y), shuffle=True, batch_size=100)\n",
    "\n",
    "        \n",
    "# Final evaluation of the model\n",
    "scores = []\n",
    "for v_x,v_y in next_batch(DATA_val_x, DATA_val_x):\n",
    "    scores.append( model.evaluate(v_x, v_y,verbose=0)[1] )\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Generator for SNR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch_SXX_cmplxS_cmplx(S_,X_,X_cmplx_,S_cmplx_):\n",
    "    \n",
    "    batch_s = None\n",
    "    batch_x = None\n",
    "    batch_x_cmplx = None\n",
    "    batch_s_cmplx = None\n",
    "    \n",
    "    for e,(s,x,x_cmplx,s_cmplx) in enumerate( zip(S_,X_,X_cmplx_,S_cmplx_)): \n",
    "        batch_s = np.array(s.T) if batch_s is None else np.concatenate( (batch_s,s.T), axis=0)\n",
    "        batch_x = np.array(x.T) if batch_x is None else np.concatenate( (batch_x,x.T), axis=0)\n",
    "        batch_x_cmplx = np.array(x_cmplx.T) if batch_x_cmplx is None else np.concatenate( (batch_x_cmplx,x_cmplx.T), axis=0)\n",
    "        batch_s_cmplx = np.array(s_cmplx.T) if batch_s_cmplx is None else np.concatenate( (batch_s_cmplx,s_cmplx.T), axis=0)\n",
    "        \n",
    "        \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp_s, batch_s = batch_s, None\n",
    "            temp_x, batch_x = batch_x, None\n",
    "            temp_x_cmplx, batch_x_cmplx = batch_x_cmplx, None\n",
    "            temp_s_cmplx, batch_s_cmplx = batch_s_cmplx, None\n",
    "            \n",
    "            temp_s = temp_s.reshape((-1,Max_RNN,513))\n",
    "            temp_x = temp_x.reshape((-1,Max_RNN,513))\n",
    "            temp_x_cmplx = temp_x_cmplx.reshape((-1,Max_RNN,513))\n",
    "\n",
    "            yield temp_s,temp_x,temp_x_cmplx,temp_s_cmplx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 5.717474456837075\n"
     ]
    }
   ],
   "source": [
    "sum_s = 0.0\n",
    "sum_s_diff = 0.0\n",
    "\n",
    "\n",
    "for v_s,v_x,v_x_cmplx,v_s_cmplx in next_batch_SXX_cmplxS_cmplx(DATA_val_s,DATA_val_x,DATA_val_x_cmplx,DATA_val_s_cmplx):\n",
    "    \n",
    "    mask = model.predict(v_x)\n",
    "    S_hat = (mask) * v_x_cmplx\n",
    "    S_hat = S_hat.reshape(-1,513).T\n",
    "    S = v_s_cmplx.T\n",
    "\n",
    "    S_org = librosa.istft(S, hop_length=512)\n",
    "    S_pred = librosa.istft(S_hat, hop_length=512)\n",
    "\n",
    "    sum_s += np.sum(S_org*S_org)\n",
    "    sum_s_diff += np.sum((S_org-S_pred)*(S_org-S_pred))\n",
    "    \n",
    "acc = sum_s/ sum_s_diff\n",
    "print( 'SNR:', 10*np.log10(acc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_audio():\n",
    "    mags = None\n",
    "    cmplxs = None\n",
    "    g_counter = 0\n",
    "    \n",
    "    for e, file_x in enumerate(sorted(glob.glob(PATH_directory+PATH_test+MIX_format_test))):\n",
    "        print(e)\n",
    "        sn, sr = librosa.load(file_x, sr=None)\n",
    "        Sn = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        mag_Sn=np.abs(Sn)\n",
    "        \n",
    "        mags = np.array(mag_Sn.T) if mags is None else np.concatenate( (mags,mag_Sn.T), axis=0)\n",
    "        cmplxs = np.array(Sn.T) if cmplxs is None else np.concatenate( (cmplxs,Sn.T), axis=0)\n",
    "        \n",
    "        if e>0 and (e+1)%10==0:\n",
    "            temp, mags = mags, None\n",
    "            temp_cmplxs, cmplxs = cmplxs, None\n",
    "            \n",
    "            temp = temp.reshape((-1,Max_RNN,513))\n",
    "            mask = model.predict(temp)\n",
    "            \n",
    "            mask=mask.reshape(-1,513)\n",
    "            S_hat = (mask) * temp_cmplxs\n",
    "            S_hat = S_hat.T\n",
    "            \n",
    "            lenght_w = S_hat.shape[1]//10\n",
    "            for clip in range(10):\n",
    "                start_w = clip*lenght_w\n",
    "                end_w = (clip+1)*lenght_w\n",
    "                \n",
    "                wav = S_hat[:,start_w:end_w]\n",
    "\n",
    "                S_time=librosa.istft(wav, hop_length=512)\n",
    "                fname = PATH_directory+PATH_denoise+ str(g_counter) + \"_redoise.wav\"\n",
    "                g_counter += 1\n",
    "                \n",
    "                print(fname)\n",
    "                librosa.output.write_wav(fname, S_time, sr)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "/N/u/knayem/data/timit-homework/dn/0_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/1_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/2_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/3_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/4_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/5_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/6_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/7_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/8_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/9_redoise.wav\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "/N/u/knayem/data/timit-homework/dn/10_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/11_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/12_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/13_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/14_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/15_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/16_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/17_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/18_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/19_redoise.wav\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "/N/u/knayem/data/timit-homework/dn/20_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/21_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/22_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/23_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/24_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/25_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/26_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/27_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/28_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/29_redoise.wav\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "/N/u/knayem/data/timit-homework/dn/30_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/31_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/32_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/33_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/34_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/35_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/36_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/37_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/38_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/39_redoise.wav\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "/N/u/knayem/data/timit-homework/dn/40_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/41_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/42_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/43_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/44_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/45_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/46_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/47_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/48_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/49_redoise.wav\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "/N/u/knayem/data/timit-homework/dn/50_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/51_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/52_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/53_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/54_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/55_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/56_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/57_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/58_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/59_redoise.wav\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "/N/u/knayem/data/timit-homework/dn/60_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/61_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/62_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/63_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/64_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/65_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/66_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/67_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/68_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/69_redoise.wav\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "/N/u/knayem/data/timit-homework/dn/70_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/71_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/72_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/73_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/74_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/75_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/76_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/77_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/78_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/79_redoise.wav\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "/N/u/knayem/data/timit-homework/dn/80_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/81_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/82_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/83_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/84_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/85_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/86_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/87_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/88_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/89_redoise.wav\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "/N/u/knayem/data/timit-homework/dn/90_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/91_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/92_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/93_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/94_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/95_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/96_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/97_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/98_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/99_redoise.wav\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "/N/u/knayem/data/timit-homework/dn/100_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/101_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/102_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/103_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/104_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/105_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/106_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/107_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/108_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/109_redoise.wav\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "/N/u/knayem/data/timit-homework/dn/110_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/111_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/112_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/113_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/114_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/115_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/116_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/117_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/118_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/119_redoise.wav\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "/N/u/knayem/data/timit-homework/dn/120_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/121_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/122_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/123_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/124_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/125_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/126_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/127_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/128_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/129_redoise.wav\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "/N/u/knayem/data/timit-homework/dn/130_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/131_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/132_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/133_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/134_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/135_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/136_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/137_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/138_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/139_redoise.wav\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "/N/u/knayem/data/timit-homework/dn/140_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/141_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/142_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/143_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/144_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/145_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/146_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/147_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/148_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/149_redoise.wav\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "/N/u/knayem/data/timit-homework/dn/150_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/151_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/152_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/153_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/154_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/155_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/156_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/157_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/158_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/159_redoise.wav\n",
      "160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "/N/u/knayem/data/timit-homework/dn/160_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/161_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/162_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/163_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/164_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/165_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/166_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/167_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/168_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/169_redoise.wav\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "/N/u/knayem/data/timit-homework/dn/170_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/171_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/172_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/173_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/174_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/175_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/176_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/177_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/178_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/179_redoise.wav\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "/N/u/knayem/data/timit-homework/dn/180_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/181_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/182_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/183_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/184_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/185_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/186_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/187_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/188_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/189_redoise.wav\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "/N/u/knayem/data/timit-homework/dn/190_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/191_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/192_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/193_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/194_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/195_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/196_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/197_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/198_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/199_redoise.wav\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "/N/u/knayem/data/timit-homework/dn/200_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/201_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/202_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/203_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/204_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/205_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/206_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/207_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/208_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/209_redoise.wav\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "/N/u/knayem/data/timit-homework/dn/210_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/211_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/212_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/213_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/214_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/215_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/216_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/217_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/218_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/219_redoise.wav\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "/N/u/knayem/data/timit-homework/dn/220_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/221_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/222_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/223_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/224_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/225_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/226_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/227_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/228_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/229_redoise.wav\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "/N/u/knayem/data/timit-homework/dn/230_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/231_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/232_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/233_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/234_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/235_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/236_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/237_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/238_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/239_redoise.wav\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "/N/u/knayem/data/timit-homework/dn/240_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/241_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/242_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/243_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/244_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/245_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/246_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/247_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/248_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/249_redoise.wav\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "/N/u/knayem/data/timit-homework/dn/250_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/251_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/252_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/253_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/254_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/255_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/256_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/257_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/258_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/259_redoise.wav\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "/N/u/knayem/data/timit-homework/dn/260_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/261_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/262_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/263_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/264_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/265_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/266_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/267_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/268_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/269_redoise.wav\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "/N/u/knayem/data/timit-homework/dn/270_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/271_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/272_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/273_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/274_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/275_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/276_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/277_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/278_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/279_redoise.wav\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "/N/u/knayem/data/timit-homework/dn/280_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/281_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/282_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/283_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/284_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/285_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/286_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/287_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/288_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/289_redoise.wav\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "/N/u/knayem/data/timit-homework/dn/290_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/291_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/292_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/293_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/294_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/295_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/296_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/297_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/298_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/299_redoise.wav\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "/N/u/knayem/data/timit-homework/dn/300_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/301_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/302_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/303_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/304_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/305_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/306_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/307_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/308_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/309_redoise.wav\n",
      "310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "/N/u/knayem/data/timit-homework/dn/310_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/311_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/312_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/313_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/314_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/315_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/316_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/317_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/318_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/319_redoise.wav\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "/N/u/knayem/data/timit-homework/dn/320_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/321_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/322_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/323_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/324_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/325_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/326_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/327_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/328_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/329_redoise.wav\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "/N/u/knayem/data/timit-homework/dn/330_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/331_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/332_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/333_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/334_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/335_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/336_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/337_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/338_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/339_redoise.wav\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "/N/u/knayem/data/timit-homework/dn/340_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/341_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/342_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/343_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/344_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/345_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/346_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/347_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/348_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/349_redoise.wav\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "/N/u/knayem/data/timit-homework/dn/350_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/351_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/352_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/353_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/354_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/355_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/356_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/357_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/358_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/359_redoise.wav\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "/N/u/knayem/data/timit-homework/dn/360_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/361_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/362_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/363_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/364_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/365_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/366_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/367_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/368_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/369_redoise.wav\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "/N/u/knayem/data/timit-homework/dn/370_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/371_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/372_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/373_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/374_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/375_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/376_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/377_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/378_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/379_redoise.wav\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "/N/u/knayem/data/timit-homework/dn/380_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/381_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/382_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/383_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/384_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/385_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/386_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/387_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/388_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/389_redoise.wav\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "/N/u/knayem/data/timit-homework/dn/390_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/391_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/392_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/393_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/394_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/395_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/396_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/397_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/398_redoise.wav\n",
      "/N/u/knayem/data/timit-homework/dn/399_redoise.wav\n"
     ]
    }
   ],
   "source": [
    "write_audio()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
