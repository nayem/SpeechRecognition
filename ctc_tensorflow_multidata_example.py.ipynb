{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/igormq/ctc_tensorflow_example/blob/master/ctc_tensorflow_multidata_example.py\n",
    "#  Compatibility imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "\n",
    "from six.moves import xrange as range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from python_speech_features import mfcc\n",
    "except ImportError:\n",
    "    print(\"Failed to import python_speech_features.\\n Try pip install python_speech_features.\")\n",
    "    raise ImportError\n",
    "    \n",
    "from utils import sparse_tuple_from as sparse_tuple_from\n",
    "from utils import pad_sequences as pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_data(num_examples, num_features, num_labels, min_size = 10, max_size=100):\n",
    "\n",
    "    # Generating different timesteps for each fake data\n",
    "    timesteps = np.random.randint(min_size, max_size, (num_examples,))\n",
    "\n",
    "    # Generating random input\n",
    "    inputs = np.asarray([np.random.randn(t, num_features).astype(np.float32) for t in timesteps])\n",
    "\n",
    "    # Generating random label, the size must be less or equal than timestep in order to achieve the end of the lattice in max timestep\n",
    "    labels = np.asarray([np.random.randint(0, num_labels, np.random.randint(1, inputs[i].shape[0], (1,))).astype(np.int64) for i, _ in enumerate(timesteps)])\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space\n",
    "\n",
    "# Some configs\n",
    "num_features = 13\n",
    "# Accounting the 0th indice +  space + blank label = 28 characters\n",
    "num_classes = ord('z') - ord('a') + 1 + 1 + 1\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 40\n",
    "num_hidden = 50\n",
    "num_layers = 1\n",
    "batch_size = 2\n",
    "initial_learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "\n",
    "num_examples = 16\n",
    "num_batches_per_epoch = int(num_examples/batch_size)\n",
    "\n",
    "num_units = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = fake_data(num_examples, num_features, num_classes - 1)\n",
    "\n",
    "# You can preprocess the input data here\n",
    "train_inputs = inputs\n",
    "\n",
    "# You can preprocess the target data here\n",
    "train_targets = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MAIN CODE!\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # e.g: log filter bank or MFCC features\n",
    "    # Has size [batch_size, max_stepsize, num_features], but the\n",
    "    # batch_size and max_stepsize can vary along each step\n",
    "    inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "\n",
    "    # Here we use sparse_placeholder that will generate a\n",
    "    # SparseTensor required by ctc_loss op.\n",
    "    targets = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "    # 1d array of size [batch_size]\n",
    "    seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    # Defining the cell\n",
    "    # Can be:\n",
    "    #   tf.nn.rnn_cell.RNNCell\n",
    "    #   tf.nn.rnn_cell.GRUCell\n",
    "    # Stacking rnn cells\n",
    "    cells = []\n",
    "    for _ in range(num_layers):\n",
    "        cell = tf.contrib.rnn.LSTMCell(num_units)  # Or LSTMCell(num_units)\n",
    "        cells.append(cell)\n",
    "    stack = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "    # The second output is the last state and we will no use that\n",
    "    outputs, _ = tf.nn.dynamic_rnn(stack, inputs, seq_len, dtype=tf.float32)\n",
    "\n",
    "    shape = tf.shape(inputs)\n",
    "    batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "    # Reshaping to apply the same weights over the timesteps\n",
    "    outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "\n",
    "    # Truncated normal with mean 0 and stdev=0.1\n",
    "    # Tip: Try another initialization\n",
    "    # see https://www.tensorflow.org/versions/r0.9/api_docs/python/contrib.layers.html#initializers\n",
    "    W = tf.Variable(tf.truncated_normal([num_hidden,\n",
    "                                         num_classes],\n",
    "                                        stddev=0.1))\n",
    "    # Zero initialization\n",
    "    # Tip: Is tf.zeros_initializer the same?\n",
    "    b = tf.Variable(tf.constant(0., shape=[num_classes]))\n",
    "\n",
    "    # Doing the affine projection\n",
    "    logits = tf.matmul(outputs, W) + b\n",
    "\n",
    "    # Reshaping back to the original shape\n",
    "    logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "\n",
    "    # Time major\n",
    "    logits = tf.transpose(logits, (1, 0, 2))\n",
    "\n",
    "    loss = tf.nn.ctc_loss(targets, logits, seq_len)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(initial_learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "\n",
    "    # Option 2: tf.nn.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "    # Inaccuracy: label error rate\n",
    "    ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                          targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 780 values, but the requested shape requires a multiple of 50\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose_1, Reshape/shape)]]\n\t [[Node: transpose/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_105_transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Reshape', defined at:\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-27707c222243>\", line 35, in <module>\n    outputs = tf.reshape(outputs, [-1, num_hidden])\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3997, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 780 values, but the requested shape requires a multiple of 50\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose_1, Reshape/shape)]]\n\t [[Node: transpose/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_105_transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 780 values, but the requested shape requires a multiple of 50\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose_1, Reshape/shape)]]\n\t [[Node: transpose/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_105_transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-36741229eefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                     seq_len: batch_train_seq_len}\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mbatch_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_cost\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtrain_ler\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 780 values, but the requested shape requires a multiple of 50\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose_1, Reshape/shape)]]\n\t [[Node: transpose/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_105_transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Reshape', defined at:\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-27707c222243>\", line 35, in <module>\n    outputs = tf.reshape(outputs, [-1, num_hidden])\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3997, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/opt/Anaconda3-5.0.1/envs/e533/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 780 values, but the requested shape requires a multiple of 50\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/transpose_1, Reshape/shape)]]\n\t [[Node: transpose/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_105_transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    # Initializate the weights and biases\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "    for curr_epoch in range(num_epochs):\n",
    "        train_cost = train_ler = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for batch in range(num_batches_per_epoch):\n",
    "\n",
    "            # Getting the index\n",
    "            indexes = [i % num_examples for i in range(batch * batch_size, (batch + 1) * batch_size)]\n",
    "\n",
    "            batch_train_inputs = train_inputs[indexes]\n",
    "            # Padding input to max_time_step of this batch\n",
    "            batch_train_inputs, batch_train_seq_len = pad_sequences(batch_train_inputs)\n",
    "\n",
    "            # Converting to sparse representation so as to to feed SparseTensor input\n",
    "            batch_train_targets = sparse_tuple_from(train_targets[indexes])\n",
    "\n",
    "            feed = {inputs: batch_train_inputs,\n",
    "                    targets: batch_train_targets,\n",
    "                    seq_len: batch_train_seq_len}\n",
    "\n",
    "            batch_cost, _ = session.run([cost, optimizer], feed)\n",
    "            train_cost += batch_cost*batch_size\n",
    "            train_ler += session.run(ler, feed_dict=feed)*batch_size\n",
    "\n",
    "\n",
    "        # Shuffle the data\n",
    "        shuffled_indexes = np.random.permutation(num_examples)\n",
    "        train_inputs = train_inputs[shuffled_indexes]\n",
    "        train_targets = train_targets[shuffled_indexes]\n",
    "\n",
    "        # Metrics mean\n",
    "        train_cost /= num_examples\n",
    "        train_ler /= num_examples\n",
    "\n",
    "        log = \"Epoch {}/{}, train_cost = {:.3f}, train_ler = {:.3f}, time = {:.3f}\"\n",
    "        print(log.format(curr_epoch+1, num_epochs, train_cost, train_ler, time.time() - start))\n",
    "\n",
    "    # Decoding all at once. Note that this isn't the best way\n",
    "\n",
    "    # Padding input to max_time_step of this batch\n",
    "    batch_train_inputs, batch_train_seq_len = pad_sequences(train_inputs)\n",
    "\n",
    "    # Converting to sparse representation so as to to feed SparseTensor input\n",
    "    batch_train_targets = sparse_tuple_from(train_targets)\n",
    "\n",
    "    feed = {inputs: batch_train_inputs,\n",
    "            targets: batch_train_targets,\n",
    "            seq_len: batch_train_seq_len\n",
    "            }\n",
    "\n",
    "    # Decoding\n",
    "    d = session.run(decoded[0], feed_dict=feed)\n",
    "    dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=session)\n",
    "\n",
    "    for i, seq in enumerate(dense_decoded):\n",
    "\n",
    "        seq = [s for s in seq if s != -1]\n",
    "\n",
    "        print('Sequence %d' % i)\n",
    "        print('\\t Original:\\n%s' % train_targets[i])\n",
    "        print('\\t Decoded:\\n%s' % seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
